{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "751511a4-1a3b-4172-a4aa-644136d3eeaa",
   "metadata": {},
   "source": [
    "# 혼공머 08-1\n",
    "> 합성곱 신경망의 구성 요소\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: 김동준\n",
    "- categories : [\"Python\", \"혼공머\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c7fd1-1b2d-4e89-9109-42c0daeb4777",
   "metadata": {},
   "source": [
    "# 주로쓰는 패키지들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f7d8173-4461-491f-b109-b58addb5f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "import numpy as np #넘파이\n",
    "import pandas as pd #판다스\n",
    "from plotnine import *  #플롯나인\n",
    "import matplotlib.pyplot as plt #맷플랏립\n",
    "import plotly.express as px #플랏리 상호작용 그래프\n",
    "from IPython.display import HTML #블로그에 html로 올리려고 변환하는 패키지\n",
    "import seaborn as sns # 씨본, 히스토그램 깔끔하게 그리는 패키지\n",
    "#___________________________________\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier # k 최근접이웃\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor  # 결정계수 \n",
    "from sklearn.metrics import mean_absolute_error # 타깃과 예측의 절댓값 오차 평균을 반환\n",
    "from sklearn.linear_model import LinearRegression # 선형 회귀\n",
    "from sklearn.preprocessing import PolynomialFeatures #다중회귀로의 변환기\n",
    "from sklearn.preprocessing import StandardScaler #규제\n",
    "from sklearn.linear_model import Ridge #릿지\n",
    "from sklearn.linear_model import Lasso #라쏘\n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱회귀\n",
    "from scipy.special import expit #시그모이드함수\n",
    "from scipy.special import softmax #소프트맥스함수\n",
    "from sklearn.linear_model import SGDClassifier # 확률적 경사 하강법\n",
    "from sklearn.tree import DecisionTreeClassifier # 트리\n",
    "from sklearn.tree import plot_tree # 트리 모형\n",
    "from sklearn.model_selection import cross_validate # 교차 검증\n",
    "from sklearn.model_selection import StratifiedKFold # Kfold 교차 검증\n",
    "from sklearn.model_selection import GridSearchCV # 그리드 서치 (하이퍼 파라미터 튜닝)\n",
    "from scipy.stats import uniform, randint #랜덤 서치\n",
    "from sklearn.model_selection import RandomizedSearchCV # 랜덤 서치 클래스\n",
    "from sklearn.ensemble import RandomForestClassifier # 랜덤포레스트 앙상블\n",
    "from sklearn.ensemble import ExtraTreesClassifier # 엑스트라 트리 앙상블\n",
    "from sklearn.ensemble import GradientBoostingClassifier # 그레이디언트 부스팅 앙상블\n",
    "\n",
    "# 히스토그램 기반 그레이디언트 부스팅\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance # 특성중요도\n",
    "from xgboost import XGBClassifier # 알고리즘을 구현한 또다른 라이브러리1\n",
    "from lightgbm import LGBMClassifier # 알고리즘을 구현한 또다른 라이브러리2 , 마이크로소프트에서 구현 \n",
    "\n",
    "\n",
    "# ____________________\n",
    "from sklearn.cluster import KMeans # KMeans\n",
    "from sklearn.decomposition import PCA # 주성분 분석\n",
    "\n",
    "# 7장 딥러닝\n",
    "from tensorflow import keras # 케라스 \n",
    "import tensorflow as tf # 텐서플로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca8608b-d4fc-4a22-a8a4-5f16cc4f1ebe",
   "metadata": {},
   "source": [
    "# 합성곱 convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a223de-730f-416e-b3c5-44dbc0210814",
   "metadata": {},
   "source": [
    "> 마치 입력 데이터에 마법의 도장을 찍어서 유용한 특성만을 드러나게 하는 것으로 비유 가능\n",
    "\n",
    "> 7장에서 사용한 밀집층에는 뉴런마다 입력 개수만큼의 가중치가 있다. 즉 모든 입력에 가중치를 곱한다.\n",
    "\n",
    "> 인공신경망은 처음에 가중치 w1~w10과 절편 b를 랜덤하게 초기화한 다음 에포크를 반복하면서 경사 하강법 알고리즘을 사용하여 손실이 낮아지도록 최적의 가중치와 절편을 찾아간다. : 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44f726-d7c0-4f94-9b44-61e30dc21267",
   "metadata": {},
   "source": [
    "> 예를 들어 밀집층에 뉴런이 3개 있다면 출력은 3개가 된다. (입력 개수에 상관없이 동일)\n",
    "\n",
    "> ex) 784개의 픽셀을 입력받는 은닉층의 뉴런 개수가 100개면 뉴런마다 하나씩 출력도 100개가 된다.\n",
    "\n",
    "> 합성곱은 밀집층의 계산과 조금 다르다. 입력 데이터 전체에 가중치를 적용하는 것이 아니라 일부에 가중치를 곱한다.\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4582219a-e4a6-4b7f-8c46-80c3782fd2c0",
   "metadata": {},
   "source": [
    "> 가중치 $w1~w3$이 입력의 처음 3개 특성과 곱해져 1개의 출력을 만든다. 그다음이 중요한데, 이뉴런이 한칸 아래로 이동해 두번째부터 네번째 특성과 곱해져 새로운 출력을 만든다.\n",
    "\n",
    "> 여기에서 중요한 것은 첫 번째 합성곱에 사용된 가중치 $w1~w3$과 절편 b가 두 번째 합성곱에도 동일하게 사용된다.\n",
    "\n",
    "> 이렇게 한 칸씩 아래로 이동하면서 출력을 만드는 것이 합성곱.\n",
    "\n",
    "> 여기서는 이 뉴런의 가중치가 3개이기 때문에 모두 8개의 출력이 만들어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf48af-bd9d-4f6e-be88-58fe8a240c39",
   "metadata": {},
   "source": [
    "> 8개 출력 모두 같은 뉴런이며 같은 가중치 $w1~w3$과 절편 $b$를 사용한다.\n",
    "\n",
    "> 밀집층의 뉴런은 입력 개수만큼 10개의 가중치를 가지고 1개의 출력을 만든다. 합성곱 층의 누런은 3개의 가중치를 가지고 8개의 출력을 만든다.\n",
    "\n",
    "> 합성곱 층의 뉴런에 있는 가중치 개수는 정하기 나름이다. ( 또 다른 하이퍼 파라미터 )\n",
    "\n",
    "> 입력 데이터 위를 이동하면서 같은 도장으로 하나씩 직는 것처럼 생각할 수 있다.\n",
    "\n",
    "> 도장을 찍을 때마다 출력이 하나씩 만들어 진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b58453-3e81-40f0-aeaf-071e16674d8f",
   "metadata": {},
   "source": [
    "> **합성곱 신경망(Convolution neural network , CNN)** 에서는 완전 연결 신경망(밀집층만 이용)과 달리 뉴런을 **필터** 혹은 **커널** 이라고 부른다.\n",
    "\n",
    "> 합성곱의 장점은 1차원이 아니라 2차원 입력에도 적용할 수 있다는 것이다.\n",
    "\n",
    "> 입력이 2차원 배열이면 필터도 2차원이어야한다. 커널의 크기를 (3x3) 으로 가정한다.\n",
    "\n",
    "> 왼쪽 위 모서리에서부터 합성곱을 시작한다. 입력의 9개 원소와 커널의 9개 가중치를 곱한 후 1개의 출력을 만든다.\n",
    "\n",
    "> 필터가 오른쪽으로 한칸 이동하여 합성곱을 또 수행한다. 입력의 너비가 4이므로 더 이상 오른쪽으로 한 칸 이동할 수 없다. 이럴때는 아래로 한 칸 이동한 다음 다시 왼쪽에서부터 합성곱을 수행한다. 그리고 다시 오른쪽으로 한 칸 이동한다.\n",
    "\n",
    "> 계속 왼쪽 위에서 오른쪽 맨 아래까지 이동하면서 출력을 만든다. 계산식은 밀집층과 크게 다르지 않다. 입력과 가중치의 행과 열을 맞추어 곱셈하고 모두 더하는 게 전부다.\n",
    "\n",
    "> 이때 5개의 출력을 필터가 입력에 놓인 위치에 맞게 2차원으로 배치한다. 즉 왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래 모두 4개의 위치에 해당 값을 놓는다. 이렇게 출력을 2차원으로 표현하면 (4,4) 키ㅡ기의 입력을 (2,2) 크기로 압축한 느낌이다.\n",
    "\n",
    "> 합성곱 계산을 통해 얻은 출력을 특별히 **특성 맵(feature map)** 이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab7f5b-0b34-4ca3-af24-5a8dcf92eb7b",
   "metadata": {},
   "source": [
    "> 밀집층에서 여러 개의 누런을 사용하듯이 합성곱 층에서도 여러 개의 필터를 사용한다.\n",
    "\n",
    "> (2,2)크기의 특성 맵을 쌓으면 3차원 배열이 된다.\n",
    "\n",
    "> 밀집층에 있는 뉴런의 가중치가 모두 다르듯이 합성곱 층에 있는 필터의 가중치(커널)도 모두 다르다. $\\to$ 굳이 같은 가중치를 가진 필터를 여러 개 사용할 이유가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426bdca7-ddaf-4f65-9561-278592d14bec",
   "metadata": {},
   "source": [
    "### 합성곱 마무리\n",
    "\n",
    "> 실제 계산은 밀집층과 동일하게 단순히 입력과 가중치를 곱하는 것이지만 2차원 형태를 유지하는 점이 다르다.\n",
    "\n",
    "> 입력보다 훨씬 작은 크기의 커널을 사용하고 입력 위를 (왼쪽 $\\to$ 오른쪽 , 위 $\\to$ 아래) 이동하면서 2차원 특성 맵을 만든다.\n",
    "\n",
    "> 2차원 구조를 사용하기 때문에 합성곱 신경망이 이미지 처리 분야에서 뛰어난 성능을 발휘한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ef78a-e343-4549-812e-65fc24109973",
   "metadata": {},
   "source": [
    "# 케라스 합성곱 층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168cb0e-7e76-4779-bc37-4e4e6d77e295",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dff0d4-28f3-4d54-9fae-bcc00bd7f99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
