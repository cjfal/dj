{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a923d57a-fd2d-4be7-b5c0-a7bae46f2e29",
   "metadata": {},
   "source": [
    "# 혼공머 07-2\n",
    "> 심층 신경망\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: 김동준\n",
    "- categories : [\"Python\", \"혼공머\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3583b2f-f4d0-497d-9d5e-0e2d14a590f4",
   "metadata": {},
   "source": [
    "# 주로쓰는 패키지들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28a1a18-7851-4db5-aad5-43ee750b5055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "import numpy as np #넘파이\n",
    "import pandas as pd #판다스\n",
    "from plotnine import *  #플롯나인\n",
    "import matplotlib.pyplot as plt #맷플랏립\n",
    "import plotly.express as px #플랏리 상호작용 그래프\n",
    "from IPython.display import HTML #블로그에 html로 올리려고 변환하는 패키지\n",
    "import seaborn as sns # 씨본, 히스토그램 깔끔하게 그리는 패키지\n",
    "#___________________________________\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier # k 최근접이웃\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor  # 결정계수 \n",
    "from sklearn.metrics import mean_absolute_error # 타깃과 예측의 절댓값 오차 평균을 반환\n",
    "from sklearn.linear_model import LinearRegression # 선형 회귀\n",
    "from sklearn.preprocessing import PolynomialFeatures #다중회귀로의 변환기\n",
    "from sklearn.preprocessing import StandardScaler #규제\n",
    "from sklearn.linear_model import Ridge #릿지\n",
    "from sklearn.linear_model import Lasso #라쏘\n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱회귀\n",
    "from scipy.special import expit #시그모이드함수\n",
    "from scipy.special import softmax #소프트맥스함수\n",
    "from sklearn.linear_model import SGDClassifier # 확률적 경사 하강법\n",
    "from sklearn.tree import DecisionTreeClassifier # 트리\n",
    "from sklearn.tree import plot_tree # 트리 모형\n",
    "from sklearn.model_selection import cross_validate # 교차 검증\n",
    "from sklearn.model_selection import StratifiedKFold # Kfold 교차 검증\n",
    "from sklearn.model_selection import GridSearchCV # 그리드 서치 (하이퍼 파라미터 튜닝)\n",
    "from scipy.stats import uniform, randint #랜덤 서치\n",
    "from sklearn.model_selection import RandomizedSearchCV # 랜덤 서치 클래스\n",
    "from sklearn.ensemble import RandomForestClassifier # 랜덤포레스트 앙상블\n",
    "from sklearn.ensemble import ExtraTreesClassifier # 엑스트라 트리 앙상블\n",
    "from sklearn.ensemble import GradientBoostingClassifier # 그레이디언트 부스팅 앙상블\n",
    "\n",
    "# 히스토그램 기반 그레이디언트 부스팅\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance # 특성중요도\n",
    "from xgboost import XGBClassifier # 알고리즘을 구현한 또다른 라이브러리1\n",
    "from lightgbm import LGBMClassifier # 알고리즘을 구현한 또다른 라이브러리2 , 마이크로소프트에서 구현 \n",
    "\n",
    "\n",
    "# ____________________\n",
    "from sklearn.cluster import KMeans # KMeans\n",
    "from sklearn.decomposition import PCA # 주성분 분석\n",
    "\n",
    "# 7장 딥러닝\n",
    "from tensorflow import keras # 케라스 \n",
    "import tensorflow as tf # 텐서플로\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfdec63-79ee-405a-a88d-c5b4c6b87735",
   "metadata": {},
   "source": [
    "# 2개의 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef47ec1-5701-48a8-a5c0-18f2eac26d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 API 로 패션 MNIST 데이터셋 로드\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3963d040-ede6-4458-8544-22c55d24f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 이미지의 픽셀값 0~255 범위에서 0~1로 전처리\n",
    "# 2. 28x28 크기의 2차원 배열을 784 크기의 1차원 배열로 펼치기\n",
    "# 3. 훈련세트와 검증세트 나누기\n",
    "\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled = train_scaled.reshape(-1, 28*28)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85991fba-8bc5-4734-a9f1-a89f66d59fe3",
   "metadata": {},
   "source": [
    "## 만든 인공 신경망 모형에 2개의 층 추가\n",
    "\n",
    "> 입력층과 출력층 사이에 밀집층이 추가된 것. $\\to$ 은닉층 이라고 부름.\n",
    "\n",
    "> 은닉층에는 활성화 함수가 있음 (신경망 층의 선형 방정식의 계산 값에 적용하는 함수)\n",
    "\n",
    "> 소프트 맥스 함수도 활성화 함수\n",
    "\n",
    "> 출력층에 적용하는 활성화 함수는 종류가 제한 (이진 분류 : 시그모이드 함수, 다중 분류 : 소프트맥스 함수)\n",
    "\n",
    "> 분류 문제는 클래스에 대한 확률을 출력하기 위해 활성화 함수를 사용, 회귀의 출력은 임의의 어떤 숫자라서 활성화 함수를 적용할 필요가 없음. \\\n",
    "즉, 출력층의 선형 방정식의 계산을 그대로 출력\n",
    "\n",
    "> 은닉층에서 선형적인 산술 계산만 수행한다면 수행 역할이 없는 셈이라서 활성화 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef76626c-00d1-493c-ba87-3fb91aff6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 활성화 함수를 사용한 은닉층과 소프트맥스 함수를 사용한 출력층 만들기\n",
    "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
    "dense2 = keras.layers.Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89928af4-3a94-4f97-9afe-eba6a90f98af",
   "metadata": {},
   "source": [
    "> dense1 이 은닉층이고 100개의 뉴런을 가진 밀집층, sigmoid로 활성화 함수 지정, 출력층의 뉴런보다는 많게 만들어야함.\n",
    "\n",
    "> dense2 : 출력층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28810b68-d217-4f5c-ae18-927a24c38aa8",
   "metadata": {},
   "source": [
    "# 심층 신경망 만들기 (Deep Neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f84b6f-3099-42a4-97fe-032f3bf14580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 심층 신경망 생성\n",
    "model = keras.Sequential([dense1, dense2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e8d08-92c5-4dc5-946c-9be59ed4d668",
   "metadata": {},
   "source": [
    "> 리스트로 전달 해야하며 , 출력층을 가장 마지막에 두어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b1dc336-e94b-4de4-8ca0-b8db6ae26f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 서머리로 유용한 정보 확인 (케라스)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e7754-f0f0-407d-b587-7c6c221023f6",
   "metadata": {},
   "source": [
    "> 모델의 이름이 나오며 , 그 모델에 들어 있는 층이 순서대로 나열 (은닉층에서 출력층의 순서)\n",
    "\n",
    "> 층마다 층 이름, 클래스 ,출력 크기 ,모델 파라미터 개수가 출력\n",
    "\n",
    "> Output Shape : (샘플의 수 , 뉴런의 수)\n",
    "\n",
    "> Total params : 총 모델 파라미터 개수\n",
    "\n",
    "> Trainable params : 훈련되는 파라미터 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc80b3-0e3d-4565-a478-1c56b066851e",
   "metadata": {},
   "source": [
    "# 층을 추가하는 다른 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124fe7f7-07e2-4660-be94-54d34041e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seqeuntial 클래스에 층을 추가하는 다른 방법.(Seqeuntial 클래스의 생성자 안에서 바로 Dense 클래스의 객체를 생성)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
    "    keras.layers.Dense(10, activation='softmax', name='output')\n",
    "], name='패션 MNIST 모델')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46f108-69a2-4e54-b6ef-fb7aad1060c0",
   "metadata": {},
   "source": [
    "> 추가되는 층을 한눈에 쉽게 알아볼 수 있는 장점이 있음.\n",
    "\n",
    "> 층의 이름은 반드시 영문이어야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a459b943-3db8-4355-9bc4-095789e6eb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST 모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6125d8f-39d7-4a75-a27a-56922ab7da47",
   "metadata": {},
   "source": [
    "> 모델 이름과 층이름이 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "912427ea-0971-448f-96ad-3a7da7d18107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 add()메서드로 층 추가하기\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9587f4c5-5d31-47fc-b87f-f2332e4b4877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c33eb0d-c16c-4787-8ec0-4e16622731b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5661 - accuracy: 0.8092\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4068 - accuracy: 0.8532\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3728 - accuracy: 0.8646\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3515 - accuracy: 0.8725\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3335 - accuracy: 0.8782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1298643f10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련 ( compile() 메서드 )\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb99ae56-e6a3-4ed2-921b-a66eb3668973",
   "metadata": {},
   "source": [
    "> 추가된 층이 성능을 향상시켰다는 것을 알 수 있다.\n",
    "\n",
    "> 몇개의 층이 추가되어도 compile() 과 fit() 메서드의 사용법은 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c239b-d0e8-46b3-bc52-8183f3693ca0",
   "metadata": {},
   "source": [
    "# 렐루 함수  (활성화 함수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bea4f3-ae90-46d8-b3eb-811af4f191dc",
   "metadata": {},
   "source": [
    "> 시그모이드 함수는 층이 많을수록 효과가 누적되어 학습을 더 어렵게 만듬\\\n",
    "$\\to$ 해결 : 렐루 함수\\\n",
    "$\\to$ 입력이 양수일 경우 마치 활성화 함수가 없는 것처럼 그냥 입력을 통과 시키고 음수일 경우에는 0으로 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9fdac8e-af63-43fe-a3e7-e23b45d1aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten 층을 입력층 바로 뒤에 추가\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef9c09-a28d-4ded-af54-ee83488a7736",
   "metadata": {},
   "source": [
    "> 첫 번째 Dense 층에 있던 input_shape 매개변수를 Flatten 층으로 옮김\n",
    "\n",
    "> 첫 번째 Dense 층의 활성화 함수를 relu로 바꿈\n",
    "\n",
    "> Flatten 클래스는 학습하는 층이 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "370144c4-1700-470f-8296-cf96af8110f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54902358-db6d-4eef-8300-a86703917f87",
   "metadata": {},
   "source": [
    "> flatten 클래스에 포함된 모델 파라미터는 0개\n",
    "\n",
    "> 케라스dml flatten 층을 신경망 모형에 추가하면 입력값의 차원을 짐작할 수 있다.\n",
    "\n",
    "> 784개의 입력이 첫 번째 은닉층에 전달되었다.\n",
    "\n",
    "> 입력 데이터에 대한 전처리 과정을 가능한 모델에 포함 시킨다. : 케라스 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca6fabd0-6af5-469e-9fff-115b514e7320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 모델 훈련\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_scaled = train_input / 255.0\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0de8d0d-1e56-457c-a216-2d2767d81203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5315 - accuracy: 0.8127\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3930 - accuracy: 0.8584\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3572 - accuracy: 0.8723\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3345 - accuracy: 0.8813\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3215 - accuracy: 0.8850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f12983d73a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14ac4ce-fa75-4547-bd6b-30f9093a58d2",
   "metadata": {},
   "source": [
    "> 시그모이드 함수를 사용했을 때와 비교하면 성능이 조금 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "409e0562-5c70-4a73-8edc-711a597a7a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 897us/step - loss: 0.3641 - accuracy: 0.8789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36406102776527405, 0.8789166808128357]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증 세트에서의 성능도 확인\n",
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675d3fb-d73a-4c5d-aee8-8483f4ea8548",
   "metadata": {},
   "source": [
    "> 은닉층을 추가하지 않은 경우보다 몇 퍼센트 성능이 향상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e804c-d0cc-4297-9aae-41cde3df5c80",
   "metadata": {},
   "source": [
    "# 옵티마이저\n",
    "\n",
    "> 은닉층의 뉴런 개수도 하이퍼 파라미터이다.\n",
    "\n",
    "> 층의 종류도 하이퍼 파라미터 이다.\n",
    "\n",
    "> 옵티마이저 : 케라스에서 제공하는 다양한 경사 하강법 알고리즘\n",
    "\n",
    "> RMSprop의 학습률 또한 하이터 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb9740-3230-4ecc-a654-5a6305842900",
   "metadata": {},
   "source": [
    "## 가장 기본적인 옵티마이저 : 확률적 경사 하강법 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e869529c-1364-412f-9157-c9ebebc484fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "130a3cf7-1ffd-4d19-81eb-0e51b3dd06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD()\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "685c740b-c409-4bc4-a613-d5c994a0d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 변경\n",
    "sgd = keras.optimizers.SGD(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf78ed-5edd-4c34-902b-5462cebe16d3",
   "metadata": {},
   "source": [
    "## 모멘텀 최적화\n",
    "\n",
    "> 그레이디언트를 가속도처럼 사용\n",
    "\n",
    "> SGD 클래스의 nesterov 매개변수를 기본값 False에서 True로 바꾸면 네스테로프 모멘텀 최적화 를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0b3d3b7-1926-42ab-b0d2-51e33533ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c2942-016e-48f7-8995-dc1696caf26d",
   "metadata": {},
   "source": [
    "## 적응적 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "152d9b12-b64a-4897-b2bb-010aee62d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "adagrad = keras.optimizers.Adagrad()\n",
    "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "340959a2-021f-4901-93f7-84749947f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop()\n",
    "model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba99917a-6eca-488b-913d-a86b25a32858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam 클래스의 매개변수 기본값을 사용해 패션  MNIST 모델훈련\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e2ad315-cfb1-442f-a0ac-a776f2da4ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5299 - accuracy: 0.8139\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3942 - accuracy: 0.8590\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 974us/step - loss: 0.3546 - accuracy: 0.8698\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 990us/step - loss: 0.3245 - accuracy: 0.8810\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 984us/step - loss: 0.3063 - accuracy: 0.8852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f129cb65e80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile() 메서드의 optimizer를 adam 으로 설정하고 5번의 에포크 동안 훈련\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca9abb74-ce6f-4d5e-bc67-e3bece5f9d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 729us/step - loss: 0.3352 - accuracy: 0.8794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3352320194244385, 0.8794166445732117]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증 세트 성능 확인\n",
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a843d22-7df3-48ee-b792-3ebc9499eaba",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af9833-bb64-4a3a-ad33-507d6079fa54",
   "metadata": {},
   "source": [
    "# **마무리**\n",
    "\n",
    "`*` 키워드로 끝내는 핵심 포인트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed977f3-1698-4394-a818-97a19f4494ba",
   "metadata": {},
   "source": [
    "`-` **심층 신경망** : 2개 이상의 층을 포함한 신경망입니다. 종종 다층 인공 신경망, 심층 신경망, 딥러닝을 같은 의미로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2936ffae-aa86-41ac-aa20-63a6ae8d2b98",
   "metadata": {},
   "source": [
    "`-` **렐루 함수** : 이미지 분류 모델의 은닉층에 많이 사용하는 활성화 함수입니다. 시그모이드 함수는 층이 많을수록 활성화 함수의 양쪽 끝에서 변화가 작기 때문에 학습이 어려워집니다. 렐루함수는 이런 문제가 없으며 계산도 간단합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66587475-9c52-4b29-8797-bb6d0060dd45",
   "metadata": {},
   "source": [
    "`-` **옵티마이저** : 신경망의 가중치와 절편을 학습하기 위한 알고리즘 또는 방법을 말합니다. 케라스에는 다양한 경사 하강법 알고리즘이 구현되어 있습니다. 대표적으로 SGD, 네스테로프 모멘텀, RMSprop, Adam 등이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60678087-9ca6-4ce4-8b63-c7be29a425b6",
   "metadata": {},
   "source": [
    "`-` **핵심 패키지**\n",
    "\n",
    "`-` TensorFlow\n",
    "\n",
    "> `1` add() : 케라스 모델에 층을 추가하는 메서드입니다.\n",
    "\n",
    ">>케라스 모델의 add() 메서드는 keras.layers 패키지 아래에 있는 층의 객체를 입력받아 신경망 모델에 추가합니다. add() 메서드를 호출하여 전달한 순서대로 층이 차례대로 늘어납니다.\n",
    "\n",
    "\n",
    "> `2` summary () : 케라스 모델의 정보를 출력하는 메서드입니다.\n",
    "\n",
    ">>모델에 추가된 층의 종류와 순서, 모델 파라미터 개수를 출력합니다. 층을 만들 때 name 매개변수로 이름을 지정하면 summary() 메서드 출력에서 구분하기 쉽습니다.\n",
    "\n",
    ">>percentiles 매개변수에서 백분위수를 지정합니다. 기본값은 [0.25, 0.5, 0.75]입니다.\n",
    "\n",
    "\n",
    "> `3` SGD : 기본 경사 하강법 옵티마이저 클래스입니다.\n",
    "\n",
    ">>learning_rate 매개변수로 학습률을 지정하며 기본값은 0.01입니다\n",
    "\n",
    ">>momentum 매개변수에 이 이상의 값을 지정하면 모멘텀 최적화를 수행합니다.\n",
    "\n",
    ">>nesteroy 매개변수를 True로 설정하면 네스테로프 모멘텀 최적화를 수행합니다.\n",
    "\n",
    "\n",
    "> `4` Adagrad : Adagrad 옵티마이저 클래스입니다.\n",
    "\n",
    ">>learning_rate 매개변수로 학습률을 지정하며 기본값은 0.001입니다. learning_rate 매개변수로 학습률을 지정하며 기본값은 0.001입니다. learning_rate 매개변수로 학습률을 지정하며 기본값은 0.001입니다.\n",
    "\n",
    ">>Adagrad는 그레이디언트 제곱을 누적하여 학습률을 나눕니다. initial accumulator Value 매개변수에서 누적 초깃값을 지정할 수 있으며 기본값은 0.1입니다.\n",
    "\n",
    "\n",
    "> `5` RMSprop : RMSprop 옵티마이저 클래스입니다.\n",
    "\n",
    ">>Adagrad처럼 그레이디언트 제곱으로 학습률을 나누지만 최근의 그레이디언트를 사용하기 위해 지수 감소를 사용합니다. rho 매개변수에서 감소 비율을 지정하며 기본값은 0.9입니다.\n",
    "\n",
    "\n",
    "> `6` Adam : Adam 옵티마이저 클래스입니다.\n",
    "\n",
    ">>모멘텀 최적화에 있는 그레이디언트의 지수 감소 평균을 조절하기 위해 beta 1 매개변수가 있으며 기본값은 0.9 입니다.\n",
    "\n",
    ">>RMSprop에 있는 그레이디언트 제곱의 지수 감소 평균을 조절하기 위해 beta 2 매개변수가 있으며 기본값은 0.999입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f2924-2681-4dd5-81a1-5823e0e3ecdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
