{
  
    
        "post0": {
            "title": "회귀분석 5장",
            "content": "5.2 . - 어떤 화학반응에서 촉매의 양(x)이 합성물의 소득량(y)에 어떻게 영향을 끼치는지 알아보기 위해 12번 실험하여 다음의 자료를 얻었다. . x(g) 1 1 1 2 2 2 4 4 4 8 8 8 . y(g) | 13.5 | 15.4 | 16.1 | 18.2 | 19.6 | 20.2 | 21.8 | 22.2 | 23.1 | 23.6 | 24.7 | 24.9 | . x &lt;- c(1,1,1,2,2,2,4,4,4,8,8,8) y &lt;- c(13.5,15.4,16.1,18.2,19.6,20.2,21.8,22.2,23.1,23.6,24.7,24.9) . 1) x&#50640;&#45824;&#54620; y&#51032; &#49328;&#51216;&#46020;&#47484; &#44536;&#47140;&#46972;. . plot(x,y,col=&quot;red&quot;) . 2) $ log_{10} x$&#47484; &#44228;&#49328;&#54616;&#44256; $ log_{10} x$&#50640; &#45824;&#54620; y&#44050;&#51032; &#49328;&#51216;&#46020;&#47484; &#44536;&#47140;&#46972;. . logx &lt;- log(x,base=10) logx . &lt;ol class=list-inline&gt;0 | 0 | 0 | 0.301029995663981 | 0.301029995663981 | 0.301029995663981 | 0.602059991327962 | 0.602059991327962 | 0.602059991327962 | 0.903089986991944 | 0.903089986991944 | 0.903089986991944 | &lt;/ol&gt; plot(logx,y,col=&quot;blue&quot;) . par(mfrow=c(1,2)) plot(x,y,col=&quot;red&quot;) plot(logx,y,col=&quot;blue&quot;,xlim=c(0,8)) # xlim 으로 x범위 조정 . 3) &#50948; 1)&#44284; 2) &#51473; &#50612;&#45712; &#44163;&#51060; &#45908; &#49440;&#54805;&#50640; &#44032;&#44620;&#50868;&#44032;? . 2)의 로그 그래프가 같은 범위에서 더 선형에 가깝다. . . 5.3 . - 연습문제 5.2의 자료에 대해 다음 질문에 답하여라. . 1) $ y = beta_0 + beta_1 x + epsilon $ &#47484; &#51201;&#54633;&#49884;&#53412;&#44256; $MSE$ &#47484; &#44396;&#54616;&#50668;&#46972;. . lm53 &lt;- lm(y~x) coefficients(lm53) . &lt;dl class=dl-inline&gt;(Intercept)15.8130434782609x1.18985507246377&lt;/dl&gt; $y= 15.51 + 1.19x$ . anova(lm53) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x 1 | 122.10888 | 122.108877 | 34.1147 | 0.0001636405 | . Residuals10 | 35.79362 | 3.579362 | NA | NA | . $MSE$ :Mean Square Residuals = 3.579362 . 2) $ y = beta_0 + beta_1 log_{10} x + epsilon $ &#47484; &#44032;&#51221;&#54616;&#44256; $MSE$ &#47484; &#44228;&#49328;&#54616;&#50668;&#46972;. . lm53log &lt;- lm(y~logx) anova(lm53log) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . logx 1 | 146.32817 | 146.328167 | 126.4247 | 5.374543e-07 | . Residuals10 | 11.57433 | 1.157433 | NA | NA | . $MSE$ :Mean Square Residuals = 1.157433 . 3) &#50948; 1)&#44284; 2)&#51032; &#47784;&#54805; &#51473; &#50612;&#45712; &#44163;&#51060; &#45908; &#51201;&#54633;&#54620;&#51648; $MSE$ &#47484; &#51060;&#50857;&#54616;&#50668; &#48708;&#44368;&#54616;&#50668;&#46972;. . $ log_{10} x$ 에서의 $MSE$ 가 더 작다. 즉, 2)의 모형이 더 적합하다. . . 5.12 . - 다음 과 같은 자료에 대하여 . x 2 6 10 . y | 4 | 7 | 4 | . 1) &#45800;&#49692;&#54924;&#44480;&#47784;&#54805; $ y = beta_0 + beta_1 x + epsilon $ , $ epsilon sim N(0, sigma^2)$&#51012; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#51649;&#49440;&#51012; &#52628;&#51221;&#54616;&#50668;&#46972;. &#46608; $ beta_1$ &#51032; 90% &#49888;&#47280;&#44396;&#44036;&#51012; &#44396;&#54616;&#50668;&#46972;. . x &lt;- c(2, 6, 10) y &lt;- c(4, 7, 4) lm512 &lt;- lm(y~x) coefficients(lm512) confint(lm512,level = 0.90) # 기울기와 절편의 90% 신뢰구간 . &lt;dl class=dl-inline&gt;(Intercept)5x-4.81432375190295e-16&lt;/dl&gt; A matrix: 2 × 2 of type dbl 5 %95 % . (Intercept)-13.676329 | 23.676329 | . x -2.733935 | 2.733935 | . 기울기 $ beta_1$의 90% 신뢰구간:$(-2.733935, 2.733935)$ . 2) $ y = beta_0 + beta_1 x + epsilon $ , $ epsilon sim N(0,k^2 {x_i}^2)$ &#51012; &#44032;&#51221;&#54616;&#50668; &#44032;&#51473;&#54924;&#44480;&#51649;&#49440;&#51012; &#52628;&#51221;&#54616;&#44256; $ beta_1$ &#51032; 90% &#49888;&#47280;&#44396;&#44036;&#51012; &#44396;&#54616;&#50668;&#46972;. . w512 &lt;- sqrt(1/var(x)) . 3) &#50948; 1), 2)&#51032; &#44208;&#44284;&#47484; &#48708;&#44368;&#54616;&#50668;&#46972; . . 5.14 . - 다음은 어떤 컴퓨터 부품의 과거 14개월(x) 동안의 판매액(y)에 관한 자료이다. . x 1 2 3 4 5 6 7 8 9 10 11 12 13 14 . y | 6.0 | 6.3 | 6.1 | 6.8 | 7.5 | 8.0 | 8.1 | 8.5 | 9.0 | 8.7 | 7.9 | 8.2 | 8.4 | 9.0 | . 1) &#45936;&#51060;&#53552;&#51032; &#49328;&#51216;&#46020;&#47484; &#44536;&#47140;&#46972;. . x &lt;- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14) y &lt;- c(6.0,6.3,6.1,6.8,7.5,8.0,8.1,8.5,9.0,8.7,7.9,8.2,8.4,9.0) plot(x,y) . 2) &#45800;&#49692;&#54924;&#44480;&#47784;&#54805;&#51012; &#44032;&#51221;&#54616;&#44256; &#51092;&#52264;&#51032; &#49328;&#51216;&#46020;&#47484; &#45208;&#53440;&#45236;&#44256; &#51088;&#44592;&#49345;&#44288;&#51060; &#51316;&#51116;&#54616;&#45716;&#51648;&#47484; &#44160;&#53664;&#54616;&#50668;&#46972;. . lm514 &lt;- lm(y~x) coefficients(lm514) . &lt;dl class=dl-inline&gt;(Intercept)6.13296703296704x0.215604395604395&lt;/dl&gt; err &lt;- function(A){ print(0.215604395604395 * A + 6.13296703296704) } . plot(err(x)-y) . [1] 6.348571 6.564176 6.779780 6.995385 7.210989 7.426593 7.642198 7.857802 [9] 8.073407 8.289011 8.504615 8.720220 8.935824 9.151429 . 3) Durbin-Watson d &#53685;&#44228;&#47049;&#51032; &#44050;&#51012; &#44396;&#54616;&#50668; $H_0 : rho = 0 , H_1 : rho neq 0 $ &#51012; $ alpha = 0.05 $ &#47196; &#44160;&#51221;&#54616;&#50668;&#46972;. . 4) &#50948; 3)&#51032; &#44160;&#51221;&#44208;&#44284;&#45716; 2)&#51032; &#49328;&#51216;&#46020;&#50640;&#49436; &#50619;&#51008; &#45712;&#45196;&#44284; &#51068;&#52824;&#54616;&#45716;&#51648; &#45436;&#51032;&#54616;&#50668;&#46972;. .",
            "url": "https://cjfal.github.io/dj/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2022/01/03/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D5%EC%9E%A5.html",
            "relUrl": "/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2022/01/03/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D5%EC%9E%A5.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "회귀분석3장연습문제2",
            "content": "# 회귀분석 3장 연습문제 뒷부분 .",
            "url": "https://cjfal.github.io/dj/2022/01/03/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D3%EC%9E%A5%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C2.html",
            "relUrl": "/2022/01/03/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D3%EC%9E%A5%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C2.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "회귀분석 3장 연습문제1",
            "content": "3.3) &#50612;&#45712; &#51613;&#44428;&#54924;&#49324;&#50640;&#49436;&#51032; &#51452;&#44032;x&#50752; &#51333;&#54633;&#51452;&#44032;&#51648;&#49688;y &#48516;&#49437; . Base . x &lt;- c(650, 670, 690, 650, 660, 650, 670, 660, 690, 710) y &lt;- c(210, 212, 217, 215, 216, 214, 220, 218, 220, 224) lm33 &lt;- lm(y~x) . 1) &#54364;&#48376;&#49345;&#44288;&#44228;&#49688; &#44396;&#54616;&#44592; . cor(x,y) . 0.757203385853764 2) &#45800;&#49692;&#54924;&#44480;&#49440; &#52628;&#51221;, &#49328;&#51216;&#46020; . plot(y~x) abline(lm(y~x),col=&quot;red&quot;) . 3) MSE &#44228;&#49328; &#48143; &#49328;&#51216;&#46020;&#50752; &#48708;&#44368; . anova(lm33) summary(lm33) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x1 | 88.52632 | 88.526316 | 10.75104 | 0.01120658 | . Residuals8 | 65.87368 | 8.234211 | NA | NA | . Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -4.6000 -1.9026 0.6895 1.4132 3.4000 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 114.33684 31.20166 3.664 0.00636 ** x 0.15263 0.04655 3.279 0.01121 * Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 2.87 on 8 degrees of freedom Multiple R-squared: 0.5734, Adjusted R-squared: 0.52 F-statistic: 10.75 on 1 and 8 DF, p-value: 0.01121 . 4) &#51092;&#52264;&#47484; &#44396;&#54616;&#44256; &#54633;&#51060; 0&#51060; &#46104;&#45716; &#44163;&#51012; &#54869;&#51064; . lm33$residuals . &lt;dl class=dl-inline&gt;1-3.54736842105262-4.63-2.6526315789473741.4526315789473650.92631578947367760.45263157894735973.482.9263157894736890.347368421052632101.29473684210527&lt;/dl&gt; -3.5473684-4.6000000-2.6526316+1.4526316+0.9263158+0.4526316+3.4000000+2.9263158+0.3473684+1.2947368 . 8.88178419700125e-16 sum(lm33$residuals) . 1.55431223447522e-15 $ to$ 둘다 0에 수렴하는 값 . 5) &#51092;&#52264;&#46308;&#51032; x&#50640; &#51032;&#54620; &#44032;&#51473;&#54633;&#51060; 0&#51060; &#46120;&#51012; &#48372;&#51060;&#44592; . res33 &lt;- lm33$residuals x*res33 . &lt;dl class=dl-inline&gt;1-2305.789473684192-30823-1830.315789473684944.2105263157835611.3684210526276294.2105263157847227881931.368421052639239.68421052631610919.26315789474&lt;/dl&gt; -2305.7895 -3082.0000 -1830.3158+944.2105+611.3684+294.2105+2278.0000+ 1931.3684 +239.6842 + 919.2632 . -9.99999995201506e-05 sum(x*res33) . -4.54747350886464e-13 $ to$ 둘다 0에 수렴하는 값 . 6) &#51092;&#52264;&#46308;&#51032; yhat&#50640; &#51032;&#54620; &#44032;&#51473;&#54633;&#51060; 0&#51060; &#46120;&#51012; &#48372;&#51060;&#44592; . res33*0.15263+(res33*(114.33684*x)) . &lt;dl class=dl-inline&gt;1-263637.2235611552-352386.8429783-209272.9284416844107958.269588841569902.0747225258633639.17095884147260459.8404628220827.008782526927404.788248315810105105.84221779&lt;/dl&gt; -263637.22 -352386.84 -209272.93 + 107958.27 + 69902.07 + 33639.17 +260459.84 + 220827.01 + 27404.79+ 105105.84 . 1.16415321826935e-10 sum(res33*0.15263+(res33*(114.33684*x)) ) . 4.36557456851006e-11 $ to$ 둘다 0에 수렴하는 값 . . 3.5) &#50612;&#46500; &#52980;&#54504;&#53552;&#54924;&#49324;&#51032; &#49436;&#48708;&#49828; &#50836;&#44396;&#44148;&#49688;&#50752; &#49688;&#47532;&#49884;&#44036; &#48516;&#49437; . Base . library(ggplot2) x &lt;- c(4,2,5,7,1,3,4,5,2,4,6) y &lt;- c(109,58,138,189,37,82,103,134,68,112,154) lm35 &lt;- lm(y~x) . 1) &#49328;&#51216;&#46020; &#44536;&#47532;&#44592; . plot(y~x) abline(lm35,col=&quot;red&quot;) . 2) 1&#52264;&#49440;&#54805;&#54924;&#44480;&#49440;&#51012; &#44032;&#51221;&#54616;&#44256; &#52572;&#49548;&#51228;&#44273;&#52628;&#51221;&#47049; b0&#50752; b1&#44396;&#54616;&#44592; . coef(lm35) # b0(절편,intercept), b1(기울기,x) . &lt;dl class=dl-inline&gt;(Intercept)11.46408839779x24.6022099447514&lt;/dl&gt; xbar &lt;- mean(x) ybar &lt;- mean(y) minusx &lt;- x-xbar minusy &lt;- y-ybar . Sxx &lt;- sum(minusx^2) Sxx . 32.9090909090909 Syy &lt;- sum(minusy^2) Syy . 20110.5454545455 Sxy &lt;- sum(minusx*minusy) Sxy . 809.636363636364 b1 &lt;- Sxy/Sxx b1 . 24.6022099447514 b0 &lt;- ybar - b1*xbar b0 . 11.4640883977901 3) &#52628;&#51221;&#52824; b1&#51032; &#51032;&#48120;&#47484; &#49444;&#47749;&#54616;&#50668;&#46972; . 기울기 . 4) &#49436;&#48708;&#49828; &#49688;&#44032; 4&#51068; &#46412; &#49688;&#47532;&#49884;&#44036; &#52628;&#51221;, &#52628;&#51221;&#44050;&#51032; &#51032;&#48120; . 적합된 회귀선으로 추정한 x=4 일때의 y의 예측(추정) 값 . yhat=b0+b1x . b0+b1*4 . 109.872928176796 5) &#49328;&#51221;&#46020; &#50948;&#50640; &#52628;&#51221;&#46108; &#54924;&#44480;&#51649;&#49440; &#46020;&#49884;&#54616;&#44256; &#51092;&#52264;&#54364;&#49884; . library(ggplot2) library(modelr) . df &lt;- data.frame(x,y) df . A data.frame: 11 × 2 xy . &lt;dbl&gt;&lt;dbl&gt; . 4 | 109 | . 2 | 58 | . 5 | 138 | . 7 | 189 | . 1 | 37 | . 3 | 82 | . 4 | 103 | . 5 | 134 | . 2 | 68 | . 4 | 112 | . 6 | 154 | . 103-109.86 . -6.86 ggplot(df, aes(x=x, y=y)) + geom_point() + stat_smooth(method=&#39;lm&#39;) + geom_text(x=1,y=37,label=&quot;0.94&quot;)+ geom_text(x=2,y=58,label=&quot;-2.66&quot;)+ geom_text(x=2,y=68,label=&quot;7.34&quot;)+ geom_text(x=3,y=82,label=&quot;-3.26&quot;)+ geom_text(x=4,y=103,label=&quot;-6.86&quot;)+ geom_text(x=4,y=109,label=&quot;-0.86&quot;)+ geom_text(x=4,y=112,label=&quot;2.14&quot;)+ geom_text(x=5,y=134,label=&quot;-0.46&quot;)+ geom_text(x=5,y=138,label=&quot;3.54&quot;)+ geom_text(x=6,y=154,label=&quot;-5.06&quot;)+ geom_text(x=7,y=189,label=&quot;5.34&quot;) . `geom_smooth()` using formula &#39;y ~ x&#39; . 6) &#49345;&#44288;&#44228;&#49688; &#44396;&#54616;&#44592; . cor(x,y) . 0.995222389856898 . 3.9) &#50612;&#45712; &#54617;&#44553;&#51032; &#49884;&#54744;&#51216;&#49688;y&#50752; &#44208;&#49437;&#51068;&#49688;x &#49324;&#51060;&#51032; &#44288;&#44228; . n=50 . $ sum_{}^{} x_i$ = 18 . $ sum_{}^{} y_i$ = 3000 . $ sum_{}^{} xy$ = 8800 . $ sum_{}^{} x^2$ = 680 . $ sum_{}^{} y_i^2$ = 196000 . 1) &#49884;&#54744;&#51216;&#49688;&#50752; &#44208;&#49437;&#51068;&#49688; &#49324;&#51060;&#51032; &#54364;&#48376;&#49345;&#44288;&#44228;&#49688;&#47484; &#44396;&#54616;&#50668;&#46972; . 표본상관계수 :$r_xy = frac{S_(xy)}{S_x S_y} = 157.551/(3.7075 * 18.07)=2.3517 $ . $S_xy = frac{1}{n-1} { sum_{}^{} xy - frac{ sum_{}^{} x sum_{}^{} y}{n} } =157.551$ . $S_x = sqrt{ frac{1}{n-1} { sum_{}^{} x^2 - frac{ sum_{}^{} x^2}{n} }} = 3.7075$ . $S_y = sqrt{ frac{1}{n-1} { sum_{}^{} y^2 - frac{ sum_{}^{} y^2}{n} }} = 18.07$ . 2) &#45824;&#52404;&#47784;&#54805; &#54924;&#44480;&#49440;&#50640;&#49436; beta_0 &#44284; beta_1 &#51032; &#52572;&#49548;&#51228;&#44273;&#52628;&#51221;&#47049;&#51012; &#44396;&#54644;&#46972; . 정규방정식 . $b_0n + b_1 sum_{}^{} x_i = sum_{}^{} y_i$ . $b_0 sum_{}^{} x_i + b_1 sum_{}^{} x_i^2 = sum_{}^{} x_i y_i$ . 50$b_0$+18$b_1$=3000 . 18$b_0$+680$b_1$=8800 이고, 연립방정식을 풀면 . $b_0$ = 55.87 , $b_1$ = 11.46 이다. . 3) &#44208;&#49437;&#51012; 3&#48264;&#54620; &#54617;&#49373;&#50640; &#45824;&#54620; &#54217;&#44512;&#49457;&#51201;&#51032; &#52628;&#51221;&#47049;&#51012; &#44228;&#49328;&#54616;&#50668;&#46972;. . $ hat{y} = b_0 + b_1x to hat{y} = 55.87 + 11.46 * 3 = 90.25$ . 4) &#50724;&#52264;&#54637; $ epsilon$ &#51032; &#54364;&#51456;&#54200;&#52264; $ sigma$ &#47484; &#44396;&#54616;&#50668;&#46972; . $SSE= sum_{}^{} y_i^2 - b_0 sum_{}^{} y_i - b_1 sum_{}^{} xy =196000-55.87×3000-11.46×8800 = -72458$ . $ sigma = MSE = frac{SSE}{n-2} = -1510$ .",
            "url": "https://cjfal.github.io/dj/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2022/01/03/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D3%EC%9E%A5%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C1.html",
            "relUrl": "/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2022/01/03/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D3%EC%9E%A5%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C1.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "한솔제지 자소서",
            "content": "자기 자신을 진솔하게 소개하여 주시기 바랍니다. (자신의 성격/취미/가치관) (최대 800자 입력가능) . [성실함에서 오는 꼼꼼함] . 저에게는 어려서부터 지키고 있는 자신과의 약속이 있습니다. 바로 정해진 시간에 절대 늦지 않는다는 약속입니다. 시간을 지키지 않으면 나뿐만 아니라 다른 사람에게까지 해가 될 수 있기에 이런 다짐을 했었습니다. 이 약속은 자연스레 미리미리 준비하는 습관과 미루지 않는 습관이 몸에 배이게 했습니다. 학창시절에는 반에서 항상 1등으로 등교하여 문을 열어 두었고, 선생님들께는 성실한 학생으로 인식에 남게 되었습니다. 그런 인식을 바탕으로 학급에서 반 노트북관리, 출입 열쇠와 출석부 관리 등 꼼꼼함이 중요한 직책들이 저에게 주어지곤 했습니다. 대학에서는 좋은 성적과 평소 쌓아놓은 성실한 이미지를 바탕으로 학과사무실 근로장학생으로 선발되기도 했습니다. 비단 성실하기만 한 것이 아니었습니다. 대학교에서는 1학년을 좋은 성적으로 마무리 한 뒤 1종장학금을 받고 전과에 성공하였고, 대학교 4학년 전부 전액 장학금에 더불 어 성적을 중요하게 보는 기숙사 지원에 전부 합격하는 등 꼼꼼함을 바탕으로 원하는 목표를 이룰 수 있었습니다. 연구직과 개발직은 특히 꼼꼼함과 섬세함이 중요하다고 생각하며 저와 어울리는 직무라고 생각합니다. . | . 지금까지 살아오면서 스스로 생각하기에 가장 큰 성공사례와 실패사례를 소개해 주세요. (최대 800자 입력가능) | . [6번의 탈락] . 대학 입시 시절, 수시 논술 전형에 6군데를 지원 했었습니다. 그러나 6개의 전형 모두 떨어지게 되었습니다. 어렸을 때 단기간에 걸쳐 한번에 겪은 실패의 경험이었습니다. 하지만 저는 이런 낙마에 굴하지 않았고, 긍정적으로 내가 할 수 있는 최선이 무엇인가에 대하여 찾았습니다. 바로 앞에 있는 나무와 같은 대입에 연연하지 않고, 미래 지향적으로 넓게 숲을 보며 진정으로 하고 싶은 일이 무엇인지 생각할 수 있게 만드는 좋은 배경이 되었습니다. . [꿈을 향한 전과의 성공] . 당시 유행하고 있던 탄소 섬유에 관심을 가져 섬유관련 학과에 입학했었습니다. 대학에 진학하여 섬유에 관련한 공부를 진행하다 보니, 특수한 하나의 타이틀에 집중하여 공부하는 것 보다는 전반적인 화학 공정을 공부하고 싶다는 생각을 했습니다. 다행히 1학년의 성적은 굉장히 우수했고, 전과를 위한 베이스는 충분했습니다. 이에 따라 저는 화학관련 공정을 전반적으로 다루는 학과인 화학공학과에 전과를 할 수 있었습니다. 특히 에너지 및 환경 관련 분야에 관심을 가져 에너지 관련 화학공학과로 들어갔습니다. 전과 후 생활은 성공적이었습니다. 새로운 사람에 대한 두려움이 있었지만, 적극적인 사교활동을 통해 스터디 그룹을 형성했고, 자칫 놓칠 수 있었던 부분을 함께 협력하여 새로운 과 생활을 순조롭게 진행할 수 있었습니다. . | . 팀 단위의 과제 혹은 프로젝트 활동 경험을 하나만 선택하여 자세하게 소개해주세요. (최대 800자 입력가능) | . [어플을 제작하다!] . 캡스톤 디자인 과목 프로젝트에서 전공과는 다소 거리가 먼 고창군 ‘책마을 해리’ 활성화 프로젝트를 진행했습니다. 모든 조원이 공대로 이루어진 팀으로 친숙하지 않은 인문학적인 프로젝트를 진행해야 했습니다. 하지만 저희 조는 인문학적인 프로젝트에 공학적 소스를 감미하여 프로젝트를 진행하기로 했습니다. 책마을에 없기도 하고, 고질적인 문제인 접근성을 조금이라도 해결하기 위하여 어플리케이션 제작이라는 프로젝트를 선정했습니다. 하지만 다뤄본 언어는 R과 파이썬 뿐이었는데, 어플리케이션을 노베이스에서 만들기 위해서는 자바 html 및 DB구축 능력이 필요했습니다. 하지만 짧은 기간안에 완성시켜야하는 프로젝트 였기에 이런 언어를 새로 배우기에는 촉박했습니다. 그래서 시중에 나와있는 어플 제작 프로그램을 활용하기로 했습니다. 조금의 알고리즘에 대한 이해와 오피스 활용 능력이 있으면 누구나 어플을 만들 수 있었습니다. 그래도 처음 다루는 프로그램이라서 적응이 필요하고, 디자인과 인앱 편의성이 중요하다고 생각했습니다. 팀원들과 최대한 머리를 맞대고 어플 구성에 대해서 토론을 한 결과, 단기간에 프로그램을 익혀 ‘책마을 해리’ 데모 버전 어플을 만드는 데 성공했습니다. 비록 테스트 어플이었지만, 책마을 해리의 촌장님과 담당 교수님도 아이디어를 굉장히 좋게 생각하여 어플 제작 관련 사업을 시작한다고 들었습니다. . | . 창의성을 발휘한 경험을 자세하게 소개해 주세요. (최대 800자 입력가능) | . [예비군 훈련에 큰 기여를 하다.] . 저는 예비군 훈련 조교로서 민간인 민원을 통해 포상 휴가를 수상한 적이 있습니다. 저의 복무지는 서울 서초구에 있는 예비군 훈련장이었습니다. 주된 업무는 물론 예비군 훈련이었는데, 저는 꼼꼼함을 바탕으로 가장 중요하다고 할 수 있는 예비군들의 입소 및 퇴소 절차를 맡았습니다. 상황은 예비군훈련에 성과제도가 처음으로 도입되었을 때 생겼습니다. 우리 부대는 평소에 하던 진부한 예비군훈련이 아닌, 참여율을 높이기 위한 훈련을 진행했습니다. 이에 따라 훈련 현황을 확인할 수 있는 화면이 필요했습니다. 다른 대대에서 사용하던 엑셀 시트가 있었지만 그 시트는 현재 훈련 적용에 활용할 수 없었습니다. 그래서 새로운 차트를 만들어야만 했는데, 그 당시는 핸드폰도 인터넷도 되지않았으며, 오피스를 잘 다룰 수 있는 인재도 없었습니다. 이런 이유로 인해 평소 자신이 있었던, 차트구성에 도전을 해봤습니다. 훈련에서 필요한 정보와 시각화 해야하는 목록을 확인한 후 엑셀을 이용하여 모두가 편하게 확인할 수 있는 데이터표를 작성했습니다. 가시적으로 잘 나타난 표에 대해서 동원과장님과 대대장님 모두 호의를 표하셨고, 계속해서 관리를 하라고 하셨습니다. 이 과정에서 예비군 대원들에게도 친절한 설명과 더불어 지속적인 업데이트로 1주일 간의 훈련을 성공적으로 마무리 했습니다. 이를 통해 예비군들의 칭찬 민원과 대대장님의 선정을 통해 포상휴가를 수상하여 공익에 기여를 했다는 것에 큰 의의와 자부심을 두고 있습니다. . | . 우리 회사를 지원한 동기와 희망직무에 대하여 준비해 온 것을 기술하여 주시기 바랍니다. (최대 800자 입력가능) | . [분석자로서의 능력 향상] . 저는 전반적인 지구 환경 해결에 관심을 가지고 있습니다. 2020년 코로나19가 대두되기 시작했을 때부터 환경에 대해 더욱 관심을 가지기 시작했습니다. 이런 관심에 맞춰 고분자공학 수업에서 시행한 설계 프로젝트에서 마스크의 업사이클링 및 리사이클에 대해 발표를 진행하기도 했습니다. 이와 같은 단순한 조사 과정에서도 자료의 분석과 통계가 중요하다고 생각하였고, 연구 및 개발을 위해서는 더 전문적인 분석능력과 통계적 테크닉이 필요하다고 느꼈습니다. 그래서 부전공으로 통계학과를 선택하여 통계학의 가장 기초적인 부분부터 공부를 시작했습니다. 저는 공학적 지식에 더불어 이를 활용할 수 있는 MATLAB 프로그램 뿐만 아니라, 부전공을 통한 통계 분석과 통계 프로그램 활용이 가능합니다. 4차산업시대에 발 맞춰 데이터를 활용한 연구에서 도움이 될 수 있을 뿐만 아니라 시각적인 결과물 정리도 도움이 될 것 같습니다. 현재 한솔에서도 그린경영이라는 타이틀을 앞세워 환경 문제 해결에 적극적인 활동을 진행하고 있는 것으로 알고 있습니다. 저의 관심분야에 딱 맞는 기업이라고 생각하여 한솔에 입사해서는 친환경 재생지 분야와 탄소 배출량 감소 부분에 더 집중하여 연구를 진행하고 싶습니다. . | . 800자 가늠 | . 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. // 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구 안녕하세요 저는 김동준입니다. 어쩌구저쩌구안녕하세요 저는 김동준입니다. 어쩌구저쩌구안녕하세요 저는 김동준입니다. 어쩌구저쩌구안녕하세요 저는 김동 | .",
            "url": "https://cjfal.github.io/dj/2022/01/03/%ED%95%9C%EC%86%94%EC%A0%9C%EC%A7%80-%EC%9E%90%EC%86%8C%EC%84%9C.html",
            "relUrl": "/2022/01/03/%ED%95%9C%EC%86%94%EC%A0%9C%EC%A7%80-%EC%9E%90%EC%86%8C%EC%84%9C.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Title",
            "content": "파이썬 입문(1분반) 기말고사 - 최규빈교수님 . 201514142 김동준 에너지화학공학과 . 1 . import pandas as pd import numpy as np import random as rd def upgrade(day,usernum): success = [1,1,1,0,0,0,0,0,0,0] user = [0] while len(user) &lt; day+1: if (user[-1] == 5): user.append(5) elif (rd.choice(success) == 1): user.append(user[-1]+1) else: user.append(user[-1]) user_df = pd.DataFrame(user) user_df.columns=[&#39;user%s&#39;%usernum] return(user_df) def last(numd,numuser): lastday = pd.DataFrame({&#39;0&#39;:[0]*(numd+1)}) for numuser in range(1,numuser+1): lastday[&#39;user%s&#39;%numuser] = upgrade(numd,numuser) lastdayreal=lastday.iloc[:,1:1000] return(lastdayreal) . last(62,100) . user1 user2 user3 user4 user5 user6 user7 user8 user9 user10 ... user91 user92 user93 user94 user95 user96 user97 user98 user99 user100 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | . 2 0 | 2 | 1 | 0 | 0 | 1 | 1 | 0 | 0 | 1 | ... | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | . 3 0 | 2 | 2 | 0 | 0 | 1 | 1 | 0 | 0 | 1 | ... | 1 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | . 4 0 | 2 | 2 | 0 | 0 | 1 | 1 | 0 | 0 | 1 | ... | 1 | 2 | 0 | 1 | 0 | 0 | 0 | 0 | 2 | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 59 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 60 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 61 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 62 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 63 rows × 100 columns . 1 62&#51068;&#52264;&#50640; &#44053;&#54868;&#47484; &#49457;&#44277;&#54620; &#49324;&#46988;&#51032; &#49688; &#44228;&#49328; (&#54665;&#51032; &#47560;&#51648;&#47561;&#51032; bool&#54805;&#51012; &#45908;&#54616;&#50668; &#54869;&#51064;) . sum(last(62,100).iloc[-1,:] == 5) . 100 . . . 2 -(1),(2) . import pandas as pd import numpy as np import random as rd success = [1,1,1,1,1,1,1,0,0,0] def upgrade(day,usernum): user = [0] countzero = [0] while len(user) &lt; day+1: if (user[-1] == 5): user.append(5) elif (rd.choice(success) == 0): user.append(user[-1]) if (user[-1] == 0): continue else: countzero[0] = countzero[0] + 1 else: user.append(user[-1]+1) if countzero[0] == 2: user[-1] = 0 countzero[0] = 0 else: continue user_df = pd.DataFrame(user) user_df.columns=[&#39;user%s&#39;%usernum] return(user_df) def last(numd,numuser): lastday = pd.DataFrame({&#39;0&#39;:[0]*(numd+1)}) for numuser in range(1,numuser+1): lastday[&#39;user%s&#39;%numuser] = upgrade(numd,numuser) lastdayreal=lastday.iloc[:,1:1000] return(lastdayreal) . last(62,100) . user1 user2 user3 user4 user5 user6 user7 user8 user9 user10 ... user91 user92 user93 user94 user95 user96 user97 user98 user99 user100 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 1 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | ... | 1 | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 1 | 0 | . 2 2 | 1 | 1 | 1 | 2 | 1 | 2 | 1 | 1 | 2 | ... | 2 | 2 | 2 | 2 | 2 | 1 | 1 | 2 | 2 | 0 | . 3 3 | 1 | 0 | 2 | 2 | 2 | 2 | 0 | 2 | 3 | ... | 3 | 3 | 3 | 2 | 3 | 1 | 2 | 3 | 3 | 0 | . 4 3 | 0 | 1 | 3 | 3 | 3 | 3 | 0 | 3 | 4 | ... | 4 | 4 | 4 | 3 | 3 | 2 | 3 | 4 | 4 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 59 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 60 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 61 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 62 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 63 rows × 100 columns . 2 . (1) 이 경우 62일의 방학뒤에 100명의 유저중 대략 몇명정도 +5 강화상태에 있겠는가? 시뮬레이션을 활용하여 추론하라. (단, +5강화에 성공하지 못한 모 든 유저는 반드시 하루에 한번 강화를 시도해야 한다고 가정하자.) . last 에 numd = 62 , numuser = 100 대입 . sum(last(62,100).iloc[-1,:] == 5) . 100 . . . (2) 31번째 시도 이후 대략 몇명의 유저가 +5 강화상태에 있겠는가? . last 에 numd = 31 , numuser = 100 대입 . sum(last(31,100).iloc[-1,:] == 5) . 97 . . . 2 (3) . import pandas as pd import numpy as np import random as rd success = [1,1,1,1,1,1,1,0,0,0] def upgrade(day,usernum): user = [0] countzero = [0] while len(user) &lt; day+1: if (user[-1] == 5): user.append(5) elif (rd.choice(success) == 0): user.append(user[-1]) if (user[-1] == 0): continue else: countzero[0] = countzero[0] + 1 else: user.append(user[-1]+1) if countzero[0] == 2: user[-1] = 0 countzero[0] = 0 else: continue user_df = pd.DataFrame(user) user_df.columns=[&#39;user%s&#39;%usernum] return(user_df) def last(numd,numuser): lastday = pd.DataFrame({&#39;0&#39;:[0]*(numd+1)}) for numuser in range(1,numuser+1): lastday[&#39;user%s&#39;%numuser] = upgrade(numd,numuser) if sum(lastday.iloc[-1,1:1000] == 5) &gt;= 50: success = [1,1,1,1,1,1,1,1,1,0] lastdayreal=lastday.iloc[:,1:1000] return(lastdayreal) . last(62,100) . user1 user2 user3 user4 user5 user6 user7 user8 user9 user10 ... user91 user92 user93 user94 user95 user96 user97 user98 user99 user100 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 1 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 0 | 1 | ... | 0 | 0 | 1 | 0 | 1 | 1 | 1 | 1 | 1 | 0 | . 2 1 | 0 | 2 | 2 | 1 | 2 | 2 | 2 | 0 | 1 | ... | 1 | 1 | 2 | 0 | 1 | 2 | 2 | 2 | 1 | 0 | . 3 2 | 1 | 3 | 2 | 2 | 2 | 2 | 3 | 1 | 2 | ... | 2 | 2 | 3 | 1 | 0 | 3 | 3 | 2 | 0 | 1 | . 4 0 | 2 | 3 | 3 | 3 | 3 | 3 | 4 | 2 | 3 | ... | 3 | 3 | 4 | 2 | 1 | 3 | 4 | 3 | 1 | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 59 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 60 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 61 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 62 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | ... | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | . 63 rows × 100 columns . 2_(3) . 100명의 유저중 50명이상의 유저가 +5 강화상태에 도달하는 순간 모든 유저의 강화성공확률을 90%로 증가시킨다고 하자. 62일의 방학뒤에 100명의 유저 중 몇명 정도가 +5 강화상태에 있겠는가? . last 에 numd = 62 , numuser = 100 대입 . sum(last(62,100).iloc[-1,:] == 5) . 100 .",
            "url": "https://cjfal.github.io/dj/2022/01/03/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9E%85%EB%AC%B8%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC%EB%AC%B8%EC%A0%9C1,2_201514142_%EA%B9%80%EB%8F%99%EC%A4%80.html",
            "relUrl": "/2022/01/03/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9E%85%EB%AC%B8%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC%EB%AC%B8%EC%A0%9C1,2_201514142_%EA%B9%80%EB%8F%99%EC%A4%80.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Title",
            "content": "library(MASS) . install.packages(&quot;ISLR2&quot;) . Installing package into ‘/usr/local/lib/R/site-library’ (as ‘lib’ is unspecified) . install.packages(&quot;tree&quot;) . Installing package into ‘/usr/local/lib/R/site-library’ (as ‘lib’ is unspecified) . library(ISLR2) . Attaching package: ‘ISLR2’ The following object is masked from ‘package:MASS’: Boston . library(tree) . . High &lt;- factor(ifelse(Boston$medv &lt; 20 , &quot;low&quot;, &quot;high&quot;)) Boston[,&quot;medv1&quot;] &lt;- data.frame(High) . . attach(Boston) . tree.medv1 &lt;- tree(medv1 ~.-medv,Boston) plot(tree.medv1) text(tree.medv1, pretty = 0) summary(tree.medv1) . Classification tree: tree(formula = medv1 ~ . - medv, data = Boston) Variables actually used in tree construction: [1] &#34;lstat&#34; &#34;rm&#34; &#34;dis&#34; &#34;nox&#34; &#34;indus&#34; &#34;tax&#34; &#34;rad&#34; &#34;age&#34; Number of terminal nodes: 17 Residual mean deviance: 0.3498 = 171.1 / 489 Misclassification error rate: 0.07905 = 40 / 506 . 가장 중요한 변수는 lstat 인것으로 보인다. . set.seed(201514142) cv.medv1 &lt;- cv.tree(tree.medv1, FUN = prune.misclass) names(cv.medv1) cv.medv1 . &lt;ol class=list-inline&gt;&#39;size&#39; | &#39;dev&#39; | &#39;k&#39; | &#39;method&#39; | &lt;/ol&gt; $size [1] 17 13 9 7 2 1 $dev [1] 94 94 91 91 89 210 $k [1] -Inf 0 2 3 4 136 $method [1] &#34;misclass&#34; attr(,&#34;class&#34;) [1] &#34;prune&#34; &#34;tree.sequence&#34; . length(Boston$medv1) . 506 set.seed(201514142) train &lt;- sample(1:nrow(Boston), 250) Boston.test &lt;- Boston[-train, ] medv1.test &lt;- medv1[-train] tree.Boston &lt;- tree(medv1 ~ . - medv, Boston, subset = train) . tree.pred &lt;- predict(tree.Boston, Boston.test, type = &quot;class&quot;) table(tree.pred, medv1.test) . medv1.test tree.pred high low high 122 17 low 25 92 . (122+92)/250 . 0.856 85.6% 의 테스트 데이터의 정확도를 보인다. . 9노드의 트리를 얻기위한 함수 코드 . prune.medv1 &lt;- prune.misclass(tree.medv1, best = 9) plot(prune.medv1) text(prune.medv1, pretty = 0) . tree.pred1 &lt;- predict(prune.medv1, Boston.test, type = &quot;class&quot;) table(tree.pred1, medv1.test) . medv1.test tree.pred1 high low high 133 12 low 14 97 . (133+97) / 250 . 0.92 92% 로 정확성 향상 . . set.seed(201514142) train &lt;- sample(1:nrow(Boston), nrow(Boston) / 2) tree.boston &lt;- tree(medv1 ~ .-medv, Boston, subset = train) summary(tree.boston) . Classification tree: tree(formula = medv1 ~ . - medv, data = Boston, subset = train) Variables actually used in tree construction: [1] &#34;lstat&#34; &#34;rm&#34; &#34;nox&#34; &#34;dis&#34; &#34;ptratio&#34; &#34;age&#34; Number of terminal nodes: 13 Residual mean deviance: 0.2084 = 50.02 / 240 Misclassification error rate: 0.05138 = 13 / 253 . 트리를 구성하는 데 6개의 변수만 사용되었다. . plot(tree.boston) text(tree.boston, pretty = 0) . 가지치기로 성능을 향상 . prune.boston &lt;- prune.tree(tree.boston, best = 5) plot(prune.boston) text(prune.boston, pretty = 0) . . install.packages(&quot;gbm&quot;) library(gbm) . Installing package into ‘/usr/local/lib/R/site-library’ (as ‘lib’ is unspecified) Loaded gbm 2.1.8 . set.seed(1) boost.boston &lt;- gbm(medv1 ~ . -medv, data = Boston[train, ], distribution = &quot;gaussian&quot;, n.trees = 5000, interaction.depth = 4) . summary(boost.boston) . A data.frame: 12 × 2 varrel.inf . &lt;chr&gt;&lt;dbl&gt; . lstatlstat | 44.0647732 | . rmrm | 14.1350606 | . ageage | 8.0966246 | . taxtax | 6.6639979 | . crimcrim | 6.4895353 | . noxnox | 5.9589193 | . disdis | 5.9119778 | . ptratioptratio | 3.9765543 | . indusindus | 3.3378129 | . radrad | 0.7925498 | . chaschas | 0.4191571 | . znzn | 0.1530372 | . plot(boost.boston, i = &quot;rm&quot;) . plot(boost.boston, i = &quot;lstat&quot;) . plot(boost.boston, i = &quot;age&quot;) . yhat.boost &lt;- predict(boost.boston, newdata = Boston[-train, ], n.trees = 5000) . plot(yhat.boost) . boost.boston &lt;- gbm(medv1 ~ .-medv, data = Boston[train, ], distribution = &quot;gaussian&quot;, n.trees = 5000, interaction.depth = 4, shrinkage = 0.2, verbose = F) yhat.boost &lt;- predict(boost.boston, newdata = Boston[-train, ], n.trees = 5000) . Classification Trees에서 노드를 9개로 한 나무모형이 92%의 정확도로 성능이 가장 좋은것으로 예측된다. .",
            "url": "https://cjfal.github.io/dj/2022/01/03/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5.html",
            "relUrl": "/2022/01/03/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "파이썬코딩 무료 강의(기본편)",
            "content": "&#47928;&#51088;&#50676; . sentence = &#39;나는 소년입니다&#39; print(sentence) . 나는 소년입니다 . sentence2 = &quot;파이썬은 쉬워요&quot; . print(sentence2) . 파이썬은 쉬워요 . sentence3 = &quot;&quot;&quot; 나는 소년이고, 파이썬은 쉬워요 &quot;&quot;&quot; print(sentence3) #4줄 출력 . 나는 소년이고, 파이썬은 쉬워요 . &#49836;&#46972;&#51060;&#49905; . jumin = &quot;990120-1234567&quot; . print(&quot;성별 : &quot; + jumin[7]) . 성별 : 1 . print(&quot;출생년도 :&quot; + jumin[0:2]) #첫번째부터 두번째까지 . 출생년도 :99 . print(&quot;월 :&quot; + jumin[2:4]) . 월 :01 . print(&quot;생년월일 :&quot; + jumin[0:6]) .",
            "url": "https://cjfal.github.io/dj/python/%EC%97%B0%EC%8A%B5/2022/01/02/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%BD%94%EB%94%A9-%EB%AC%B4%EB%A3%8C-%EA%B0%95%EC%9D%98(%EA%B8%B0%EB%B3%B8%ED%8E%B8).html",
            "relUrl": "/python/%EC%97%B0%EC%8A%B5/2022/01/02/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%BD%94%EB%94%A9-%EB%AC%B4%EB%A3%8C-%EA%B0%95%EC%9D%98(%EA%B8%B0%EB%B3%B8%ED%8E%B8).html",
            "date": " • Jan 2, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "데이터시각화",
            "content": "fig.add_axes() ## 액시즈를 fig에 추가하라. fig.axes ## 현재 fig에 있는 액시즈 정보 . &#51452;&#47196;&#50416;&#45716; &#54056;&#53412;&#51648;&#46308; . import numpy as np #넘파이 import pandas as pd #판다스 from plotnine import * #플롯나인 import matplotlib.pyplot as plt #맷플랏립 import plotly.express as px #플랏리 상호작용 그래프 from IPython.display import HTML #블로그에 html로 올리려고 변환하는 패키지 import seaborn as sns # 씨본, 히스토그램 깔끔하게 그리는 패키지 import cv2 as cv from scipy import stats . &#50976;&#50857;&#54620; &#51105;&#44592;&#49696; . 코드 맨위 &quot; #collapse &quot; : 복잡한 코드가 주피터에 올라갈 때 인풋을 숨길 수 있음 #숨기기 . pd.concat([df1,df2]) : 데이터프레임 합치기 . ignore_index=True -&gt; 기존에 있던 인덱스를 무시해라 . ${0 sim9} + {0 sim9}$ (기존) -&gt; 0~19 (무시) . 코드 맨위 &quot; #hide &quot; : 인풋 아웃풋 둘다 숨기기 . pd.DataFrame({&#39;열이름지정1&#39;:y1(리스트나 함수),&#39;열이름지정2&#39;:[&#39;A&#39;]*len(y1)(리스트나 함수)}) . $ to$ 데이터 프레임 생성 . HTML(저장한플랏이름.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . 생성된 플랏을 html로 바꾸어 블로그에서 읽을 수 있게 함, 패키지 필요, IPython.display의 HTML . 숫자형.round(n) #소수 n째자리에서 반올림 . np.random.seed(아무숫자) : 값이 안변하도록 시드설정 . 이미지 불러오기 . img = cv.imread(&#39;사진이름.확장자&#39;,흑백원하면 0(안쓰면 컬러) ) :wd에 있어야함 . np.corrcoef([x,y]) 상관계수 구하기 . k=np.linspace(-2,2,9) #-2 부터 2까지 9개의 등분 k . array([-2. , -1.5, -1. , -0.5, 0. , 0.5, 1. , 1.5, 2. ]) . range(n) #n 까지의 자연수 출력 . &#50937;&#49324;&#51060;&#53944;&#50640; &#44277;&#44060;&#46108; csv &#48520;&#47084;&#50724;&#44592; . pd.read_csv(&#39;웹주소.csv&#39;) . - 깃허브 저장소에 아예 데이터만 따로 모아서 관리하는 것도 좋은 방법입니다. . . &#50668;&#47084;&#44536;&#47548;&#51012; &#44536;&#47532;&#44592; . &#46972;&#51064;&#54540;&#46991;&#51012; &#44536;&#47532;&#45716; &#48169;&#48277; . import matplotlib.pyplot as plt x=[1,2,3,4] y=[1,2,4,3] plt.plot(x,y) . [&lt;matplotlib.lines.Line2D at 0x7f7a165e8130&gt;] . &#49328;&#51216;&#46020; &#44536;&#47532;&#44592; (&#50741;&#49496;&#47564; &#48148;&#44988;&#44163;) . import matplotlib.pyplot as plt x=[1,2,3,4] y=[1,2,4,3] plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fe22e3e5d90&gt;] . (1) &#44217;&#52432;&#44536;&#47532;&#44592; . x=[1,2,3,4] y=[1,2,4,3] x=np.arange(-5,5,0.1) y=2*x+np.random.normal(loc=0,scale=1,size=100) plt.plot(x,y,&#39;.b&#39;) plt.plot(x,2*x,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f7a1439fa60&gt;] . (2) &#46384;&#47196;&#44536;&#47532;&#44592; - subplots . x=[1,2,3,4] y=[1,2,4,3] _, axs = plt.subplots(2,2) # 2x2의 서브플랏을 만들겠다. 따로그리기의 기본 # 리턴값이 (fig,axs) 임 그래서 fig자리는 어느것이든 상관이 없어서 아무것도 안쓰려고 _ 를 쓴것 axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fe22d944df0&gt;] . . lambda . lambda &#49324;&#50857;&#48277; . f = lambda x,y,z : x+y+z ## lambda 입력:출력 #이자체가 오브젝트로 취급된다. . f(2,3,4) . 9 . lambda &#46356;&#54260;&#53944;&#51077;&#47141;&#44050; . x= (lambda a=&#39;fee&#39;,b=&#39;fie&#39;,c=&#39;foe&#39;: a+b+c) . x(&#39;wee&#39;) . &#39;weefiefoe&#39; . lambda&#51032; &#47532;&#49828;&#53944;&#54868; . l = [lambda x: x**2, lambda x: x**3, lambda x: x**4] #리스트안에 람다 3개 . for f in l: print(f(2)) . 4 8 16 . lambda&#51032; &#46357;&#49492;&#45320;&#47532;&#54868; . dct={&#39;f1&#39;: (lambda x: x+1), &#39;f2&#39;: (lambda x: x+22), &#39;f3&#39;: (lambda x: x+333)} . dct[&#39;f1&#39;](1), dct[&#39;f2&#39;](1), dct[&#39;f3&#39;](1) . (2, 23, 334) . lambda&#51032; &#51312;&#44148;&#48512; &#52636;&#47141; . lower = lambda x,y : x if x&lt;y else y . lower(&#39;a&#39;,&#39;b&#39;) . &#39;a&#39; . lower(&#39;c&#39;,&#39;b&#39;) . &#39;b&#39; . lambda expression &#51012; return &#51077;&#47141;&#44032;&#45733; . def action(x): return (lambda y: x+y) #리턴을 람다로 . act = action(99) ## act를 99+y를 수행하는 함수로 저장 act2 = action(98) ## act2를 98+y를 수행하는 함수로 저장 . action은 마치 함수를 만드는 함수같다.. | . print(act(2)) # act안에 y에 2를 넣겠다. 99+2 print(act2(2)) # act2안에 y에 2를 넣겠다. 98+2 . 101 100 . &#50696;&#51228;6&#51032; &#48156;&#51204; . action = lambda x: (lambda y: x+y) # 람다 출력에 또 람다 . act= action(99) #x에 99를 넣은 함수 act 선언 act2=action(98) #x에 98를 넣은 함수 act2 선언 . print(act(2)) print(act2(2)) . 101 100 . 괄호를 생략하여 선언하면 . action = lambda x: lambda y: x+y act= action(99) act2=action(98) print(act(2)) print(act2(2)) # 똑같다. . 101 100 . . map . map? #map(func, *iterables) --&gt; map 개체 #다음 인수를 사용하여 함수를 계산하는 반복자를 만듭니다. #각 반복 사항 최단 시간이 소진되면 중지됩니다. . Init signature: map(self, /, *args, **kwargs) Docstring: map(func, *iterables) --&gt; map object Make an iterator that computes the function using arguments from each of the iterables. Stops when the shortest iterable is exhausted. Type: type Subclasses: . map &#49324;&#50857;&#48169;&#48277; . def inc(x): return x+1 #임시로 쓸건데 공간도 차지하고 좀 그럼 $ to$ 람다로 처리 . list(map(inc,[1,2,3,4])) . [2, 3, 4, 5] . &#50696;&#51228;1&#51032; &#48320;&#54805;(&#46988;&#45796;&#49324;&#50857;) . list(map(lambda x: x+1,[1,2,3,4])) . [2, 3, 4, 5] . list(map(def inc(x): return x+1,[1,2,3,4])) #안됨 . File &#34;&lt;ipython-input-69-e70d258d54b1&gt;&#34;, line 1 list(map(def inc(x): return x+1,[1,2,3,4])) #안됨 ^ SyntaxError: invalid syntax . 함수명을 쓰는 자리에 lambda로 표현한 오브젝트 자체를 전달할 수 있다. $ to$ 코드가 간단하다. | . map&#44284; &#47532;&#49828;&#53944;&#52980;&#54532;&#47532;&#54760;&#49496; &#48708;&#44368; . (함수선언) . f = lambda x: &#39;X&#39; in x . f(&#39;X1&#39;),f(&#39;X2&#39;),f(&#39;Y1&#39;),f(&#39;Y2&#39;) . (True, True, False, False) . (map) . list(map(f,[&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;])) . [True, True, False, False] . (리스트컴프리헨션과 비교) . [f(x) for x in [&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;]] . [True, True, False, False] . &#46160;&#44060;&#51032; &#51077;&#47141;&#51012; &#48155;&#45716; &#54632;&#49688;(pow) map, &#47532;&#49828;&#53944;&#52980;&#54532;&#47532;&#54760;&#49496; &#48708;&#44368; . (함수소개) . pow(2,4) #2를 4제곱 . 16 . (map) . list(map(pow,[2,2,2,3,3,3],[0,1,2,0,1,2])) . [1, 2, 4, 1, 3, 9] . (리스트컴프리헨션과 비교) . [pow(x,y) for x,y in zip([2,2,2,3,3,3],[0,1,2,0,1,2])] #zip이라는 새로운 오브젝트 생성 . [1, 2, 4, 1, 3, 9] . map은 (하나의 함수,다양한 입력)인 경우 사용가능 . l=[lambda x: x+1, lambda x: x+2, lambda x: x+3 ] . list(map(l,[100,200,300])) . TypeError Traceback (most recent call last) &lt;ipython-input-78-dcc049c06067&gt; in &lt;module&gt; -&gt; 1 list(map(l,[100,200,300])) TypeError: &#39;list&#39; object is not callable . 리스트컴프리헨션은 (다양한함수,다양한입력)이 가능함 . [l[i](x) for i,x in zip([0,1,2],[100,200,300])] . [101, 202, 303] . 리스트컴프리헨션은 (다양한함수,다양한입력)이 가능함 . [l[i](x) for i,x in zip([0,1,2],[100,200,300])] . [101, 202, 303] . 종합:map을 리스트컴프리헨션과 비교 . (1) 반복인덱스를 쓰지 않는 장점 . (2) 좀 더 제약적으로 사용할 수 밖에 없다는 단점 . &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; &#44536;&#47532;&#44592; . fig = plt.figure() fig.axes . [] . &lt;Figure size 432x288 with 0 Axes&gt; . fig.subplots(2,2) fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1,ax2,ax3,ax4=fig.axes . ax1.plot([1,2,3],&#39;ob&#39;) ax2.plot([1,2,3],&#39;or&#39;) ax3.plot([1,2,3],&#39;ok&#39;) ax4.plot([1,2,3],&#39;oy&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fb177430&gt;] . fig . - 단계적으로 코드를 실행하고 싶을때 . x=[1,2,3,4] y=[1,2,4,3] . _, axs = plt.subplots(2,2) . axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0faaa0940&gt;] . 어? 그림을 볼려면 어떻게 하지? | . _ . plt.subplots()&#47484; 2$ times$2 subplot &#44536;&#47532;&#44592; -- &#50529;&#49884;&#51592;&#47484; &#44033;&#44033; &#48320;&#49688;&#47749;&#51004;&#47196; &#51200;&#51109; . x=[1,2,3,4] y=[1,2,4,3] fig, axs = plt.subplots(2,2) . (ax1,ax2), (ax3,ax4) = axs . ax1.plot(x,y,&#39;o:r&#39;) ax2.plot(x,y,&#39;Xb&#39;) ax3.plot(x,y,&#39;xm&#39;) ax4.plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fb3650d0&gt;] . fig . &#51228;&#47785;&#49444;&#51221; . &#50696;&#51228;1: plt.plot() . x=[1,2,3] y=[1,2,2] . plt.plot(x,y) plt.title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . &#50696;&#51228;2: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857; . fig = plt.figure() fig.subplots() . &lt;AxesSubplot:&gt; . ax1=fig.axes[0] . ax1.set_title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . fig . - 문법을 잘 이해했으면 각 서브플랏의 제목을 설정하는 방법도 쉽게 알 수 있다. . &#50696;&#51228;3: subplot&#50640;&#49436; &#44033;&#44033;&#51032; &#51228;&#47785;&#49444;&#51221; $ star$ . fig, ax = plt.subplots(2,2) . (ax1,ax2),(ax3,ax4) =ax . ax1.set_title(&#39;title1&#39;) ax2.set_title(&#39;title2&#39;) ax3.set_title(&#39;title3&#39;) ax4.set_title(&#39;title4&#39;) . Text(0.5, 1.0, &#39;title4&#39;) . fig #뭔가 엉성함 . - 보기싫음 $ to$ 서브플랏의 레이아웃 재정렬 . fig.tight_layout() # 외우세요.. fig #깔끔해짐 . &#50696;&#51228;4: &#50529;&#49884;&#51592;&#51032; &#51228;&#47785; + Figure&#51228;&#47785; . fig.suptitle(&#39;sup title&#39;) . Text(0.5, 0.98, &#39;sup title&#39;) . fig . fig.tight_layout() . fig . &#52629;&#48276;&#50948; &#49444;&#51221; . plt.xlim(-1,5) # plt 이용 plt.ylim(3,7) ax1.set_xlim(-10,110) #axs 이용 ax1.set_ylim(-5,5) . .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/12/31/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%9E%A1%EA%B8%B0%EC%88%A0.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/12/31/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%9E%A1%EA%B8%B0%EC%88%A0.html",
            "date": " • Dec 31, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "회귀분석 10장 연습문제R",
            "content": "10.2) . 예제 10.2의 가정된 모형에서 교호작용 효과에 대한 검정결과 유의하지 않게 판정되었다. 교호작용이 없는 모형 . $y_j= beta_0+ beta_1x_{1j}+ beta_2x_{2j}+ epsilon_j$ . 를 가정하고 분산분석표를 작성하여 예의 결과와 비교하여라 . &#50696;&#51228; 10.2) . 다음 자료는 새로운 제조방법$(x_2)$ A, B에 의하여 제조된 벨트 16개에 충격$(x_1)$을 가한 후 수명을 조사한 것이다. . 일련번호 $y$(수명) $x_1$(충격) $x_2$(제조방법) . 1 | 18 | 61 | A | . 2 | 17.4 | 72 | A | . 3 | 14.5 | 85 | A | . 4 | 14 | 84 | A | . 5 | 13.4 | 98 | A | . 6 | 24.4 | 53 | A | . 7 | 22.7 | 54 | A | . 8 | 12.7 | 89 | A | . 9 | 27.1 | 77 | B | . 10 | 25.4 | 88 | B | . 11 | 33.5 | 76 | B | . 12 | 35.6 | 59 | B | . 13 | 26.1 | 91 | B | . 14 | 36.8 | 65 | B | . 15 | 34.9 | 81 | B | . 16 | 43.6 | 51 | B | . EX102 &lt;- read.csv(&quot;10dot2.csv&quot;,header=T) . EX102[,&quot;manu1&quot;] &lt;- c(0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1) . head(EX102) . A data.frame: 6 × 5 numlifeworkmanumanu1 . &lt;int&gt;&lt;dbl&gt;&lt;int&gt;&lt;chr&gt;&lt;dbl&gt; . 11 | 18.0 | 61 | A | 0 | . 22 | 17.4 | 72 | A | 0 | . 33 | 14.5 | 85 | A | 0 | . 44 | 14.0 | 84 | A | 0 | . 55 | 13.4 | 98 | A | 0 | . 66 | 24.4 | 53 | A | 0 | . attach(EX102) . gyo &lt;- work*manu1 gyo . &lt;ol class=list-inline&gt;0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 77 | 88 | 76 | 59 | 91 | 65 | 81 | 51 | &lt;/ol&gt; fit1 &lt;- lm(life~work+manu1) . fitgyo &lt;- lm(life~work+manu1+gyo) . summary(fitgyo) . Call: lm(formula = life ~ work + manu1 + gyo) Residuals: Min 1Q Median 3Q Max -4.3938 -1.1350 0.0171 1.6701 4.9848 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 35.16364 4.31882 8.142 3.14e-06 *** work -0.24196 0.05669 -4.268 0.00109 ** manu1 26.71723 6.71235 3.980 0.00183 ** gyo -0.15268 0.08916 -1.712 0.11252 Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 2.557 on 12 degrees of freedom Multiple R-squared: 0.9441, Adjusted R-squared: 0.9301 F-statistic: 67.56 on 3 and 12 DF, p-value: 8.73e-08 . anova(fitgyo) . A anova: 4 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . work 1 | 353.81512 | 353.815123 | 54.132838 | 8.764291e-06 | . manu1 1 | 951.69664 | 951.696636 | 145.607229 | 4.545839e-08 | . gyo 1 | 19.16497 | 19.164974 | 2.932194 | 1.125250e-01 | . Residuals12 | 78.43264 | 6.536053 | NA | NA | . 연습문제와의 비교 . summary(fit1) . Call: lm(formula = life ~ work + manu1) Residuals: Min 1Q Median 3Q Max -4.7121 -1.5151 -0.1434 1.3539 4.3026 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 39.76136 3.62542 10.967 6.10e-08 *** work -0.30368 0.04689 -6.476 2.08e-05 *** manu1 15.43382 1.37079 11.259 4.47e-08 *** Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 2.74 on 13 degrees of freedom Multiple R-squared: 0.9304, Adjusted R-squared: 0.9197 F-statistic: 86.95 on 2 and 13 DF, p-value: 2.987e-08 . anova(fit1) . A anova: 3 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . work 1 | 353.81512 | 353.815123 | 47.12817 | 1.144082e-05 | . manu1 1 | 951.69664 | 951.696636 | 126.76597 | 4.471157e-08 | . Residuals13 | 97.59762 | 7.507509 | NA | NA | . 연습문제에서 적합한 모형은 . $ hat{y} = 39.76136 -0.30368x_1 + 15.43382x_2$ 이다. . 예제의 모형에서 교호작용효과를 무시할 수 있다고 결론 내렸으므로 연습문제의 적합이 적절하다. . . 10.4) . 다음 자료에 대하여 . x y . 2.5 | 65 | . 4.4 | 34 | . 4.5 | 40 | . 1.4 | 80 | . 4.7 | 30 | . 3.5 | 57 | . 2.5 | 72 | . 3.8 | 48 | . 1) y&#51032; x&#50640; &#45824;&#54620; &#49328;&#51216;&#46020;&#47484; &#44536;&#47140;&#48372;&#44256; &#47751; &#44060;&#51032; &#44396;&#44036;&#51004;&#47196; &#45208;&#45572;&#50612; &#48516;&#49437;&#54616;&#47732; &#51339;&#51008;&#51648;&#47484; &#49444;&#47749;&#54616;&#44256; &#50612;&#46500; &#51216;$(x_p)$&#50640;&#49436; &#45208;&#45572;&#45716; &#44163;&#51060; &#51339;&#51008;&#51648;&#47484; &#49444;&#47749;&#54616;&#50668;&#46972;. . EX104 &lt;- read.csv(&quot;104.csv&quot;,header=T) attach(EX104) . plot(x4,y4,col=&quot;red&quot;) . $x_p = 3.8$ 에서 나누는것이 좋아보인다. . 2) &#50948; &#51088;&#47308;&#47484; &#46160; &#44396;&#44036;&#51004;&#47196;&#47564; &#45208;&#45572;&#47140;&#44256; &#54620;&#45796;&#47732; &#50612;&#46500; &#51216;$(x_p)$&#50640;&#49436; &#45208;&#45572;&#45716; &#44163;&#51060; &#51339;&#51008;&#51648;&#47484; &#49444;&#47749;&#54616;&#44256; &#44536; &#51216;&#51012; &#44221;&#44228;&#47196; &#54616;&#50668; &#45796;&#51020; &#47784;&#54805;&#51012; &#51201;&#54633;&#49884;&#53020; &#48372;&#50500;&#46972;. . $y_j = beta_0 + beta_1x_{1j} + beta_2(x_{1j}-x_p)x_{2j}+ epsilon_j$ . $x_{2j} = 1, 만약 x_{1j} &gt; x_p 이면$ . $x_{2j} = 0, 만약 x_{1j} leq x_p 이면$ . x4_2 &lt;- function(x4) ifelse(x4&gt;3.8,1,0) . x4_2(x4) . &lt;ol class=list-inline&gt;0 | 1 | 1 | 0 | 1 | 0 | 0 | 0 | &lt;/ol&gt; EX104[,&quot;x4_&quot;] = (x4-3.8)*x4_2(x4) EX104$x4_ . &lt;ol class=list-inline&gt;0 | 0.6 | 0.7 | 0 | 0.9 | 0 | 0 | 0 | &lt;/ol&gt; fit104 &lt;- lm(y4~x4+x4_,data=EX104) . summary(fit104) . Call: lm(formula = y4 ~ x4 + x4_, data = EX104) Residuals: 1 2 3 4 5 6 7 8 -2.421 -3.663 4.531 -1.462 -1.082 2.344 4.579 -2.826 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 99.333 5.907 16.817 1.36e-05 *** x4 -12.765 2.046 -6.238 0.00155 ** x4_ -9.173 6.201 -1.479 0.19911 Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 3.939 on 5 degrees of freedom Multiple R-squared: 0.9668, Adjusted R-squared: 0.9535 F-statistic: 72.71 on 2 and 5 DF, p-value: 0.0002015 . $ hat{y} = 99.333 -12.765x_1 -9.173x_2$ 을 추정할 수 있다. . 3) &#44480;&#47924;&#44032;&#49444; $H_0 : beta_2 = 0$, &#45824;&#47549;&#44032;&#49444; $H_1 : beta_2 neq 0 $ &#47484; &#50976;&#51032;&#49688;&#51456; 0.05&#47196; &#44160;&#51221;&#54616;&#50668;&#46972;. . anova(fit104) . A anova: 3 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x41 | 2221.98174 | 2221.98174 | 143.230386 | 7.182332e-05 | . x4_1 | 33.95155 | 33.95155 | 2.188539 | 1.991072e-01 | . Residuals5 | 77.56670 | 15.51334 | NA | NA | . p-value 가 0에 근접하여 영가설을 기각한다. 즉, $ beta_2$ 는 0이아니라는 것을 알 수 있다. . . 10.5) . 다음의 자료는 모든 조건이 같은 60마리의 실험용 동물을 각각 30마리씩 두 그룹으로 나누어 한 그룹에 A, 또 다른 그룹에는 B의 안정제를 $5, 10, 20mg$ 씩 투약했을 때 관찰된 불안도$(y)$이다. $y, x_1,x_2$를 각각 불안도, 약의 복용량, 약의 종류라고 하고 다음 질문에 답하여라. . 5 10 20 . (A) | 15 | 16 | 18 | 16 | 20 | 17 | . (A) | 16 | 15 | 17 | 15 | 19 | 18 | . (A) | 18 | 16 | 18 | 19 | 21 | 21 | . (A) | 13 | 17 | 19 | 18 | 18 | 20 | . (A) | 19 | 15 | 20 | 16 | 19 | 17 | . (B) | 16 | 15 | 19 | 18 | 24 | 23 | . (B) | 17 | 15 | 21 | 20 | 25 | 24 | . (B) | 18 | 18 | 22 | 21 | 23 | 22 | . (B) | 17 | 17 | 23 | 22 | 25 | 26 | . (B) | 15 | 16 | 20 | 19 | 25 | 24 | . 1) &#51648;&#49884;&#48320;&#49688;&#47484; &#51060;&#50857;&#54616;&#50668; &#51088;&#47308;&#50640; &#45824;&#54620; &#51201;&#51208;&#54620; &#47784;&#54805;&#51012; &#49444;&#51221;&#54616;&#50668;&#46972;. . 4.24-0.013x . EX105 &lt;- read.csv(&quot;105.csv&quot;,header = T) . EX105 . A data.frame: 60 × 4 dosageunrestkindkindn . &lt;int&gt;&lt;int&gt;&lt;chr&gt;&lt;int&gt; . 5 | 15 | A | 0 | . 5 | 16 | A | 0 | . 5 | 16 | A | 0 | . 5 | 15 | A | 0 | . 5 | 18 | A | 0 | . 5 | 16 | A | 0 | . 5 | 13 | A | 0 | . 5 | 17 | A | 0 | . 5 | 19 | A | 0 | . 5 | 15 | A | 0 | . 10 | 18 | A | 0 | . 10 | 16 | A | 0 | . 10 | 17 | A | 0 | . 10 | 15 | A | 0 | . 10 | 18 | A | 0 | . 10 | 19 | A | 0 | . 10 | 19 | A | 0 | . 10 | 18 | A | 0 | . 10 | 20 | A | 0 | . 10 | 16 | A | 0 | . 20 | 20 | A | 0 | . 20 | 17 | A | 0 | . 20 | 19 | A | 0 | . 20 | 18 | A | 0 | . 20 | 21 | A | 0 | . 20 | 21 | A | 0 | . 20 | 18 | A | 0 | . 20 | 20 | A | 0 | . 20 | 19 | A | 0 | . 20 | 17 | A | 0 | . 5 | 16 | B | 1 | . 5 | 15 | B | 1 | . 5 | 17 | B | 1 | . 5 | 15 | B | 1 | . 5 | 18 | B | 1 | . 5 | 18 | B | 1 | . 5 | 17 | B | 1 | . 5 | 17 | B | 1 | . 5 | 15 | B | 1 | . 5 | 16 | B | 1 | . 10 | 21 | B | 1 | . 10 | 20 | B | 1 | . 10 | 22 | B | 1 | . 10 | 21 | B | 1 | . 10 | 23 | B | 1 | . 10 | 22 | B | 1 | . 10 | 20 | B | 1 | . 10 | 19 | B | 1 | . 10 | 24 | B | 1 | . 10 | 23 | B | 1 | . 20 | 25 | B | 1 | . 20 | 24 | B | 1 | . 20 | 23 | B | 1 | . 20 | 22 | B | 1 | . 20 | 25 | B | 1 | . 20 | 26 | B | 1 | . 20 | 25 | B | 1 | . 20 | 24 | B | 1 | . 20 | 24 | B | 1 | . 20 | 23 | B | 1 | . one &lt;- rep(1,length(EX105$kind)) . &lt;ol class=list-inline&gt;1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | &lt;/ol&gt; X105 &lt;- matrix(c(one,EX105$dosage,EX105$kindn),length(EX105$kind),3) . y105 &lt;- matrix(c(EX105$unrest),length(EX105$unrest),1) . solve(t(X105)%*%X105)%*%t(X105)%*%y105 . A matrix: 3 × 1 of type dbl 13.6333333 | . 0.3342857 | . 3.1333333 | . 2) (1)&#51032; &#47784;&#54805;&#51012; &#52572;&#49548;&#51228;&#44273;&#48277;&#50640; &#51032;&#54644; &#52628;&#51221;&#54616;&#44256; &#48516;&#49328;&#48516;&#49437;&#54364;&#47484; &#51089;&#49457;&#54616;&#50668;&#46972;. . fit105 &lt;- lm(EX105$unrest~EX105$dosage+EX105$kindn) . summary(fit105) . Call: lm(formula = EX105$unrest ~ EX105$dosage + EX105$kindn) Residuals: Min 1Q Median 3Q Max -3.4381 -1.3488 -0.1095 1.1548 3.8905 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 13.63333 0.57751 23.607 &lt; 2e-16 *** EX105$dosage 0.33429 0.03949 8.465 1.17e-11 *** EX105$kindn 3.13333 0.49251 6.362 3.65e-08 *** Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 1.907 on 57 degrees of freedom Multiple R-squared: 0.663, Adjusted R-squared: 0.6512 F-statistic: 56.07 on 2 and 57 DF, p-value: 3.447e-14 . anova(fit105) . A anova: 3 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . EX105$dosage 1 | 260.7429 | 260.742857 | 71.66357 | 1.165330e-11 | . EX105$kindn 1 | 147.2667 | 147.266667 | 40.47534 | 3.647996e-08 | . Residuals57 | 207.3905 | 3.638429 | NA | NA | . 3) &#51088;&#47308;&#50640; $y= beta_0+ beta_1x_1+ beta_2x_2+ epsilon$&#47484; &#51201;&#54633;&#49884;&#53412;&#44256; &#54924;&#44480;&#49440;&#51012; &#52628;&#51221;&#54616;&#50668;&#46972;. . $ to b_0 = 13.63 , b_1 = 0.3343 , b_2 = 3.133 $ . 반응 함수는 $ hat{y} = 13.63 + 0.3343x_1 + 3.133x_2 $ 이다. . 이 결과는 많은양 복용시 불안도가 올라가고, B의 안정제의 불안도가 3정도 더 높다는 것을 보여준다. . 4) &#44368;&#54840;&#51089;&#50857;&#51060; &#51080;&#45716;&#51648; &#44160;&#51221;&#54616;&#50668;&#46972;. $ alpha = 0.05$ . EX105[,&quot;inter&quot;] &lt;- EX105$dosage * EX105$kindn . fit105int &lt;- lm(EX105$unrest~EX105$dosage+EX105$kindn+EX105$inter) . summary(fit105int) . Call: lm(formula = EX105$unrest ~ EX105$dosage + EX105$kindn + EX105$inter) Residuals: Min 1Q Median 3Q Max -3.2571 -1.2250 -0.1714 0.9357 4.1286 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 15.30000 0.65419 23.388 &lt; 2e-16 *** EX105$dosage 0.19143 0.04945 3.871 0.000286 *** EX105$kindn -0.20000 0.92516 -0.216 0.829634 EX105$inter 0.28571 0.06994 4.085 0.000142 *** Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 1.689 on 56 degrees of freedom Multiple R-squared: 0.7404, Adjusted R-squared: 0.7265 F-statistic: 53.23 on 3 and 56 DF, p-value: &lt; 2.2e-16 . $ to kindn$ 의 pvalue가 상당히 크게 측정되어 교호작용은 없는것으로 판단된다. . . 10.7) . 다음 자료는 어느 초등 학교에서 안경을 쓴 학생들을 학년별로 조사한 자료이다. . 학년별 1 2 3 4 5 6 . 전체학생수 | 250 | 252 | 151 | 204 | 202 | 195 | . 안경착용수 | 15 | 20 | 18 | 25 | 32 | 40 | . 1)&#47196;&#51648;&#49828;&#54001; &#48152;&#51025;&#54632;&#49688;&#47484; &#52628;&#51221;&#54616;&#50668;&#46972;. . EX107 &lt;- read.csv(&quot;107.csv&quot;,header=T) attach(EX107) . head(EX107) . A data.frame: 6 × 3 gradestudentglasses . &lt;int&gt;&lt;int&gt;&lt;int&gt; . 11 | 250 | 15 | . 22 | 252 | 20 | . 33 | 151 | 18 | . 44 | 204 | 25 | . 55 | 202 | 32 | . 66 | 195 | 40 | . EX107[,&quot;P&quot;] &lt;- glasses/student EX107 . A data.frame: 6 × 4 gradestudentglassesP . &lt;int&gt;&lt;int&gt;&lt;int&gt;&lt;dbl&gt; . 1 | 250 | 15 | 0.06000000 | . 2 | 252 | 20 | 0.07936508 | . 3 | 151 | 18 | 0.11920530 | . 4 | 204 | 25 | 0.12254902 | . 5 | 202 | 32 | 0.15841584 | . 6 | 195 | 40 | 0.20512821 | . logit &lt;- function(x) log(x/(1-x)) . EX107[,&quot;Pstar&quot;] &lt;- logit(EX107$P) EX107 . A data.frame: 6 × 5 gradestudentglassesPPstar . &lt;int&gt;&lt;int&gt;&lt;int&gt;&lt;dbl&gt;&lt;dbl&gt; . 1 | 250 | 15 | 0.06000000 | -2.751535 | . 2 | 252 | 20 | 0.07936508 | -2.451005 | . 3 | 151 | 18 | 0.11920530 | -1.999977 | . 4 | 204 | 25 | 0.12254902 | -1.968510 | . 5 | 202 | 32 | 0.15841584 | -1.670063 | . 6 | 195 | 40 | 0.20512821 | -1.354546 | . temp = 0 for (i in 1:6){ temp = EX107$student[i]*EX107$P[i]*(1-EX107$P[i]) print(temp) } . [1] 14.1 [1] 18.4127 [1] 15.8543 [1] 21.93627 [1] 26.93069 [1] 31.79487 . a &lt;- c(14.1,0,0,0,0,0) b &lt;- c(0,18.4127,0,0,0,0) c &lt;- c(0,0,15.8543,0,0,0) d &lt;- c(0,0,0,21.93627,0,0) e &lt;- c(0,0,0,0,26.93069,0) f &lt;- c(0,0,0,0,0,31.79487) . W &lt;- matrix(c(a,b,c,d,e,f),6,6) W . A matrix: 6 × 6 of type dbl 14.1 | 0.0000 | 0.0000 | 0.00000 | 0.00000 | 0.00000 | . 0.0 | 18.4127 | 0.0000 | 0.00000 | 0.00000 | 0.00000 | . 0.0 | 0.0000 | 15.8543 | 0.00000 | 0.00000 | 0.00000 | . 0.0 | 0.0000 | 0.0000 | 21.93627 | 0.00000 | 0.00000 | . 0.0 | 0.0000 | 0.0000 | 0.00000 | 26.93069 | 0.00000 | . 0.0 | 0.0000 | 0.0000 | 0.00000 | 0.00000 | 31.79487 | . X &lt;- matrix(c(1,1,1,1,1,1,array(student)),6,2) X . A matrix: 6 × 2 of type dbl 1 | 250 | . 1 | 252 | . 1 | 151 | . 1 | 204 | . 1 | 202 | . 1 | 195 | . Xt &lt;- t(X) . pmat &lt;- matrix(c(array(EX107$Pstar)),6,1) pmat . A matrix: 6 × 1 of type dbl -2.751535 | . -2.451005 | . -1.999977 | . -1.968510 | . -1.670063 | . -1.354546 | . solve(Xt%*%W%*%X) %*% Xt %*%W %*% pmat . A matrix: 2 × 1 of type dbl 0.038849649 | . -0.009442624 | . $ beta_0 = 0.0388 , beta_1 = -0.00944 $ . $ hat{p^{*}} =0.0388 -0.00944student $ 이다. . 2)&#49352;&#47196; &#51204;&#54617;&#54644; &#50732; &#45348; &#54617;&#49373;&#51060; &#50504;&#44221;&#51012; &#52265;&#50857;&#54624; &#54869;&#47456;&#51008;? . 0.0388 -0.00944* 4 . 0.00104 3) $ hat{p}^{*}$&#47484; $x$&#50640; &#45824;&#54616;&#50668; &#46020;&#49884;&#54616;&#44256; &#47196;&#51648;&#49828;&#54001; &#48152;&#51025;&#54632;&#49688;&#47484; &#51201;&#54633;&#49884;&#53412;&#45716; &#44163;&#51060; &#53440;&#45817;&#54620;&#51648;&#47484; &#44160;&#53664;&#54616;&#50668;&#46972;. . plot(EX107$Pstar,EX107$student) . 타당하지 않다. .",
            "url": "https://cjfal.github.io/dj/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/11/22/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D10%EC%9E%A5%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/11/22/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D10%EC%9E%A5%EA%B3%BC%EC%A0%9C.html",
            "date": " • Nov 22, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "11주차 회귀분석 연습문제 8장 R 풀이",
            "content": "8.1) . 어떤 철 제품을 생산하는 공장에서 제품의 인장강도 ($kg/cm^2$)가 온도와 시간에 어떤영향을 받는가를 분석하기 위하여 다음과 같은 자료를 얻었다. . 공정온도:$x_1$ 시간(분):$x_2$ 인장강도:y . 175 | 15 | 120.4 | . 210 | 18 | 112.5 | . 192 | 20 | 95.4 | . 250 | 28 | 162.3 | . 245 | 25 | 160.2 | . 226 | 21 | 131.5 | . 260 | 32 | 157.6 | . 230 | 25 | 158.4 | . 205 | 24 | 149.6 | . 185 | 19 | 130.4 | . 1)&#49440;&#54805;&#54924;&#44480;&#47784;&#54805; $y= beta_0+ beta_1x_1+ beta_2x_2+ epsilon$ &#51060; &#49457;&#47549;&#54620;&#45796;&#44256; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#47784;&#54805;&#51012; &#52628;&#51221;&#54616;&#50668;&#46972;. . fac &lt;- read.csv(&quot;8-1csv.csv&quot;) fac . A data.frame: 10 × 3 x1x2y_ . &lt;int&gt;&lt;int&gt;&lt;dbl&gt; . 175 | 15 | 120.4 | . 210 | 18 | 112.5 | . 192 | 20 | 95.4 | . 250 | 28 | 162.3 | . 245 | 25 | 160.2 | . 226 | 21 | 131.5 | . 260 | 32 | 157.6 | . 230 | 25 | 158.4 | . 205 | 24 | 149.6 | . 185 | 19 | 130.4 | . attach(fac) . lm81 &lt;- lm(y_~x1+x2,data=fac) . coef(lm81) . &lt;dl class=dl-inline&gt;(Intercept)35.3358543470464x10.204751085230047x22.55063256783478&lt;/dl&gt; 추정된 y는 $y=35.3359+ 0.2048x_1 + 2.5506x_2 $ 이다. . 2) &#52628;&#51221;&#46108; &#54924;&#44480;&#44228;&#49688;&#46308;&#50640; &#45824;&#54616;&#50668; $Var(b_0),Var(b_1),Var(b_2)$ &#47484; &#44396;&#54616;&#50668;&#46972;. . X &lt;- matrix(c(1,1,1,1,1,1,1,1,1,1,array(fac$x1),array(fac$x2)),10,3) beta &lt;- matrix(c(35.3359,0.2048,2.5506),3,1) . XtX &lt;- t(X) %*% X #[X&#39;X] XtX . A matrix: 3 × 3 of type dbl 10 | 2178 | 227 | . 2178 | 481940 | 50621 | . 227 | 50621 | 5385 | . XtXr &lt;- solve(XtX) # [X&#39;X]의 역함수 XtXr . A matrix: 3 × 3 of type dbl 8.99974754 | -0.065260222 | 0.234093777 | . -0.06526022 | 0.000637595 | -0.003242642 | . 0.23409378 | -0.003242642 | 0.020799716 | . $Var(b_0)$ : XtXr 의 대각 1번째 원소 $ times$ $ sigma^2$ . $8.9997 sigma^2$ . $Var(b_1)$ :XtXr 의 대각 2번째 원소 $ times$ $ sigma^2$&gt; $0.00064 sigma^2$ . $Var(b_2)$ :XtXr 의 대각 3번째 원소 $ times$ $ sigma^2$&gt; $0.0208 sigma^2$ . 3) &#52628;&#51221;&#46108; &#54924;&#44480;&#44228;&#49688; $b_1$&#44284; $b_2$&#51032; &#51032;&#48120;&#45716; &#47924;&#50631;&#51064;&#44032;? . $b_1$ : $1^ circ C$ 온도 증가에 따른 인장강도의 변화 . $b_2$ : $1$분 시간 흐름에 따른 인장강도의 변화 . 4) &#54924;&#44480;&#44228;&#49688; $ beta_1$ &#44284; $ beta_2$&#51032; 95% &#49888;&#47280;&#44396;&#44036;&#51012; &#44396;&#54616;&#50668;&#46972;. . confint(lm81) . A matrix: 3 × 2 of type dbl 2.5 %97.5 % . (Intercept)-79.4362406 | 150.107949 | . x1 -0.7612855 | 1.170788 | . x2 -2.9669628 | 8.068228 | . $ -0.7612855 &lt; beta_1 &lt; 1.170788 $ . $ -2.9669628 &lt; beta_2 &lt; 8.068228 $ . 5) &#48516;&#49328;&#48516;&#49437;&#54364;&#47484; &#51089;&#49457;&#54616;&#44256; $H_0 : beta_1 = beta_2 = 0 $ &#51012; &#50976;&#51032;&#49688;&#51456; 0.05&#47196; &#44160;&#51221;&#54616;&#50668;&#46972;. . anova(lm81) . A anova: 3 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x11 | 2747.5393 | 2747.5393 | 10.496050 | 0.01425777 | . x21 | 312.7796 | 312.7796 | 1.194869 | 0.31053404 | . Residuals7 | 1832.3821 | 261.7689 | NA | NA | . 분산분석표 . 자유도 제곱합 제곱평균 F . model | 2 | 3060 | 1530 | 6 | . error | 7 | 1832 | 262 | | . total | 9 | 4892 | | | . 유의수준 0.05 에서 F의 값보다 분산분석에서의 Fvalue(6)가 크므로 영가설을 기각하여 . $ beta_1$ 과 $ beta_2$ 가 다르다는 것을 알 수 있다. . 6) $x_1 = 200, x_2 = 20 $ &#50640;&#49436; $E(y)$ &#51032; 95% &#50696;&#52769;&#44396;&#44036;&#51012; &#44396;&#54616;&#50668;&#46972;. . q11 &lt;- data.frame(x1 = 200 , x2 = 20) . predict(lm81, q11, level=0.95 ,interval = &quot;predic&quot;) . A matrix: 1 × 3 of type dbl fitlwrupr . 1127.2987 | 86.41531 | 168.1821 | . $ hat{y} pm t times sqrt{x&#39;(X&#39;X)^{-1}x bullet MSE} $ . $ hat{y} = 127.3 , t = 2.365 , MSE = 262 , $ . $ x&#39;(X&#39;X)^{-1}x : x = c(1, 200, 20) $ 으로 계산 $ to 0.142$ . x_ &lt;- matrix(c(1,200,20),3,1) xt_ &lt;- t(x_) c_ &lt;- (xt_) %*% (XtXr) %*% (x_) c_ . A matrix: 1 × 1 of type dbl 0.1419628 | . 127.3 + 2.365*sqrt(0.142*262) . 141.725336838355 127.3 - 2.365*sqrt(0.142*262) . 112.874663161645 따라서 예측구간은 112.9 ~ 141.7 이다. . 7) &#44480;&#47924;&#44032;&#49444; $H_0 : beta_1 = beta_2$, &#45824;&#47549;&#44032;&#49444; $H_1 : beta_1 neq beta_2$ &#47484; &#50976;&#51032;&#49688;&#51456; 5%&#47196; &#44160;&#51221;&#54616;&#50668;&#46972;. . q = matrix(c(0,1,-1),3,1) b = matrix(c(35.3359,0.2048,2.5506),3,1) qb = t(q) %*% b qb . A matrix: 1 × 1 of type dbl -2.3458 | . qb/sqrt(t(q) %*% XtXr %*% q *262) #검정 t통계량 . A matrix: 1 × 1 of type dbl -0.8672862 | . 0.87 은 2.365보다 작으므로 영가설을 기각할 수 없다. 즉 $ beta_1 = beta_2 $ 가 성립한다. . 8) $x_1 =240 , x_2 =30 $ &#50640;&#49436; y&#51032; 95% &#50696;&#52769;&#44396;&#44036;&#51012; &#44396;&#54616;&#50668;&#46972;. . q10 &lt;- data.frame(x1 = 240 , x2 = 30) . predict(lm81, q10, level=0.95 ,interval = &quot;predic&quot;) . A matrix: 1 × 3 of type dbl fitlwrupr . 1160.9951 | 114.5839 | 207.4063 | . 예측구간 : (114.5839 , 207.4063)의 사이에 y가 존재할 확률이 95%라는 뜻이다. . . 8.10) . 다음의 자료에 대하여 . $y$ $x_1$ $x_2$ . 39 | 2 | 4 | . 42 | 2 | 4 | . 51 | 3 | 4 | . 48 | 3 | 4 | . 53 | 2 | 6 | . 49 | 2 | 6 | . 61 | 3 | 6 | . 60 | 3 | 6 | . 1) &#51473;&#54924;&#44480;&#47784;&#54805; $y= beta_0+ beta_1x_1+ beta_2x_2+ epsilon$&#47484; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#49440;&#51012; &#52628;&#51221;&#54616;&#50668;&#46972;. . Q810 &lt;- read.csv(&quot;810.csv&quot;,head = T) Q810 . A data.frame: 8 × 3 y_10x1_10x2_10 . &lt;int&gt;&lt;int&gt;&lt;int&gt; . 39 | 2 | 4 | . 42 | 2 | 4 | . 51 | 3 | 4 | . 48 | 3 | 4 | . 53 | 2 | 6 | . 49 | 2 | 6 | . 61 | 3 | 6 | . 60 | 3 | 6 | . attach(Q810) . lm810 &lt;- lm(y_10~x1_10+x2_10) . coef(lm810) . &lt;dl class=dl-inline&gt;(Intercept)0.375000000000071x1_109.24999999999999x2_105.37499999999999&lt;/dl&gt; $ hat{y} = 0.375 + 9.25x_1 +5.375x_2 $ . 2) &#46021;&#47549;&#48320;&#49688; $x_1$&#47564;&#51012; &#44256;&#47140;&#54620; &#54924;&#44480;&#47784;&#54805; $y= beta_0+ beta_1x_1+ epsilon$&#47484; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#49440;&#51012; &#44396;&#54616;&#50668; &#48516;&#49328;&#48516;&#49437;&#54364;&#47484; &#51089;&#49457;&#54616;&#50668;&#46972;. . lm810_1 &lt;- lm(y_10 ~ x1_10) coef(lm810_1) . &lt;dl class=dl-inline&gt;(Intercept)27.25x1_109.25&lt;/dl&gt; $ hat{y} = 27.25 + 9.25x_1 $ . ANOVA . anova(lm810_1) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x1_101 | 171.125 | 171.12500 | 4.127638 | 0.08846031 | . Residuals6 | 248.750 | 41.45833 | NA | NA | . 3) &#46021;&#47549;&#48320;&#49688; $x_2$&#47564;&#51012; &#44256;&#47140;&#54620; &#54924;&#44480;&#47784;&#54805; $y= beta_0+ beta_2x_2+ epsilon$&#47484; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#49440;&#51012; &#44396;&#54616;&#50668; &#48516;&#49328;&#48516;&#49437;&#54364;&#47484; &#51089;&#49457;&#54616;&#50668;&#46972;. . lm810_2 &lt;- lm(y_10 ~ x2_10) coef(lm810_2) . &lt;dl class=dl-inline&gt;(Intercept)23.5x2_105.375&lt;/dl&gt; $ hat{y} = 23.5 +5.375x_2 $ . ANOVA . anova(lm810_2) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x2_101 | 231.125 | 231.12500 | 7.34702 | 0.03508095 | . Residuals6 | 188.750 | 31.45833 | NA | NA | . 4) &#45800;&#50948;&#44600;&#51060;&#48277;&#50640; &#51032;&#54616;&#50668; &#54364;&#51456;&#54868;&#46108; &#54924;&#44480;&#44228;&#49688;&#47484; &#44396;&#54616;&#50668; &#54924;&#44480;&#49440;&#51012; &#52628;&#51221;&#54616;&#50668;&#46972;. . - . - . - . - . - . - . - . - . - . - . - . $y=0.6384x_1 + 0.7419x_2$ 을 추정할 수 있다. . 5) &#54364;&#51456;&#54868;&#46108; &#54924;&#44480;&#47784;&#54805;&#50640; &#51032;&#54616;&#50668; &#48516;&#49328;&#48516;&#49437;&#54364;&#47484; &#51089;&#49457;&#54616;&#50668;&#46972;. . - . - . - . - . - . - . - . - . - . - . - . 6) 4)&#50640;&#49436; &#44228;&#49328;&#46108; &#54924;&#44480;&#44228;&#49688;&#46308;&#51032; &#49345;&#44288;&#54665;&#47148;&#51012; &#44228;&#49328;&#54616;&#44256; &#49345;&#44288;&#51060; &#51316;&#51116;&#54616;&#45716;&#51648;&#47484; &#49444;&#47749;&#54616;&#50668;&#46972;. . - . - . - . - . . 8.15) . 다음과 같은 자료에 대하여 중회귀모형 $y= beta_0+ beta_1x_1+ beta_2x_2+ epsilon$를 가정하고 아래의 질문에 답하여라. . $y$ $x_1$ $x_2$ . 11 | -5 | 5 | . 11 | 4 | 4 | . 8 | -1 | 1 | . 2 | 2 | -3 | . 5 | 2 | -2 | . 5 | 3 | -2 | . 4 | 3 | -3 | . 1) &#48516;&#49328;&#48516;&#49437;&#54364;&#47484; &#51089;&#49457;&#54616;&#44256; $H_0 : beta_1 = beta_2 = 0 $ &#51012; $ alpha = 0.05 $&#47196; &#44160;&#51221;&#54616;&#50668;&#46972;. . y15 &lt;- c(11,11,8,2,5,5,4) x1_15 &lt;- c(-5,4,-1,2,2,3,3) x2_15 &lt;- c(5,4,1,-3,-2,-2,-3) lm815 &lt;- lm(y15 ~ x1_15+x2_15) coef(lm815) . &lt;dl class=dl-inline&gt;(Intercept)6.43310529293761x1_150.121032868679595x2_151.07700221182038&lt;/dl&gt; $y=6.43310529293761 + 0.121032868679595x_1 + 1.07700221182038x_2$ . anova(lm815) . A anova: 3 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x1_151 | 15.879334 | 15.8793343 | 20.48100 | 0.010612931 | . x2_151 | 54.733671 | 54.7336707 | 70.59492 | 0.001098159 | . Residuals4 | 3.101281 | 0.7753202 | NA | NA | . Fvalue 가 6.94 보다 크므로 영가설을 기각하여 $ beta_1$ 과 $ beta_2$ 가 다르다는 것을 알 수 있다. . 2) $R( beta_0), R( beta_1, beta_2| beta_0),R( beta_1| beta_0),R( beta_2| beta_0)$ &#51012; &#44033;&#44033; &#44396;&#54616;&#50668;&#46972;. . $R( beta_1, beta_2| beta_0)$ = 15.879334 . anova(lm815) . A anova: 3 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x1_151 | 15.879334 | 15.8793343 | 20.48100 | 0.010612931 | . x2_151 | 54.733671 | 54.7336707 | 70.59492 | 0.001098159 | . Residuals4 | 3.101281 | 0.7753202 | NA | NA | . $R( beta_1| beta_0) $=15.87933 . lm815a = lm(y15~x1_15) anova(lm815a) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x1_151 | 15.87933 | 15.87933 | 1.372815 | 0.2941169 | . Residuals5 | 57.83495 | 11.56699 | NA | NA | . $R( beta_2| beta_0)$ =70.01471 . lm815b = lm(y15~x2_15) anova(lm815b) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x2_151 | 70.01471 | 70.014706 | 94.62521 | 0.0001951318 | . Residuals5 | 3.69958 | 0.739916 | NA | NA | . $R( beta_0)$ = $ n( bar{y})^2$ =302.285714285714 . 7*mean(y15)^2 . 302.285714285714 3) $H_0 : beta_1 = 0 $ &#51012; &#48512;&#48516; F&#44160;&#51221;&#51004;&#47196; &#44032;&#49444;&#44160;&#51221;&#54616;&#50668;&#46972;. $ alpha = 0.05 $ . anova(lm815b,lm815) . A anova: 2 × 6 Res.DfRSSDfSum of SqFPr(&gt;F) . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 15 | 3.699580 | NA | NA | NA | NA | . 24 | 3.101281 | 1 | 0.598299 | 0.7716799 | 0.4292997 | . Fvalue 는 0.7717 이고, 7.71 보다 작으므로 영가설을 기각하지 않는다. 즉, $ beta_1 = 0$ 이 성립한다. . 4) $H_0 : beta_2 = 0 $ &#51012; &#48512;&#48516; F&#44160;&#51221;&#51004;&#47196; &#44032;&#49444;&#44160;&#51221;&#54616;&#50668;&#46972;. $ alpha = 0.05, alpha = 0.01 $ . anova(lm815a,lm815) . A anova: 2 × 6 Res.DfRSSDfSum of SqFPr(&gt;F) . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 15 | 57.834951 | NA | NA | NA | NA | . 24 | 3.101281 | 1 | 54.73367 | 70.59492 | 0.001098159 | . Fvalue = 70.595로 측정된다. . 유의수준 0.05일때 F값 7.71 보다 F값이 크며, 유의수준 0.01일때 F값인 21.2 보다도 F값이 크다. . 즉, 영가설은 어느 유의수준에서도 기각되어 $ beta_2$ 가 0이 아니라는 것으로 볼 수 있다. . . 8.16) . 중회귀모형 $y= X beta + epsilon, epsilon ~ N(0,I)$ 에서 $X$는 $n times (k+1)$ 이다. . 1) $Q_1 = y&#39;[I-X(X&#39;X)^{-1}X&#39;]y$ &#51032; &#48516;&#54252;&#45716;? . - . - . - . - . - . 2) $Q_2 = y&#39;X(X&#39;X)^{-1}X&#39;y$ &#51032; &#48516;&#54252;&#45716;? . - . - . - . - . - . 3) $Q_1$&#44284;$Q_2$&#44032; &#49436;&#47196; &#46021;&#47549;&#51076;&#51012; &#48372;&#50668;&#46972;. . - . - . - . - . - . 4) $ beta = 0 $ &#51060;&#46972; &#54624; &#46412; . $ frac{Q_2/(k+1)}{Q_1/(n-k-1)}$ 의 분포는? . - . - . - . - . - .",
            "url": "https://cjfal.github.io/dj/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/11/17/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D8%EC%9E%A5%ED%92%80%EC%9D%B4.html",
            "relUrl": "/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/11/17/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D8%EC%9E%A5%ED%92%80%EC%9D%B4.html",
            "date": " • Nov 17, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "데이터시각화 시험공부3",
            "content": "&#51452;&#47196;&#50416;&#45716; &#54056;&#53412;&#51648;&#46308; . import numpy as np #넘파이 import pandas as pd #판다스 from plotnine import * #플롯나인 import matplotlib.pyplot as plt #맷플랏립 import plotly.express as px #플랏리 상호작용 그래프 from IPython.display import HTML #블로그에 html로 올리려고 변환하는 패키지 import seaborn as sns # 씨본, 히스토그램 깔끔하게 그리는 패키지 import cv2 as cv from scipy import stats . . query&#47484; &#51060;&#50857;&#54620; &#54665;&#51032; &#49440;&#53469; . np.random.seed(1) df=pd.DataFrame(np.random.normal(size=(15,4)),columns=list(&#39;ABCD&#39;)) df . A&gt;0 and B&lt;0 &#51064; &#54665;&#51012; &#49440;&#53469; . df.query(&#39;A&gt;0 &amp; B&lt;0&#39;) #방법 1 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . df.query(&#39;A&gt;0 and B&lt;0&#39;) # 방법 2 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . A&lt;B&lt;C &#51064; &#54665;&#51012; &#49440;&#53469; . df.query(&#39;A&lt;B&lt;C&#39;) # 방법 1 . A B C D . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 13 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . A&gt;mean(A) &#51064; &#54665;&#51012; &#49440;&#53469; . df.A.mean() # A의 평균 구하기 . -0.018839420539994597 . df.query(&#39;A&gt;-0.018839420539994597&#39;) #방법 1 진짜 평균을 넣어줌 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 14 0.838983 | 0.931102 | 0.285587 | 0.885141 | . . meanA=df.A.mean() meanA . -0.018839420539994597 . df.query(&#39;A&gt; @meanA&#39;) #방법2 외부에 지정된 함수를 쓰기위해 @ 를 붙여줌 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 14 0.838983 | 0.931102 | 0.285587 | 0.885141 | . A&gt;mean(A) &#51060;&#44256;, A&lt;0.8 &#51064; &#44163;&#51012; &#49440;&#53469; . df.query(&#39; A&gt; @meanA and A&lt;0.8&#39;) # 방법1 . A B C D . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . df.query(&#39; A&gt; @meanA&#39; &#39; and A&lt;0.8&#39;) # 방법 2, &#39;바로 옆 띄어쓰기가 진짜 중요 . NameError Traceback (most recent call last) &lt;ipython-input-2-f44db6161dcd&gt; in &lt;module&gt; -&gt; 1 df.query(&#39; A&gt; @meanA&#39; 2 &#39; and A&lt;0.8&#39;) # 방법 2, &#39;바로 옆 띄어쓰기가 진짜 중요 NameError: name &#39;df&#39; is not defined . &#45800;&#49692;&#51064;&#45937;&#49905; . - 0, 3:5, 9:11 에 해당하는 row를 뽑고싶다. $ to$ 칼럼이름을 index로 받아서 사용한다. . df.query(&#39;index==0 or 3&lt;=index &lt;=5 or 9&lt;=index &lt;=11&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 10 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . - 응용사례1 . df.query(&#39;index==0 or index ==[8,9,10]&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 10 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . - 응용사례2 . i1= np.arange(3) i1 . array([0, 1, 2]) . df.query(&#39;index in @i1 or index==5&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . &#49884;&#44228;&#50676;&#51088;&#47308;&#50640;&#49436; &#53945;&#55176; &#50976;&#50857;&#54620; query . df2=pd.DataFrame(np.random.normal(size=(10,4)), columns=list(&#39;ABCD&#39;), index=pd.date_range(&#39;20201226&#39;,periods=10)) . df2.query( &#39; &quot;2020-12-27&quot;&lt;= index &lt;= &quot;2021-01-03&quot; &#39;) . A B C D . 2020-12-27 0.508051 | 0.622423 | -2.032805 | -0.317645 | . 2020-12-28 0.345579 | 1.451286 | 0.173676 | 0.064197 | . 2020-12-29 1.002694 | -0.912398 | -1.000506 | -1.645377 | . 2020-12-30 2.361380 | 0.991708 | -0.550669 | -0.235089 | . 2020-12-31 0.495589 | -2.142331 | -0.541152 | 0.103671 | . 2021-01-01 -1.143330 | -0.482436 | -0.486146 | 1.461083 | . 2021-01-02 0.327084 | -0.722183 | 0.665579 | -1.270762 | . 2021-01-03 1.809573 | 0.100709 | 0.802929 | 0.849023 | . df2.query( &#39; &quot;2020-12-27&quot;&lt;= index &lt;= &quot;2021-01-03&quot; &#39; &#39; and A+B &lt; C&#39;) . A B C D . 2020-12-31 0.495589 | -2.142331 | -0.541152 | 0.103671 | . 2021-01-01 -1.143330 | -0.482436 | -0.486146 | 1.461083 | . 2021-01-02 0.327084 | -0.722183 | 0.665579 | -1.270762 | . . groupby . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv&#39;) . df #항공 정보 . df.columns #열이름 나열 . https://github.com/PacktPublishing/Pandas-Cookbook/blob/master/data/descriptions/flights_description.csv | . 칼럼 설명 . - 데이터프레임을 여러개의 서브데이터프레임으로 나누는 기능 . - 단독으로 쓸 이유는 별로 없다. $ to$ 그룹을 나누고 어떠한 &quot;연산&quot;을 하기 위함 . df.groupby(by=&#39;AIRLINE&#39;) . &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f3368772fa0&gt; . 데이터프레임을 각 항공사 별로 나눔 | . - 확인 . grouped_df = df.groupby(by=&#39;AIRLINE&#39;) . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv&#39;) . grouped_df.groups . 너무 보기 힘듬 | . - 보기좋은 형태로 확인 . list(grouped_df.groups) #항공사안 카테고리의 리스트 출력 . [&#39;AA&#39;, &#39;AS&#39;, &#39;B6&#39;, &#39;DL&#39;, &#39;EV&#39;, &#39;F9&#39;, &#39;HA&#39;, &#39;MQ&#39;, &#39;NK&#39;, &#39;OO&#39;, &#39;UA&#39;, &#39;US&#39;, &#39;VX&#39;, &#39;WN&#39;] . grouped_df.get_group(&#39;AA&#39;) #항공사별로 나눈 것의 특정 카테고리를 df로 보기 . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 6 1 | 1 | 4 | AA | DFW | MSY | 1250 | 84.0 | 64.0 | 447 | 1410 | 83.0 | 0 | 0 | . 8 1 | 1 | 4 | AA | ORD | STL | 1845 | -5.0 | 44.0 | 258 | 1950 | -5.0 | 0 | 0 | . 15 1 | 1 | 4 | AA | DEN | DFW | 1445 | -6.0 | 93.0 | 641 | 1745 | 4.0 | 0 | 0 | . 26 1 | 1 | 4 | AA | LAX | AUS | 1430 | 33.0 | 157.0 | 1242 | 1925 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58470 12 | 31 | 4 | AA | DFW | FAT | 1020 | -3.0 | 196.0 | 1313 | 1156 | -2.0 | 0 | 0 | . 58475 12 | 31 | 4 | AA | IAH | CLT | 710 | 1.0 | 113.0 | 912 | 1037 | -12.0 | 0 | 0 | . 58476 12 | 31 | 4 | AA | DFW | TPA | 1020 | -3.0 | 121.0 | 929 | 1340 | -6.0 | 0 | 0 | . 58479 12 | 31 | 4 | AA | DFW | ELP | 1200 | 3.0 | 94.0 | 551 | 1250 | 13.0 | 0 | 0 | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 8900 rows × 14 columns . for g in grouped_df.groups: . print(g) display(grouped_df.get_group(g)) $ to$ 리스트 카테고리들 전부를 확인 . AIRLINE&#51012; &#44592;&#51456;&#51004;&#47196; &#45936;&#51060;&#53552;&#54532;&#47112;&#51076;&#51012; &#45208;&#45572;&#44256; $ to$ ARR_DELAY&#50640; mean&#54632;&#49688;&#47484; &#51201;&#50857;: (AIRLINE $ to$ {ARR_DELAY: mean}) . - 방법1 (기본, agg와 딕셔너리 이용) . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:&#39;mean&#39;}) . ARR_DELAY . AIRLINE . AA 5.542661 | . AS -0.833333 | . B6 8.692593 | . DL 0.339691 | . EV 7.034580 | . F9 13.630651 | . HA 4.972973 | . MQ 6.860591 | . NK 18.436070 | . OO 7.593463 | . UA 7.765755 | . US 1.681105 | . VX 5.348884 | . WN 6.397353 | . - 방법2 ($ star star star$) . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:np.mean}) . ARR_DELAY . AIRLINE . AA 5.542661 | . AS -0.833333 | . B6 8.692593 | . DL 0.339691 | . EV 7.034580 | . F9 13.630651 | . HA 4.972973 | . MQ 6.860591 | . NK 18.436070 | . OO 7.593463 | . UA 7.765755 | . US 1.681105 | . VX 5.348884 | . WN 6.397353 | . - 방법3 , 나눠진 df에서 ARR_DELAY 뽑고, 평균함수적용 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(&#39;mean&#39;) . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . - 방법4 ($ star$) . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(np.mean) . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . - 방법5 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].mean() . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . - 방법2와 방법4는 사용자정의 함수를 쓸 수 있다는 장점이 있음 . - 방법6 . def f(x): return -np.mean(x) #사용자정의함수 지정 . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:f}) . ARR_DELAY . AIRLINE . AA -5.542661 | . AS 0.833333 | . B6 -8.692593 | . DL -0.339691 | . EV -7.034580 | . F9 -13.630651 | . HA -4.972973 | . MQ -6.860591 | . NK -18.436070 | . OO -7.593463 | . UA -7.765755 | . US -1.681105 | . VX -5.348884 | . WN -6.397353 | . - 방법7 . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:lambda x: -np.mean(x)}) . ARR_DELAY . AIRLINE . AA -5.542661 | . AS 0.833333 | . B6 -8.692593 | . DL -0.339691 | . EV -7.034580 | . F9 -13.630651 | . HA -4.972973 | . MQ -6.860591 | . NK -18.436070 | . OO -7.593463 | . UA -7.765755 | . US -1.681105 | . VX -5.348884 | . WN -6.397353 | . - 방법8 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(lambda x: -np.mean(x)) . AIRLINE AA -5.542661 AS 0.833333 B6 -8.692593 DL -0.339691 EV -7.034580 F9 -13.630651 HA -4.972973 MQ -6.860591 NK -18.436070 OO -7.593463 UA -7.765755 US -1.681105 VX -5.348884 WN -6.397353 Name: ARR_DELAY, dtype: float64 . &#51077;&#47141;&#51060; &#50668;&#47084;&#44060;&#51064; &#49324;&#50857;&#51088; &#51221;&#51032; &#54632;&#49688;&#51032; &#49324;&#50857; . def f(x,y): return np.mean(x)**y . - 방법1 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(f,2) . AIRLINE AA 30.721086 AS 0.694444 B6 75.561166 DL 0.115390 EV 49.485310 F9 185.794656 HA 24.730460 MQ 47.067715 NK 339.888677 OO 57.660681 UA 60.306954 US 2.826113 VX 28.610564 WN 40.926120 Name: ARR_DELAY, dtype: float64 . - 방법2 . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;: lambda x: f(x,2)}) . ARR_DELAY . AIRLINE . AA 30.721086 | . AS 0.694444 | . B6 75.561166 | . DL 0.115390 | . EV 49.485310 | . F9 185.794656 | . HA 24.730460 | . MQ 47.067715 | . NK 339.888677 | . OO 57.660681 | . UA 60.306954 | . US 2.826113 | . VX 28.610564 | . WN 40.926120 | . &#54876;&#50857; . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum} . - 방법1~5 . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:&#39;sum&#39;}) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:np.sum}) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].agg(&#39;sum&#39;) . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].agg(np.sum) . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].sum() . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum, mean} , {DIVERTED: sum, mean} . - 방법 1~4 (5번은 쓸 수 없다) . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[&#39;sum&#39;,&#39;mean&#39;],&#39;DIVERTED&#39;:[&#39;sum&#39;,&#39;mean&#39;]}) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[np.sum,np.mean],&#39;DIVERTED&#39;:[np.sum,np.mean]}) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[[&#39;CANCELLED&#39;,&#39;DIVERTED&#39;]].agg([&#39;sum&#39;,&#39;mean&#39;]) #컬럼을 리스트로 전달 . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[[&#39;CANCELLED&#39;,&#39;DIVERTED&#39;]].agg([np.sum,np.mean]) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum, mean, size} , {AIR_TIME: mean,var} . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[&#39;sum&#39;,&#39;mean&#39;,&#39;size&#39;],&#39;AIR_TIME&#39;:[&#39;mean&#39;,&#39;var&#39;]}) #딕셔너리 활용 . CANCELLED AIR_TIME . sum mean size mean var . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]) .agg({&#39;CANCELLED&#39;:[np.sum,np.mean,len],&#39;AIR_TIME&#39;:[np.mean,lambda x: np.std(x,ddof=1)**2]}) . CANCELLED AIR_TIME . sum mean len mean &lt;lambda_0&gt; . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . grouping by continuous variable &#50672;&#49549;&#54805;&#48320;&#49688; &#44536;&#47353;&#54868; . df . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 0 1 | 1 | 4 | WN | LAX | SLC | 1625 | 58.0 | 94.0 | 590 | 1905 | 65.0 | 0 | 0 | . 1 1 | 1 | 4 | UA | DEN | IAD | 823 | 7.0 | 154.0 | 1452 | 1333 | -13.0 | 0 | 0 | . 2 1 | 1 | 4 | MQ | DFW | VPS | 1305 | 36.0 | 85.0 | 641 | 1453 | 35.0 | 0 | 0 | . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 4 1 | 1 | 4 | WN | LAX | MCI | 1720 | 48.0 | 166.0 | 1363 | 2225 | 39.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 58488 12 | 31 | 4 | F9 | LAS | SFO | 1910 | 13.0 | 71.0 | 414 | 2050 | 4.0 | 0 | 0 | . 58489 12 | 31 | 4 | OO | SFO | SBA | 1846 | -6.0 | 46.0 | 262 | 1956 | -5.0 | 0 | 0 | . 58490 12 | 31 | 4 | WN | MSP | ATL | 525 | 39.0 | 124.0 | 907 | 855 | 34.0 | 0 | 0 | . 58491 12 | 31 | 4 | OO | SFO | BOI | 859 | 5.0 | 73.0 | 522 | 1146 | -1.0 | 0 | 0 | . 58492 rows × 14 columns . - 목표: DIST를 적당한 구간으로 나누어 카테고리화 하고 그것을 바탕으로 groupby를 수행하자. . df.DIST.hist() #앞쪽에 몰려있음 . &lt;AxesSubplot:&gt; . df.DIST.describe() #대략적 통계값 산출 . count 58492.000000 mean 872.900072 std 624.996805 min 67.000000 25% 391.000000 50% 690.000000 75% 1199.000000 max 4502.000000 Name: DIST, dtype: float64 . - 구간을 아래와 같이 설정한다. . bins=[-np.inf, 400, 700, 1200, np.inf] # -무한대 ~400 ~700 ~1200 ~무한대 . - pd.cut()을 이용하여 각 구간의 observation을 카테고리화(mapping) 하자. . cuts=pd.cut(df.DIST,bins=bins) #(적용할 칼럼, bins=구간) cuts . 0 (400.0, 700.0] 1 (1200.0, inf] 2 (400.0, 700.0] 3 (700.0, 1200.0] 4 (1200.0, inf] ... 58487 (1200.0, inf] 58488 (400.0, 700.0] 58489 (-inf, 400.0] 58490 (700.0, 1200.0] 58491 (400.0, 700.0] Name: DIST, Length: 58492, dtype: category Categories (4, interval[float64]): [(-inf, 400.0] &lt; (400.0, 700.0] &lt; (700.0, 1200.0] &lt; (1200.0, inf]] . - cuts, AIRLINE $ to$ {DIVERTED: sum} . df.groupby([cuts,&#39;AIRLINE&#39;]).agg({&#39;DIVERTED&#39;:sum}) #구분별 항공사 diverted합 산출 . DIVERTED . DIST AIRLINE . (-inf, 400.0] AA 0 | . AS 0 | . B6 0 | . DL 1 | . EV 3 | . F9 0 | . HA 0 | . MQ 0 | . NK 0 | . OO 5 | . UA 2 | . US 0 | . VX 0 | . WN 1 | . (400.0, 700.0] AA 3 | . AS 0 | . B6 0 | . DL 12 | . EV 8 | . F9 1 | . HA 0 | . MQ 4 | . NK 1 | . OO 7 | . UA 1 | . US 0 | . VX 0 | . WN 2 | . (700.0, 1200.0] AA 10 | . AS 0 | . B6 1 | . DL 6 | . EV 4 | . F9 0 | . HA 0 | . MQ 1 | . NK 1 | . OO 5 | . UA 4 | . US 0 | . VX 0 | . WN 4 | . (1200.0, inf] AA 13 | . AS 0 | . B6 1 | . DL 5 | . EV 0 | . F9 1 | . HA 1 | . MQ 0 | . NK 3 | . OO 4 | . UA 12 | . US 1 | . VX 1 | . WN 8 | . - 아래와 비교해보자. . df.groupby([&#39;AIRLINE&#39;]).agg({&#39;DIVERTED&#39;:sum}) . DIVERTED . AIRLINE . AA 26 | . AS 0 | . B6 2 | . DL 24 | . EV 15 | . F9 2 | . HA 1 | . MQ 5 | . NK 5 | . OO 21 | . UA 19 | . US 1 | . VX 1 | . WN 15 | . - cuts을 이용하여 추가그룹핑을 하면 조금 다른 특징들을 데이터에서 발견할 수 있다. . AA항공사와 DL항공사는 모두 비슷한 우회횟수를 가지고 있음. | AA항공사는 700회이상의 구간에서 우회를 많이하고 DL항공사는 400~700사이에서 우회를 많이 한다. (패턴이 다름) 상세한 패턴 확인 가능 | . - 구간이름에 label을 붙이는 방법 labels=[] 이용 . bins . [-inf, 400, 700, 1200, inf] . cuts2=pd.cut(df.DIST,bins=bins,labels=[&#39;Q1&#39;,&#39;Q2&#39;,&#39;Q3&#39;,&#39;Q4&#39;]) cuts2 . 0 Q2 1 Q4 2 Q2 3 Q3 4 Q4 .. 58487 Q4 58488 Q2 58489 Q1 58490 Q3 58491 Q2 Name: DIST, Length: 58492, dtype: category Categories (4, object): [&#39;Q1&#39; &lt; &#39;Q2&#39; &lt; &#39;Q3&#39; &lt; &#39;Q4&#39;] . df.groupby(by=[cuts2,&#39;AIRLINE&#39;]).agg({&#39;DIVERTED&#39;:sum}) . DIVERTED . DIST AIRLINE . Q1 AA 0 | . AS 0 | . B6 0 | . DL 1 | . EV 3 | . F9 0 | . HA 0 | . MQ 0 | . NK 0 | . OO 5 | . UA 2 | . US 0 | . VX 0 | . WN 1 | . Q2 AA 3 | . AS 0 | . B6 0 | . DL 12 | . EV 8 | . F9 1 | . HA 0 | . MQ 4 | . NK 1 | . OO 7 | . UA 1 | . US 0 | . VX 0 | . WN 2 | . Q3 AA 10 | . AS 0 | . B6 1 | . DL 6 | . EV 4 | . F9 0 | . HA 0 | . MQ 1 | . NK 1 | . OO 5 | . UA 4 | . US 0 | . VX 0 | . WN 4 | . Q4 AA 13 | . AS 0 | . B6 1 | . DL 5 | . EV 0 | . F9 1 | . HA 1 | . MQ 0 | . NK 3 | . OO 4 | . UA 12 | . US 1 | . VX 1 | . WN 8 | . df.groupby(cuts2).agg({&#39;DIVERTED&#39;:len}) . DIVERTED . DIST . Q1 15027 | . Q2 14697 | . Q3 14417 | . Q4 14351 | . . tidy data . ggplot으로 그림그리기 좋은 데이터 + pandas로 query, group by 등을 쓰기 좋은 자료 . Each variable must have its own column. | Each observation must have its own row. | Each value must have its own cell. | . tidy data는 보통 세로로 긴 데이터를 가짐 . &#50696;&#51228; tidy data . &#54400;&#51060;1: stack + reset_index . - 문제의 깃헙주소로 들어가서 데이터를 관찰 $ to$ 좌측상단이 비워져있음(Unnamed: 0) $ to$ index_col=0 옵션을 사용 . url = &#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/state_fruit.csv&#39; df=pd.read_csv(url,index_col=0) df . Apple Orange Banana . Texas 12 | 10 | 40 | . Arizona 9 | 7 | 12 | . Florida 0 | 14 | 190 | . &#45936;&#51060;&#53552;&#48320;&#54805; . df.stack() # 우리가 원하는 형태가 아님 #멀티인덱스로 되어있어서 tidy가 아님, 칼럼도 없음 . Texas Apple 12 Orange 10 Banana 40 Arizona Apple 9 Orange 7 Banana 12 Florida Apple 0 Orange 14 Banana 190 dtype: int64 . df.stack().reset_index() # 인덱스가 0~8이고 범주형변수로 나뉘어짐 . level_0 level_1 0 . 0 Texas | Apple | 12 | . 1 Texas | Orange | 10 | . 2 Texas | Banana | 40 | . 3 Arizona | Apple | 9 | . 4 Arizona | Orange | 7 | . 5 Arizona | Banana | 12 | . 6 Florida | Apple | 0 | . 7 Florida | Orange | 14 | . 8 Florida | Banana | 190 | . df.stack().reset_index().rename(columns={&#39;level_0&#39;:&#39;group1&#39;,&#39;level_1&#39;:&#39;group2&#39;,0:&#39;X&#39;}) #tidy data! 인덱스도 쉽고, 범주로 나뉘어서 query,groupby 도 쉬워짐 . group1 group2 X . 0 Texas | Apple | 12 | . 1 Texas | Orange | 10 | . 2 Texas | Banana | 40 | . 3 Arizona | Apple | 9 | . 4 Arizona | Orange | 7 | . 5 Arizona | Banana | 12 | . 6 Florida | Apple | 0 | . 7 Florida | Orange | 14 | . 8 Florida | Banana | 190 | . &#54400;&#51060;2: melt(id_vars=??) . - index_col=0 옵션을 몰랐다면 어떻게 tidydata로 만들까? . url = &#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/state_fruit.csv&#39; df2=pd.read_csv(url) df2 . Unnamed: 0 Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}) #Unnamed: 0 이 너무 불편해서 그룹1로 바꿈 . group1 Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}).melt() #세로로 바뀌었지만 그룹1이 뭔가 이상함 . variable value . 0 group1 | Texas | . 1 group1 | Arizona | . 2 group1 | Florida | . 3 Apple | 12 | . 4 Apple | 9 | . 5 Apple | 0 | . 6 Orange | 10 | . 7 Orange | 7 | . 8 Orange | 14 | . 9 Banana | 40 | . 10 Banana | 12 | . 11 Banana | 190 | . df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}).melt(id_vars=&#39;group1&#39;) # 수정된 melt형태, 그룹1은 열로 빼고 싶다. . group1 variable value . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}).melt(id_vars=&#39;group1&#39;) .rename(columns={&#39;variable&#39;:&#39;group2&#39;,&#39;value&#39;:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . &#54400;&#51060;3 reset_index + melt . df . Apple Orange Banana . Texas 12 | 10 | 40 | . Arizona 9 | 7 | 12 | . Florida 0 | 14 | 190 | . df.reset_index() . index Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df.reset_index().melt(id_vars=&#39;index&#39;) #melt는 사용하나 index칼럼은 칼럼의 범주로 넣어줌 . index variable value . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . df.reset_index().melt(id_vars=&#39;index&#39;) .rename(columns={&#39;index&#39;:&#39;group1&#39;,&#39;variable&#39;:&#39;group2&#39;,&#39;value&#39;:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . &#54400;&#51060;4 set_index + stack + reset_index + rename . df2.set_index(&#39;Unnamed: 0&#39;) . Apple Orange Banana . Unnamed: 0 . Texas 12 | 10 | 40 | . Arizona 9 | 7 | 12 | . Florida 0 | 14 | 190 | . df2.set_index(&#39;Unnamed: 0&#39;).stack() . Unnamed: 0 Texas Apple 12 Orange 10 Banana 40 Arizona Apple 9 Orange 7 Banana 12 Florida Apple 0 Orange 14 Banana 190 dtype: int64 . df2.set_index(&#39;Unnamed: 0&#39;).stack().reset_index() . Unnamed: 0 level_1 0 . 0 Texas | Apple | 12 | . 1 Texas | Orange | 10 | . 2 Texas | Banana | 40 | . 3 Arizona | Apple | 9 | . 4 Arizona | Orange | 7 | . 5 Arizona | Banana | 12 | . 6 Florida | Apple | 0 | . 7 Florida | Orange | 14 | . 8 Florida | Banana | 190 | . df2.set_index(&#39;Unnamed: 0&#39;).stack().reset_index() .rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;,&#39;level_1&#39;:&#39;group2&#39;,0:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Texas | Orange | 10 | . 2 Texas | Banana | 40 | . 3 Arizona | Apple | 9 | . 4 Arizona | Orange | 7 | . 5 Arizona | Banana | 12 | . 6 Florida | Apple | 0 | . 7 Florida | Orange | 14 | . 8 Florida | Banana | 190 | . . Barplot + &#54644;&#46308;&#47532;&#50948;&#52980;&#51032; &#44536;&#47000;&#54532;&#47112;&#51060;&#50612; . &#44592;&#48376;&#49324;&#50857;&#48277; . g=[&#39;A&#39;]*100+[&#39;B&#39;]*200 y=list(np.random.randn(100)*2+2)+list(np.random.randn(200)+3) df=pd.DataFrame({&#39;g&#39;:g,&#39;y&#39;:y}) df . g y . 0 A | -1.594055 | . 1 A | 1.225490 | . 2 A | 2.223234 | . 3 A | 1.842460 | . 4 A | 1.624541 | . ... ... | ... | . 295 B | 3.011681 | . 296 B | 3.558141 | . 297 B | 4.348230 | . 298 B | 3.966407 | . 299 B | 2.694083 | . 300 rows × 2 columns . ggplot(df)+geom_bar(aes(x=&#39;g&#39;,fill=&#39;g&#39;)) ## 디폴트로 카운트를 수행해줌 #안쪽을 채우려면 fill= 이용, 직관적이지는 않다. . &lt;ggplot: (8726962443840)&gt; . df.groupby(by=&#39;g&#39;).count() # = df.groupby(by=&#39;g&#39;).agg({&#39;y&#39;:len}) .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/11/07/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%8B%9C%ED%97%98%EA%B3%B5%EB%B6%803.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/11/07/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%8B%9C%ED%97%98%EA%B3%B5%EB%B6%803.html",
            "date": " • Nov 7, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "데이터시각화 시험공부2",
            "content": "&#51452;&#47196;&#50416;&#45716; &#54056;&#53412;&#51648;&#46308; . import numpy as np #넘파이 import pandas as pd #판다스 from plotnine import * #플롯나인 import matplotlib.pyplot as plt #맷플랏립 import plotly.express as px #플랏리 상호작용 그래프 from IPython.display import HTML #블로그에 html로 올리려고 변환하는 패키지 import seaborn as sns # 씨본, 히스토그램 깔끔하게 그리는 패키지 import cv2 as cv from scipy import stats . rpy2 . import rpy2 . R 에서 저장된 데이터를 불러오는 함수,패키지 . . &#45936;&#51060;&#53552; &#44032;&#51648;&#44256; &#45440;&#44592;(&#49328;&#51216;&#46020; &#51025;&#50857;) . &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44256; &#45824;&#47029;&#51201;&#51064; &#54644;&#49437;(plotnine&#51032; ggplot) . mpg = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/mpg.csv&#39;) . ggplot(data = mpg) + geom_point(mapping = aes(x = &quot;displ&quot;, y = &quot;hwy&quot;)) ## plotnine(R의 ggplot 짭퉁) # 빠르게 그리기: `mapping = ` 와 `data=`는 생략가능함 # = ggplot(mpg) + geom_point(aes(x = &quot;displ&quot;, y = &quot;hwy&quot;)) ## plotnine . &lt;ggplot: (8782640468625)&gt; . 산점도: 엔진크기displ와 연료효율hwy은 반비례. (엔진이 큰 차일수록 연비가 좋지 않다) | . ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) . 진짜 ggplot에서 그릴때에는 변수이름에 &quot;&quot; 를 제거함 . &#49328;&#51216;&#46020;&#51025;&#50857; (3&#52264;&#50896;) . - 데이터를 다시관찰 . mpg.head() . manufacturer model displ year cyl trans drv cty hwy fl class . 1 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 2 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 4 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 5 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . - class도 함께 plot에 표시하면 데이터를 탐색할때 좀 더 좋을것 같다. . &#49328;&#51216;&#46020; + &#51216;&#53356;&#44592;&#48320;&#44221; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,size= &#39;class&#39;)) # ,size = &#39;class&#39; 추가로 산점도의 점크기 변경을 통해 3차원 해석 가능 #하지만 색이 같아서 알아보기 힘들다. . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8782640390747)&gt; . &#49328;&#51216;&#46020; + &#53804;&#47749;&#46020;&#48320;&#44221; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,alpha= &#39;class&#39;)) # alpha=&#39;class&#39; 의 추가로 산점도에 크기가 아닌 투명도로 3차원 그래프 생성 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_alpha.py:68: PlotnineWarning: Using alpha for a discrete variable is not advised. . &lt;ggplot: (8745132609895)&gt; . &#49328;&#51216;&#46020;&#50640; &#51216;&#53356;&#44592; + &#53804;&#47749;&#46020; &#54633;&#54616;&#50668; 3&#52264;&#50896; &#54364;&#44592; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,size= &#39;class&#39;,alpha=&#39;class&#39;)) . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_alpha.py:68: PlotnineWarning: Using alpha for a discrete variable is not advised. . &lt;ggplot: (8782640337583)&gt; . &#49328;&#51216;&#46020; + &#54805;&#53468;(&#51216;&#51032; &#47784;&#50577;) . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,shape=&#39;class&#39;)) # shape = &#39;class&#39; 추가로 모양을 통한 3차원 해석 . &lt;ggplot: (8782640285946)&gt; . &#49328;&#51216;&#46020; + &#49353;&#44628; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;)) # color = &#39;class&#39; 를 통해 색깔을 통한 3차원 해석 . &lt;ggplot: (8782640439414)&gt; . &#50612;&#47157;&#44172; &#44536;&#47532;&#44592; . fig=ggplot(data=mpg) #도화지를 준비한다 a1=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;) #변수와 에스테틱사이의 맵핑을 설정한다. point1=geom_point(mapping=a1) #점들의 집합을 만든다. 즉 포인트지옴을 만든다. fig+point1 #도화지와 지옴을 합친다. . &lt;ggplot: (8782638599304)&gt; . &#44061;&#52404; &#51648;&#54693;&#51201;&#51004;&#47196; &#44536;&#47532;&#44592; . a2=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;) . a1,a2 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . point2=geom_point(a2) . fig+point2 . &lt;ggplot: (8782638599244)&gt; . &#44536;&#47000;&#54532;&#50640; &#51201;&#54633;&#49440; &#52628;&#44032; . sline1=geom_smooth(a1) . fig+point1+sline1 . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8782638568807)&gt; . fig+point2+sline1 . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8782638484258)&gt; . ggplot(data=mpg)+geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;))+geom_smooth(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;)) # 명렁어를 통해 한번에 그리기 . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8782638434226)&gt; . - 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함) . ggplot(data=mpg,mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;))+geom_point(mapping=aes(color=&#39;class&#39;))+geom_smooth() . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8745132650084)&gt; . - R에서는 confidence interval도 geom_smooth()를 이용하여 확인할 수 있다. . . &#49328;&#51216;&#46020;&#51025;&#50857;2 (4&#52264;&#50896;) . drv (전륜, 후륜, 4륜 구동)에 따라서 데이터를 시각화 하고 싶다. . ggplot(data=mpg,mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;))+geom_point(mapping=aes(size=&#39;class&#39;,color=&#39;drv&#39;),alpha=0.2) . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8782638480496)&gt; . 모든 $x$에 대하여 붉은색 점들이 대부분 초록선과 보라색 점들에 비하여 아래쪽에 위치하여 있음 $ to$ 4륜구동방식이 연비가 좋지 않음 | . - 객체지향적 . a3=a2.copy() #a2를 복사하지만 저장된 id는 다름 . id(a1),id(a2),id(a3) . (140522217560720, 140522217562000, 140522213860432) . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . a3[&#39;color&#39;]=&#39;drv&#39; a3[&#39;size&#39;]=&#39;class&#39; . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}) . 아래와 같이 선언해도 괜찮음 a3=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;drv&#39;,size=&#39;class&#39;) . | . point3=geom_point(a3,alpha=0.2) #alpha 로 투명도 조절 . fig+point3 . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8782638340422)&gt; . - 여기에 선을 추가하여 보자. . fig+point3+sline1 . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8782638289195)&gt; . &#44033; &#44536;&#47353;&#48324;&#47196; &#49440;&#51012; &#46384;&#47196; &#44536;&#47532;&#44592; . a4=a2.copy() . a4[&#39;color&#39;]=&#39;drv&#39; . sline2=geom_smooth(a4) . fig+sline2+point3 . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8782638289165)&gt; . &#49440;&#51032; &#49353;&#44628;&#51012; &#46041;&#51068;&#54616;&#44172; &#54616;&#44256; &#49440;&#51032; &#53440;&#51077;&#51012; &#48320;&#44221;&#54616;&#50668; &#44536;&#47353;&#51012; &#54364;&#49884; . a5=a1.copy() . a5[&#39;linetype&#39;]=&#39;drv&#39; . a5 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;linetype&#39;: &#39;drv&#39;} . sline3=geom_smooth(a5,size=0.5,color=&#39;gray&#39;) . fig+point3+sline3 . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8782638256240)&gt; . fig+point3+sline3+sline1 . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8782638252496)&gt; . sline2=geom_smooth(a4,size=0.5,linetype=&#39;dashed&#39;) fig+point3+sline2+sline1 # 그래도 색으로 수분하는 것이 시각적으로 훌륭해보임 . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8782716497014)&gt; . - 고차원의 변수를 표현할 수 있는 무기는 다양하다. . 산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도 | 라인플랏(스무스지옴, 라인지옴): 선의형태, 선의색깔, 선의굵기 | . &#44208;&#47200; . - 잘 훈련한다면 여러가지 형태의 고차원 그래프를 우리도 그릴 수 있다. (마치 미나드처럼) . - 해들리위컴은 이러한 방법을 체계적으로 정리했다고 보여진다. . - 해들리위컴: 그래프는 데이터 + 지옴 + 맵핑(변수와 에스테틱간의 맵핑) + 스탯(통계) + 포지션 + 축 + 패싯그리드 7개의 조합으로 그릴수 있다. . 내생각: 지옴과 맵핑만 잘 이용해도 아주 다양한 그래프를 그릴 수 있음. | . . &#54032;&#45796;&#49828;&#50640;&#49436; column&#51012; &#49440;&#53469;&#54616;&#45716; &#48169;&#48277; . &#50696;&#51228;1 &#50676; &#44256;&#47476;&#44592; . 예제 df 생성 . dic={&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5)} df=pd.DataFrame(dic) df . X1 X2 X3 . 0 0.316403 | 1.819641 | -0.535532 | . 1 -0.490887 | 1.222014 | -0.886578 | . 2 0.175277 | 1.124193 | 0.919066 | . 3 -1.996759 | -0.253654 | 0.214364 | . 4 0.359407 | -0.505990 | -0.342295 | . df.X1 #방법 1 . 0 0.316403 1 -0.490887 2 0.175277 3 -1.996759 4 0.359407 Name: X1, dtype: float64 . df[&#39;X1&#39;] #방법 2 series를 리턴 . 0 0.316403 1 -0.490887 2 0.175277 3 -1.996759 4 0.359407 Name: X1, dtype: float64 . df[[&#39;X1&#39;]] #방법 3 dataframe을 리턴 . X1 . 0 0.316403 | . 1 -0.490887 | . 2 0.175277 | . 3 -1.996759 | . 4 0.359407 | . df.loc[:,&#39;X1&#39;] #방법 4 loc 이용 , series 리턴 . 0 0.316403 1 -0.490887 2 0.175277 3 -1.996759 4 0.359407 Name: X1, dtype: float64 . df.loc[:,[&#39;X1&#39;]] #방법 5 loc 이용 , dataframe 리턴 . X1 . 0 0.316403 | . 1 -0.490887 | . 2 0.175277 | . 3 -1.996759 | . 4 0.359407 | . df.loc[:,[True,False,False]] #방법 6 , bull 인덱싱 (첫번째 열만 True로 불러오겠다.) . X1 . 0 0.316403 | . 1 -0.490887 | . 2 0.175277 | . 3 -1.996759 | . 4 0.359407 | . df.iloc[:,0] # 방법 7 , 0번째 ( 파이썬이라 0이 1 ), series 리턴 . 0 0.316403 1 -0.490887 2 0.175277 3 -1.996759 4 0.359407 Name: X1, dtype: float64 . df.iloc[:,[0]] # 방법 8 , 0번째 데이터 프레임 리턴 . X1 . 0 0.316403 | . 1 -0.490887 | . 2 0.175277 | . 3 -1.996759 | . 4 0.359407 | . df.iloc[:,[True,False,False]] #방법9 , bull형 iloc . X1 . 0 0.316403 | . 1 -0.490887 | . 2 0.175277 | . 3 -1.996759 | . 4 0.359407 | . - df.X1로 열을 선택하는게 간단하고 편리함. . 단점1: 변수이름을 알고 있어야 한다는 단점이 있음. | 단점2: 변수이름에 .이 있거나 변수이름에서 공백이 있을경우 사용할 수 없음. | . 단점의 예시 . dic={&#39;X.1&#39;:np.random.normal(0,1,5), &#39;X.2&#39;:np.random.normal(0,1,5), &#39;X.3&#39;:np.random.normal(0,1,5)} _df=pd.DataFrame(dic) _df . X.1 X.2 X.3 . 0 0.135452 | -1.312018 | -0.431092 | . 1 -0.531713 | -0.235149 | 0.523488 | . 2 0.360346 | 0.805032 | -1.374940 | . 3 -1.082895 | -0.941979 | 0.687203 | . 4 0.654108 | 0.098545 | 0.870038 | . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) . &#50668;&#47084;&#44060;&#51032; &#50676;&#51012; &#49440;&#53469;&#54616;&#44592; . dic2={&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5), &#39;X4&#39;:np.random.normal(0,1,5)} df2=pd.DataFrame(dic2) df2 . X1 X2 X3 X4 . 0 -0.289599 | -1.360181 | -1.383041 | 0.039000 | . 1 2.079617 | 0.387465 | 0.409297 | -0.125807 | . 2 0.239503 | -0.119209 | -0.366100 | -0.463638 | . 3 2.425258 | -0.832763 | -0.770286 | -0.015144 | . 4 1.337020 | 0.066310 | 1.293585 | -1.537895 | . df2[[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;]] #방법 1 . X1 X2 X3 . 0 -0.289599 | -1.360181 | -1.383041 | . 1 2.079617 | 0.387465 | 0.409297 | . 2 0.239503 | -0.119209 | -0.366100 | . 3 2.425258 | -0.832763 | -0.770286 | . 4 1.337020 | 0.066310 | 1.293585 | . df2.loc[:,[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;]] #방법 2 . X1 X2 X3 . 0 -0.289599 | -1.360181 | -1.383041 | . 1 2.079617 | 0.387465 | 0.409297 | . 2 0.239503 | -0.119209 | -0.366100 | . 3 2.425258 | -0.832763 | -0.770286 | . 4 1.337020 | 0.066310 | 1.293585 | . df2.loc[:,&#39;X1&#39;:&#39;X3&#39;] #방법 3 . X1 X2 X3 . 0 -0.289599 | -1.360181 | -1.383041 | . 1 2.079617 | 0.387465 | 0.409297 | . 2 0.239503 | -0.119209 | -0.366100 | . 3 2.425258 | -0.832763 | -0.770286 | . 4 1.337020 | 0.066310 | 1.293585 | . df2.loc[:,[True,True,True,False]] #방법 4 . X1 X2 X3 . 0 -0.289599 | -1.360181 | -1.383041 | . 1 2.079617 | 0.387465 | 0.409297 | . 2 0.239503 | -0.119209 | -0.366100 | . 3 2.425258 | -0.832763 | -0.770286 | . 4 1.337020 | 0.066310 | 1.293585 | . df2.iloc[:,[0,1,2]] #방법 5 . X1 X2 X3 . 0 -0.289599 | -1.360181 | -1.383041 | . 1 2.079617 | 0.387465 | 0.409297 | . 2 0.239503 | -0.119209 | -0.366100 | . 3 2.425258 | -0.832763 | -0.770286 | . 4 1.337020 | 0.066310 | 1.293585 | . df2.iloc[:,:3] #방법 6 # = df2.iloc[:,0:3] # = df2.iloc[:,range(3)] . X1 X2 X3 . 0 -0.289599 | -1.360181 | -1.383041 | . 1 2.079617 | 0.387465 | 0.409297 | . 2 0.239503 | -0.119209 | -0.366100 | . 3 2.425258 | -0.832763 | -0.770286 | . 4 1.337020 | 0.066310 | 1.293585 | . df2.iloc[:,[True,True,True,False]] #방법 7 , iloc + bull . X1 X2 X3 . 0 -0.289599 | -1.360181 | -1.383041 | . 1 2.079617 | 0.387465 | 0.409297 | . 2 0.239503 | -0.119209 | -0.366100 | . 3 2.425258 | -0.832763 | -0.770286 | . 4 1.337020 | 0.066310 | 1.293585 | . 그래서 column의 이름이 integer일 경우는 종종 매우 헷갈리는 일이 일어남 . Note: 사실 이것은 일부러 헷갈리게 예제를 구성한 것이다. 실제로는 헷갈리는 상황이 그렇게 자주 발생하지 않는다. 왜냐하면 보통 위와 같은 형태의 자료는 ndarray로 처리하고 colname이 있는 경우만 데이터프레임으로 처리하기 때문. . . &#49892;&#51204; &#50696;&#51228; . movie data - 특정조건에 맞는 열을 선택 . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) . df.columns #열의 이름 출력 . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . df.loc[:,[&#39;color&#39;:&#39;num_voted_users&#39;,&#39;aspect_ratio&#39;]] #출력이 안됨 . File &#34;&lt;ipython-input-92-5458cab12328&gt;&#34;, line 1 df.loc[:,[&#39;color&#39;:&#39;num_voted_users&#39;,&#39;aspect_ratio&#39;]] #출력이 안됨 ^ SyntaxError: invalid syntax . - (팁) 복잡한 조건은 iloc으로 쓰는게 편할때가 있다. $ to$ 그런데 df.columns 변수들이 몇번인지 알아보기 힘듬 . pd.Series(df.columns) # $ 열의 이름을 인덱스와 함께 출력 . 0 color 1 director_name 2 num_critic_for_reviews 3 duration 4 director_facebook_likes 5 actor_3_facebook_likes 6 actor_2_name 7 actor_1_facebook_likes 8 gross 9 genres 10 actor_1_name 11 movie_title 12 num_voted_users 13 cast_total_facebook_likes 14 actor_3_name 15 facenumber_in_poster 16 plot_keywords 17 movie_imdb_link 18 num_user_for_reviews 19 language 20 country 21 content_rating 22 budget 23 title_year 24 actor_2_facebook_likes 25 imdb_score 26 aspect_ratio 27 movie_facebook_likes dtype: object . list(range(13))+[26] # 0~12까지 + 26 . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26] . df.iloc[:,list(range(13))+[26]] . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres actor_1_name movie_title num_voted_users aspect_ratio . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | CCH Pounder | Avatar | 886204 | 1.78 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | Johnny Depp | Pirates of the Caribbean: At World&#39;s End | 471220 | 2.35 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | Christoph Waltz | Spectre | 275868 | 2.35 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | Tom Hardy | The Dark Knight Rises | 1144337 | 2.35 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | Doug Walker | Star Wars: Episode VII - The Force Awakens | 8 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | Eric Mabius | Signed Sealed Delivered | 629 | NaN | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | Natalie Zea | The Following | 73839 | 16.00 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | Eva Boehnke | A Plague So Pleasant | 38 | NaN | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | Alan Ruck | Shanghai Calling | 1255 | 2.35 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | John August | My Date with Drew | 4285 | 1.85 | . 4916 rows × 14 columns . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) . actor&#46972;&#45716; &#45800;&#50612;&#44032; &#54252;&#54632;&#46108; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . df.iloc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns) )] # 방법1 iloc에서 map과 람다를 이용 # = df.iloc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . df.loc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns) )] # 방법 2 loc에서 map과 람다를 이용 # = df.loc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . . &#48320;&#49688;&#51060;&#47492;&#51060; s&#47196; &#45149;&#45208;&#45716; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . df.iloc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . df.loc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . &#48320;&#49688;&#51060;&#47492;&#51060; c &#54841;&#51008; d&#47196; &#49884;&#51089;&#54616;&#45716; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . df.iloc[:,map(lambda x: &#39;c&#39; == x[0] or &#39;d&#39; == x[0] ,df.columns )] . . df&#51032; &#54665;&#51012; &#49440;&#53469;&#54616;&#45716; &#48169;&#48277; . &#52395;&#48264;&#51704; &#54665; &#49440;&#53469;&#54644;&#48372;&#44592; . np.random.seed(1) dic= {&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5), &#39;X4&#39;:np.random.normal(0,1,5), &#39;X5&#39;:np.random.normal(0,1,5), &#39;X6&#39;:np.random.normal(0,1,5)} df1=pd.DataFrame(dic) df1 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 1 -0.611756 | 1.744812 | -2.060141 | -0.172428 | 1.144724 | -0.122890 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . 3 -1.072969 | 0.319039 | -0.384054 | 0.042214 | 0.502494 | -0.267888 | . 4 0.865408 | -0.249370 | 1.133769 | 0.582815 | 0.900856 | 0.530355 | . df1.iloc[0] #방법 1 , 뭔가 이상하다. . X1 1.624345 X2 -2.301539 X3 1.462108 X4 -1.099891 X5 -1.100619 X6 -0.683728 Name: 0, dtype: float64 . 같은 출력 . df1.iloc[0,:] df1.loc[0] df1.loc[0,:] . df1.iloc[[0]] #방법 2 , 데이터 프레임형태로 불러와서 괜찮아보인다. . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 같은 출력 . df1.iloc[[0],:] df1.loc[[0]] df1.loc[[0],:] df1.iloc[[True,False,False,False,False]] df1.iloc[[True,False,False,False,False],:] df1.loc[[True,False,False,False,False]] df1.loc[[True,False,False,False,False],:] . 1,3&#54665;&#51012; &#49440;&#53469;&#54616;&#45716; &#48169;&#48277; (&#48520;, &#49836;&#46972;&#51060;&#49905;&#46321; &#45796;&#50577;&#54620; &#48169;&#48277; &#51316;&#51116;) . df1.iloc[[0,2],:] #방법 1 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . df1.loc[[0,2],:] #방법 2 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . - 대부분의 경우 observation에 특정한 이름이 있는 경우는 없으므로 loc이 그다지 쓸모 없음 . - 그렇지만 특정경우에는 쓸모가 있음 . 날짜 출력 같은 경우, loc이 더 쓸모가 있다. . - Note: 아래의 사실을 기억하자. . 기본적으로는 iloc, loc은 [2], [2:] 처럼 1차원으로 원소를 인덱싱할수도 있고, [2,3], [:,2] 와 같이 2차원으로 인덱싱할 수도 있다. . | 1차원으로 인덱싱하는 경우는 기본적으로 행을 인덱싱한다 $ to$ iloc, loc은 행과 더 친하고 열과 친하지 않다. . | 따라서 열을 선택하는 방법에 있어서 loc, iloc이 그렇제 좋은 방법은 아니다. . | 그렇지만 열을 선택하는 방법은 iloc이나 loc이 제일 편리하다. (이외의 다른 방법이 마땅하게 없음) 그래서 열을 선택할때도 iloc이나 loc을 선호한다. . | row는 특정간격으로 뽑는 일이 빈번함. (예를들어 일별데이터를 주별데이터로 바꾸고싶을때, 바꾸고 싶을 경우?) . | col을 특정간격으로 뽑아야 하는 일은 없음 . | . lambda + map &#51004;&#47196; &#51064;&#45937;&#49905; . np.random.seed(1) df2= pd.DataFrame(np.random.normal(size=(10,4)),columns=list(&#39;ABCD&#39;)) df2 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 7 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . &#52860;&#47100;A&#51032; &#44050;&#51060; 0&#48372;&#45796; &#53360; &#44221;&#50864;&#51032; &#54665;&#47564; . df2.loc[map(lambda x: x&gt;0,df2[&#39;A&#39;]),:] # 방법 1 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . df2.loc[lambda df: df[&#39;A&#39;]&gt;0,:] # 방법 2 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . map의 기능 | . (1) 리스트를 원소별로 분해하여 . (2) 어떠한 함수를 적용하여 아웃풋을 구한뒤 . (3) 각각의 아웃풋을 다시 하나의 리스트로 묶음 . 우리는 이중에서 (1),(3)에만 집중했음 | 하지만 생각해보면 일단 (2) 일단 함수를 적용하는 기능이 있었음 | 그런데 위의 코드는 함수를 적용한 결과가 아니라 함수 오브젝트 자체를 전달하여도 동작함 | . 요약!! . True, False로 이루어진 벡터를 리스트의 형태로 전달하여 인덱싱했음 (원래 우리가 알고 있는 개념) | True, False로 이루어진 벡터를 리턴할 수 있는 함수오브젝트 자체를 전달해도 인덱싱이 가능 | . &#52860;&#47100;A&gt;0 &#51060;&#44256; &#52860;&#47100;C&lt;0 &#51064; &#44221;&#50864;&#51032; &#54665; &#51064;&#45937;&#49905; . df2.loc[map(lambda x,y: x&gt;0 and y&lt;0, df2[&#39;A&#39;],df2[&#39;C&#39;]),:] # 방법 1 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . df2.loc[map(lambda x,y: (x&gt;0) &amp; (y&lt;0), df2[&#39;A&#39;],df2[&#39;C&#39;]),:] # 방법 2 # 0&lt;3.2 &amp; 0&lt;2.2 랑 (0&lt;3.2) &amp; (0&lt;2.2) 를 헷갈리면 안된다. . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . df2.loc[lambda df: (df[&#39;A&#39;] &gt;0) &amp; (df[&#39;C&#39;]&lt;0)] # 방법 3 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/11/07/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%8B%9C%ED%97%98%EA%B3%B5%EB%B6%802.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/11/07/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%8B%9C%ED%97%98%EA%B3%B5%EB%B6%802.html",
            "date": " • Nov 7, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "데이터시각화 시험공부1",
            "content": "&#51452;&#47196;&#50416;&#45716; &#54056;&#53412;&#51648;&#46308; . import numpy as np #넘파이 import pandas as pd #판다스 from plotnine import * #플롯나인 import matplotlib.pyplot as plt #맷플랏립 import plotly.express as px #플랏리 상호작용 그래프 from IPython.display import HTML #블로그에 html로 올리려고 변환하는 패키지 import seaborn as sns # 씨본, 히스토그램 깔끔하게 그리는 패키지 import cv2 as cv from scipy import stats . boxplot . boxplot &#49324;&#50857;&#48277; . plt.boxplot() 괄호안에는 양적으로 나열된 리스트를 넣어주면 된다. 바로 시각화가 진행됨 . 괄호안에 ([y1,y2]) 이렇게 넣으면 나란히 그릴 수 있음 (리스트 처리) . y1=[75,75,76,76,77,77,79,79,79,98] y2=[76,76,77,77,78,78,80,80,80,81] plt.boxplot([y1,y2]) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc67e227c70&gt;, &lt;matplotlib.lines.Line2D at 0x7fc67e227fd0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc67e240490&gt;, &lt;matplotlib.lines.Line2D at 0x7fc67e2407f0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc67e235370&gt;, &lt;matplotlib.lines.Line2D at 0x7fc67e2356d0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc67e240b50&gt;, &lt;matplotlib.lines.Line2D at 0x7fc67e240eb0&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc67e2278e0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc67e240130&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc67e235a30&gt;, &lt;matplotlib.lines.Line2D at 0x7fc67e24d250&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc67e235d90&gt;, &lt;matplotlib.lines.Line2D at 0x7fc67e24d5b0&gt;], &#39;means&#39;: []} . . plotly . 그림(그래프)에 마우스를 올리면 상호작용하는 그림 . plotly.express 와 pandas 필요 . 구글에 검색하면 예시가 잘 나와있다! $ to$ plotly 활용!!! . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) . df=pd.concat([A,B],ignore_index=True) # 데이터프레임 붙이기 . fig=px.box(data_frame=df, x=&#39;class&#39;,y=&#39;score&#39;) #반응형 플랏 생성 () . HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) #생성된 플랏을 html로 바꾸어 블로그에서 읽을 수 있게 함, 패키지 필요 . . . . Histogram . X축이 변수의 구간, Y축은 그 구간에 포함된 빈도를 의미하는 그림 . plt.hist() 함수 이용 . np.random.normal() :정규분포&gt; &gt; loc:평균 , scale:표준편차 , size:표본수 , bins= : 범위지정 bins를 늘리면 더 촘촘하게 그릴 수 있다. (정규분포에 더 가까워짐) . plt.hist(np.random.normal(loc=0, scale=1, size=1000000),bins=10) . (array([4.50000e+01, 1.51800e+03, 2.05060e+04, 1.22067e+05, 3.12406e+05, 3.43377e+05, 1.63298e+05, 3.38380e+04, 2.82500e+03, 1.20000e+02]), array([-4.86837268, -3.91680858, -2.96524449, -2.01368039, -1.06211629, -0.1105522 , 0.8410119 , 1.79257599, 2.74414009, 3.69570418, 4.64726828]), &lt;BarContainer object of 10 artists&gt;) . . seaborn . 깔끔하게 히스토그램을 그리는 패키지 . df를 입력으로 받는다 . np.random.seed(43052) #값이 안변하도록 시드설정 y1=np.random.normal(loc=0,scale=1,size=10000) #전북고 A반의 통계학 성적이라 생각하자. y2=np.random.normal(loc=0.5,scale=1,size=10000) #전북고 B반의 통계학 성적이라 생각하자. . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) df=pd.concat([A,B],ignore_index=True) . sns.histplot(df,x=&#39;score&#39;,hue=&#39;class&#39;) . &lt;AxesSubplot:xlabel=&#39;score&#39;, ylabel=&#39;Count&#39;&gt; . . plotnine . 인터랙티브 그래프를 위해서 plotly 홈페이지를 방문하여 적당한 코드를 가져온다. . ggplot(df)+geom_histogram(aes(x=&#39;score&#39;,color=&#39;class&#39;)) . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: &#39;stat_bin()&#39; using &#39;bins = 84&#39;. Pick better value with &#39;binwidth&#39;. . &lt;ggplot: (8780644355470)&gt; . $ to$ 별로 알아보기가 힘들다 . color&#47484;fill&#47196; &#48148;&#45012;&#51468; , position&#51012; &#46041;&#46321;&#54616;&#44172; , alpha: &#53804;&#47749;&#46020; . ggplot(df)+geom_histogram(aes(x=&#39;score&#39;,fill=&#39;class&#39;),position=&#39;identity&#39;,alpha=0.5) . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: &#39;stat_bin()&#39; using &#39;bins = 84&#39;. Pick better value with &#39;binwidth&#39;. . &lt;ggplot: (8743171077340)&gt; . . &#49328;&#51216;&#46020; (scatter plot) . 산점도:직교 좌표계(도표)를 이용해 좌표상의 점들을 표시함으로써 두 개 변수 간의 관계를 나타내는 그래프 방법이다. 산점도는 보통 $X$와 $Y$의 관계를 알고 싶을 경우 그린다. . 박스플랏, 히스토그램은 그림을 그리기 위해서 하나의 변수만 필요함; 산점도를 위해서는 두개의 변수가 필요함. | 두변수 $ to$ 두변수의 관계 | . &#47800;&#47924;&#44172;&#50752; &#53412; &#50696;&#49884; . x=[44,48,49,58,62,68,69,70,76,79] y=[159,160,162,165,167,162,165,175,165,172] . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc64abcd310&gt;] . 표본상관계수 계산 . x=np.array(x) y=np.array(y) . $r= sum_{i=1}^{n} left( frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}} frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}} right) = sum_{i=1}^{n} tilde{x}_i tilde{y}_i $ . - 사실 $a,b$는 아래와 같이 계산할 수 있다. . $a= sqrt{n} times{ tt np.std(x)}$ . $b= sqrt{n} times{ tt np.std(y)}$ . a=np.sqrt(np.sum((x-np.mean(x))**2)) #괄호 왼쪽 분모 b=np.sqrt(np.sum((y-np.mean(y))**2)) #괄호 오른쪽 분모 n=len(x) np.sqrt(n)*np.std(x), np.sqrt(n)*np.std(y) . (36.58004920718397, 15.21840990379744) . ${ tt np.std(x)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(x_i- bar{x})^2}$ | ${ tt np.std(y)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(y_i- bar{y})^2}$ | . . Note: ${ tt np.std(x,ddof=1)}= sqrt{ frac{1}{n-1} sum_{i=1}^{n}(x_i- bar{x})^2}$ . - 이제 $( tilde{x}_i, tilde{y}_i)$를 그려보자. . xx= (x-np.mean(x))/a yy= (y-np.mean(y))/b plt.plot(xx,yy,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc64abad1c0&gt;] . plotly &#51060;&#50857; . fig=px.scatter(x=xx, y=yy) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . $ tilde{x}_i$, $ tilde{y}_i$ 를 곱한값이 양수인것과 음수인것을 체크해보자. | 양수인쪽이 많은지 음수인쪽이 많은지 생각해보자. | $r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i$ 의 부호는? $ to$ 양수인 쪽이 훨씬 많다축=0 기준으로 사분면을 그어 양수쪽 기울기일지 그 수를 확인 . 1,3분면 :양수 . | . - 상관계수는 두 변수의 관계를 설명하기에 부적절하다. . 상관계수는 1번그림과 같이 두 변수가 선형관계에 있을때 그 정도를 나타내는 통계량일뿐이다. | 선형관계가 아닌것처럼 보이는 자료에서는 상관계수를 계산할수는 있겠으나 의미가 없다. | . - 교훈2: 기본적인 통계량들은 실제자료를 분석하기에 부적절할수 있다. (=통계량은 적절한 가정이 동반되어야 의미가 있다) . . Note: 통계학자는 (1) 적절한 가정을 수학적인 언어로 정의하고 (2) 그 가정하에서 통계량이 의미있다는 것을 증명해야 한다. (3) 그리고 그 결과를 시각화하여 설득한다. . . Anscombe&#39;s quartet . - 교과서에 나오는 그림임. . - 교훈: 데이터를 분석하기 전에 항상 시각화를 하라. . x = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5] y1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68] y2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74] y3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73] x4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8] y4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89] . _, axs = plt.subplots(2,2) axs[0,0].plot(x,y1,&#39;o&#39;) axs[0,1].plot(x,y2,&#39;o&#39;) axs[1,0].plot(x,y3,&#39;o&#39;) axs[1,1].plot(x4,y4,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f7a1370fb80&gt;] . - 상관계수를 잠깐 복습해보자. . 상관계수는 -1 ~ 1 사이의 값을 가진다. (코쉬슈바르츠 부등식을 사용하여 증명가능) | 완전한 직선이라면 상관계수가 1 또는 -1이다. | 상관계수가 1에 가까우면 양의 상관관계에 있다고 말하고 -1에 가까우면 음의 상관관계에 있다고 말한다. | . - 의문: 자료의 모양이 직선모양에 가까우면 상관계수가 큰것이 맞나? . $x,y$ 값이 모두 큰 하나의 관측치가 상관계수값을 키울 수 있지 않나? | . - 상관계수가 좋은것은 맞나? (=상관계수는 두 변수의 관계를 설명하기에 충분히 적절한 통계량인가?) . np.corrcoef([x,y1,y2,y3]) . array([[1. , 0.81642052, 0.81623651, 0.81628674], [0.81642052, 1. , 0.7500054 , 0.46871668], [0.81623651, 0.7500054 , 1. , 0.58791933], [0.81628674, 0.46871668, 0.58791933, 1. ]]) . np.corrcoef([x4,y4]) . array([[1. , 0.81652144], [0.81652144, 1. ]]) . - 위의 4개의 그림에 대한 상관계수는 모두 같다. (0.81652) . - 상관계수는 두 변수의 관계를 설명하기에 부적절하다. . 상관계수는 1번그림과 같이 두 변수가 선형관계에 있을때 그 정도를 나타내는 통계량일뿐이다. | 선형관계가 아닌것처럼 보이는 자료에서는 상관계수를 계산할수는 있겠으나 의미가 없다. | . - 교훈2: 기본적인 통계량들은 실제자료를 분석하기에 부적절할수 있다. (=통계량은 적절한 가정이 동반되어야 의미가 있다) . . Note: 통계학자는 (1) 적절한 가정을 수학적인 언어로 정의하고 (2) 그 가정하에서 통계량이 의미있다는 것을 증명해야 한다. (3) 그리고 그 결과를 시각화하여 설득한다. . . &#48177;&#51648;&#50640;&#49436; &#44536;&#47000;&#54532; &#44536;&#47532;&#44592; . - 전략: 그림을 만들고 (도화지를 준비) $ to$ 액시즈를 만들고 (네모틀을 만든다) $ to$ 액시즈에 그림을 그린다. (.plot()을 이용) . fig = plt.figure() # 도화지를 준비한다. . &lt;Figure size 432x288 with 0 Axes&gt; . fig # 현재 도화지상태를 체크 , 아무것도 없음 . &lt;Figure size 432x288 with 0 Axes&gt; . fig.axes # 현재 네모틀 상태를 체크 , 아무것도 없음 . [] . fig.add_axes([0,0,1,1]) # 도화지안에 (0,0) 위치에 길이가 (1,1) 인 네모틀을 만든다. . &lt;matplotlib.axes._axes.Axes at 0x7feb7c4d5370&gt; . fig.axes # 현재 네모틀 상태를 체크 --&gt; 네모틀이 하나 있음. . [&lt;matplotlib.axes._axes.Axes at 0x7feb7c4d5370&gt;] . fig # 현재도화지 상태 체크 --&gt; 도화지에 (하나의) 네모틀이 잘 들어가 있음 . axs1=fig.axes[0] ## 첫번째 액시즈 지정 . axs1.plot([1,2,3],&#39;or&#39;) # 첫번쨰 액시즈에 접근하여 그림을 그림 . [&lt;matplotlib.lines.Line2D at 0x7feb7bc4caf0&gt;] . fig #현재 도화지 상태 체크 --&gt; 그림이 잘 그려짐 . - 액시즈추가 . fig.add_axes([1,0,1,1]) #도화지 안에 1,0 자리에 1x1 네모 추가로 만들겠다. . &lt;matplotlib.axes._axes.Axes at 0x7feb7bbfaee0&gt; . fig.axes . [&lt;matplotlib.axes._axes.Axes at 0x7feb7c4d5370&gt;, &lt;matplotlib.axes._axes.Axes at 0x7feb7bbfaee0&gt;] . fig #잘 추가 되었음 . axs2=fig.axes[1] ## 두번째 액시즈 지정 . axs2.plot([1,2,3],&#39;ok&#39;) ## 두번째 액시즈에 그림그림 . [&lt;matplotlib.lines.Line2D at 0x7feb7bbfad60&gt;] . fig ## 현재 도화지 체크 . axs1.plot([1,2,3],&#39;--&#39;) ### 액시즈1에 점선추가 . [&lt;matplotlib.lines.Line2D at 0x7feb7bbd8f10&gt;] . fig ## 현재 도화지 체크 . &#44536;&#47536; &#47112;&#51060;&#50500;&#50883;&#51012; &#48320;&#44221; . fig.axes . [&lt;matplotlib.axes._axes.Axes at 0x7feb7c4d5370&gt;, &lt;matplotlib.axes._axes.Axes at 0x7feb7bbfaee0&gt;] . fig = plt.figure() #도화지 초기화 . &lt;Figure size 432x288 with 0 Axes&gt; . fig.axes . [] . fig.subplots(1,2) # 서브플랏을 이용해 나란한 그래프 (1행 2열) 생성 . array([&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], dtype=object) . fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1,ax2 = fig.axes # ax1이 첫번째 ax2가 두번째로 저장(튜플로) . ax1.plot([1,2,3],&#39;or&#39;) ax2.plot([1,2,3],&#39;ob&#39;) . [&lt;matplotlib.lines.Line2D at 0x7feb7baee8b0&gt;] . fig #뭔가 좁다 . fig.set_figwidth(10) #도화지 늘리기 fig . ax1.plot([1,2,3],&#39;--&#39;) #계속 업데이트 가능 . [&lt;matplotlib.lines.Line2D at 0x7feb7baee040&gt;] . &#55176;&#49828;&#53664;&#44536;&#47016; &#49900;&#54868; . np.random.seed(43052) x2=np.random.uniform(low=-1,high=1,size=100000) y2=np.random.uniform(low=-1,high=1,size=100000) radius = x2**2+y2**2 x3=x2[radius&lt;1] y3=y2[radius&lt;1] . h=0.05 _,axs= plt.subplots(2,2) axs[0,0].hist(y2[(x2&gt; -h )*(x2&lt; h )]) # &#39;*&#39; 는 and axs[0,0].set_xlim(-1.1,1.1) #축 범위 조절 axs[0,1].hist(y2[(x2&gt; 0.9-h )*(x2&lt; 0.9+h )]) axs[0,1].set_xlim(-1.1,1.1) axs[1,0].hist(y3[(x3&gt; -h )*(x3&lt; h )]) axs[1,0].set_xlim(-1.1,1.1) axs[1,1].hist(y3[(x3&gt; 0.9-h )*(x3&lt; 0.9+h )]) axs[1,1].set_xlim(-1.1,1.1) . (-1.1, 1.1) . &#48128;&#46020;&#54364;&#54788; . np.random.seed(43052) x4=np.random.normal(size=10000) y4=np.random.normal(size=10000) . plt.plot(x4,y4,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7feb7b54eac0&gt;] . - 디자인적인 측면에서 보면 올바른 시각화라 볼 수 없다. (이 그림이 밀도를 왜곡시킨다) . - 아래와 같은 그림이 더 우수하다. (밀도를 표현하기 위해 투명도라는 개념을 도입) . plt.scatter(x4,y4,alpha=0.01) . &lt;matplotlib.collections.PathCollection at 0x7ff0f352d610&gt; . np.corrcoef(x4,y4) . array([[ 1. , -0.01007718], [-0.01007718, 1. ]]) . . maplotlib + seaborn &#47484; &#51060;&#50857;&#54620; &#49328;&#51216;&#46020; . x=[44,48,49,58,62,68,69,70,76,79] # 몸무게 y=[159,160,162,165,167,162,165,175,165,172] #키 g=&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39; . plt.plot(x,y,&#39;o&#39;) #matplotlib . [&lt;matplotlib.lines.Line2D at 0x7fc64ab3d6d0&gt;] . sns.scatterplot(x=x,y=y,hue=g) # 씨본 . &lt;AxesSubplot:&gt; . fig, (ax1,ax2) = plt.subplots(1,2) ax1.plot(x,y,&#39;o&#39;) sns.scatterplot(x=x,y=y,hue=g,ax=ax2) # 겹쳐그리기 , ax1,ax2 이라고 지정하는 함수를 각각 추가 # 씨본과 맷플랏을 동시에 그릴수 있음 . &lt;AxesSubplot:&gt; . ax1.set_title(&#39;matplotlib&#39;) ax2.set_title(&#39;seaborn&#39;) #그래프각각의 제목 지정 fig.set_figwidth(8) #그래프의 사이즈 늘리기 fig . plt.plot([1,2,3],[3,4,5],&#39;or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc64a83ba30&gt;] . sns.set_theme() #같은 코드이지만 씨본을 통해 비주얼라이징을 더 예쁘게 변화 . plt.plot([1,2,3],[3,4,5],&#39;or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc64a700490&gt;] . . &#51221;&#44508;&#48516;&#54252;&#52628;&#51221;, &#48128;&#46020;&#52628;&#51221;&#44257;&#49440; . np.random.seed(43052) x=np.random.normal(size=1000,loc=2,scale=1.5) #정규분포 생성 from scipy import stats #t분포 패키지 y=stats.t.rvs(10,size=1000) #t분포 생성 . - 이 자료가 정규분포를 따르는지 어떻게 체크할 수 있을까? . plt.hist(x) . (array([ 10., 24., 99., 176., 232., 222., 165., 53., 16., 3.]), array([-2.44398446, -1.53832428, -0.6326641 , 0.27299608, 1.17865626, 2.08431645, 2.98997663, 3.89563681, 4.80129699, 5.70695718, 6.61261736]), &lt;BarContainer object of 10 artists&gt;) . - 종모양이므로 정규분포인듯 하다. . - 밀도추정곡선이 있었으면 좋겠다. (KDE로 추정) $ to$ seaborn을 활용하여 그려보자. . fig, (ax1,ax2) = plt.subplots(1,2) sns.histplot(x,kde=True,ax=ax1) sns.histplot(y,kde=True,ax=ax2) #kde 가 곡선 추가 옵션 . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . 둘다 종모양이다!! . scale을 표준으로 바꿔서 비교해본다 . xx= (x-np.mean(x)) / np.std(x,ddof=1) yy= (y-np.mean(y)) / np.std(y,ddof=1) fig, (ax1,ax2) = plt.subplots(1,2) sns.histplot(xx,kde=True,ax=ax1) sns.histplot(yy,kde=True,ax=ax2) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . 정확한 분포를 위해 박스플랏이랑 같이 비교 . xx= (x-np.mean(x)) / np.std(x,ddof=1) yy= (y-np.mean(y)) / np.std(y,ddof=1) fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2) fig.tight_layout() ax1.boxplot(xx) sns.histplot(xx,kde=True,ax=ax2) ax3.boxplot(yy) sns.histplot(yy,kde=True,ax=ax4) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . t분포는 종모양이나 정규분포는 아니다. $ to$ t분포의 꼬리가 더 두껍다 . . qqplot . 분포를 특정하기에 좋은 시각화 . np.random.seed(43052) x=np.random.normal(size=1000,loc=2,scale=1.5) y=stats.t.rvs(df=10,size=1000)/np.sqrt(10/8)*1.5 + 2 . fig, ax =plt.subplots(2,3) . (ax1,ax2,ax3), (ax4,ax5,ax6) = ax . sns.boxplot(x,ax=ax1) #box sns.histplot(x,kde=True,ax=ax2) #hist _ = stats.probplot(x,plot=ax3) #qqplot sns.boxplot(y,ax=ax4) sns.histplot(y,kde=True,ax=ax5) _ = stats.probplot(y,plot=ax6) #그림 사이즈조정 fig.set_figwidth(10) fig.set_figheight(8) fig.tight_layout() fig . /home/kdj/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. /home/kdj/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. . t분포: 푸른점들이 대체로 붉은선위에 놓여있는듯 하지만 양끝단에서는 그렇지 않다. (중앙부근은 정규분포와 비슷하지만, 꼬리부분은 정규분포와 확실히 다르다) | 왼쪽꼬리: 이론적으로 나와야 할 값보다 더 작은값이 실제로 관측됨 | 오른쪽꼬리: 이론적으로 나와야 할 값보다 더 큰값이 실제로 관측됨 | 해석: 이 분포는 정규분포보다 두꺼운 꼬리를 가진다. | . . &#48516;&#50948;&#49688;&#47484; &#44396;&#54616;&#45716; &#45796;&#50577;&#54620; &#48169;&#48277; . m=[i/1000 for i in np.arange(1000)+1] #리스트 컴프리헨션 # np.arange(1000) : 0~999 . $m= big { frac{i}{1000}: i in {1,2,3, dots,1000 } big }= big { frac{1}{1000}, frac{2}{1000}, dots, frac{1000}{1000} big }$ | . m[:5] . [0.001, 0.002, 0.003, 0.004, 0.005] . range? . Init signature: range(self, /, *args, **kwargs) Docstring: range(stop) -&gt; range object range(start, stop[, step]) -&gt; range object Return an object that produces a sequence of integers from start (inclusive) to stop (exclusive) by step. range(i, j) produces i, i+1, i+2, ..., j-1. start defaults to 0, and stop is omitted! range(4) produces 0, 1, 2, 3. These are exactly the valid indices for a list of 4 elements. When step is given, it specifies the increment (or decrement). Type: type Subclasses: . range . 처음부터 정수 시퀀스를 생성하는 개체 반환(포함) 단계별로 정지(정지)합니다. . 범위(i, j)는 i, i+1, i+2, ..., j-1을 생성합니다. . start 기본값은 0이고 stop은 생략됩니다! range(4)는 0, 1, 2, 3을 생성합니다. . 이들은 정확히 4개의 원소 목록에 대한 유효한 지수이다. . 단계가 지정되면 증분(또는 감소)을 지정합니다. . stats.norm.ppf? . Signature: stats.norm.ppf(q, *args, **kwds) Docstring: Percent point function (inverse of `cdf`) at q of the given RV. Parameters - q : array_like lower tail probability arg1, arg2, arg3,... : array_like The shape parameter(s) for the distribution (see docstring of the instance object for more information) loc : array_like, optional location parameter (default=0) scale : array_like, optional scale parameter (default=1) Returns - x : array_like quantile corresponding to the lower tail probability q. File: ~/anaconda3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py Type: method . stats.norm.ppf() . 주어진 RV의 q에서 백분율 포인트 함수(&#39;cdf&#39;의 역) . Parameters . q : array_like 낮은 꼬리 확률 arg1, arg2, arg3,... : array_like 분포에 대한 형상 모수(의 문서 문자열 참조) 자세한 내용을 보려면 인스턴스 개체) loc : array_like, 옵션 위치 매개 변수(기본값=0) scale : array_like, 옵션 척도 모수(기본값=1) . return . x : array_like = 아래쪽 꼬리 확률 q에 해당하는 분위수입니다. . q=[] for i in range(len(m)): q=q+[stats.norm.ppf(m[i])] q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . q=[stats.norm.ppf(m[i]) for i in range(len(m))] q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . q=list(map(stats.norm.ppf, m)) q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . stats.norm.ppf(m)[:5] . array([-3.09023231, -2.87816174, -2.74778139, -2.65206981, -2.5758293 ]) . . &#51339;&#51008; &#49884;&#44033;&#54868; &#54616;&#44592; . - 왜 우수한 그래프일까? . 자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존 | 이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임 | 미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함. | . &#49884;&#44033;&#54868; &#50696;&#51228; . x=[44,48,49,58,62,68,69,70,76,79] ## 몸무게 y=[159,160,162,165,167,162,165,175,165,172] ## 키 g= &#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;m&#39;,&#39;f&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39; df=pd.DataFrame({&#39;w&#39;:x,&#39;h&#39;:y,&#39;g&#39;:g}) . df . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 4 62 | 167 | m | . 5 68 | 162 | f | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . - 미나드의 접근방법 . sns.scatterplot(data=df,x=&#39;w&#39;,y=&#39;h&#39;,hue=&#39;g&#39;) . &lt;AxesSubplot:xlabel=&#39;w&#39;, ylabel=&#39;h&#39;&gt; . - 일반적인 사람들 (보통 색깔을 사용할 생각을 못한다.) . figs = sns.FacetGrid(df,col=&#39;g&#39;) figs.map (sns.scatterplot,&#39;w&#39;,&#39;h&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f00b6fa36d0&gt; . - 생각보다 데이터가 정리된 형태에 따라서 시각화에 대한 사고방식이 달라진다. 아래와 같은 자료를 받았다고 하자. . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv . df1 . w h . 0 44 | 159 | . 1 48 | 160 | . 2 49 | 162 | . 3 58 | 165 | . 5 68 | 162 | . df2 . w h . 4 62 | 167 | . 6 69 | 165 | . 7 70 | 175 | . 8 76 | 165 | . 9 79 | 172 | . - 데이터프레임을 바꿀 생각을 하는게 쉽지 않다. . (방법1) . df1[&#39;g&#39;]= &#39;f&#39; . df1 . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . df2[&#39;g&#39;]= &#39;m&#39; . df2 . w h g . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . pd.concat([df1,df2]) . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . (방법2) . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv . pd.concat([df1,df2],keys=[&#39;f&#39;,&#39;m&#39;]).reset_index().iloc[:,[0,2,3]].rename(columns={&#39;level_0&#39;:&#39;g&#39;}) . g w h . 0 f | 44 | 159 | . 1 f | 48 | 160 | . 2 f | 49 | 162 | . 3 f | 58 | 165 | . 4 f | 68 | 162 | . 5 m | 62 | 167 | . 6 m | 69 | 165 | . 7 m | 70 | 175 | . 8 m | 76 | 165 | . 9 m | 79 | 172 | . - 어려운점: . (1) 센스가 없어서 색깔을 넣어서 그룹을 구분할 생각을 못함 | (2) 변형해야할 데이터를 생각못함 | (3) 데이터를 변형할 생각을 한다고 해도 변형하는 실제적인 코드를 구현할 수 없음 (그래서 엑셀을 킨다..) (1) 기획력부족 -&gt; 훌륭한 시각화를 많이 볼것 | (2) 데이터프레임에 대한 이해도가 부족 -&gt; tidydata에 대한 개념 | (3) 프로그래밍 능력 부족 -&gt; 코딩공부열심히.. | . | . - 목표: . (2) 어떠한 데이터 형태로 변형해야하는가? | (3) 그러한 데이터 형태로 바꾸기 위한 pandas 숙련도 | .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/11/07/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%8B%9C%ED%97%98%EA%B3%B5%EB%B6%801.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/11/07/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%8B%9C%ED%97%98%EA%B3%B5%EB%B6%801.html",
            "date": " • Nov 7, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "데이터시각화 10/27 강의 정리",
            "content": "import pandas as pd import numpy as np . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv&#39;) . df #항공 정보 . df.columns #열이름 나열 . https://github.com/PacktPublishing/Pandas-Cookbook/blob/master/data/descriptions/flights_description.csv | . 칼럼 설명 . groupby . - 데이터프레임을 여러개의 서브데이터프레임으로 나누는 기능 . - 단독으로 쓸 이유는 별로 없다. $ to$ 그룹을 나누고 어떠한 &quot;연산&quot;을 하기 위함 . df.groupby(by=&#39;AIRLINE&#39;) . &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f3368772fa0&gt; . 데이터프레임을 각 항공사 별로 나눔 | . - 확인 . grouped_df = df.groupby(by=&#39;AIRLINE&#39;) . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv&#39;) . grouped_df.groups . 너무 보기 힘듬 | . - 보기좋은 형태로 확인 . list(grouped_df.groups) #항공사안 카테고리의 리스트 출력 . [&#39;AA&#39;, &#39;AS&#39;, &#39;B6&#39;, &#39;DL&#39;, &#39;EV&#39;, &#39;F9&#39;, &#39;HA&#39;, &#39;MQ&#39;, &#39;NK&#39;, &#39;OO&#39;, &#39;UA&#39;, &#39;US&#39;, &#39;VX&#39;, &#39;WN&#39;] . grouped_df.get_group(&#39;AA&#39;) #항공사별로 나눈 것의 특정 카테고리를 df로 보기 . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 6 1 | 1 | 4 | AA | DFW | MSY | 1250 | 84.0 | 64.0 | 447 | 1410 | 83.0 | 0 | 0 | . 8 1 | 1 | 4 | AA | ORD | STL | 1845 | -5.0 | 44.0 | 258 | 1950 | -5.0 | 0 | 0 | . 15 1 | 1 | 4 | AA | DEN | DFW | 1445 | -6.0 | 93.0 | 641 | 1745 | 4.0 | 0 | 0 | . 26 1 | 1 | 4 | AA | LAX | AUS | 1430 | 33.0 | 157.0 | 1242 | 1925 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58470 12 | 31 | 4 | AA | DFW | FAT | 1020 | -3.0 | 196.0 | 1313 | 1156 | -2.0 | 0 | 0 | . 58475 12 | 31 | 4 | AA | IAH | CLT | 710 | 1.0 | 113.0 | 912 | 1037 | -12.0 | 0 | 0 | . 58476 12 | 31 | 4 | AA | DFW | TPA | 1020 | -3.0 | 121.0 | 929 | 1340 | -6.0 | 0 | 0 | . 58479 12 | 31 | 4 | AA | DFW | ELP | 1200 | 3.0 | 94.0 | 551 | 1250 | 13.0 | 0 | 0 | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 8900 rows × 14 columns . for g in grouped_df.groups: . print(g) display(grouped_df.get_group(g)) $ to$ 리스트 카테고리들 전부를 확인 . AIRLINE&#51012; &#44592;&#51456;&#51004;&#47196; &#45936;&#51060;&#53552;&#54532;&#47112;&#51076;&#51012; &#45208;&#45572;&#44256; $ to$ ARR_DELAY&#50640; mean&#54632;&#49688;&#47484; &#51201;&#50857;: (AIRLINE $ to$ {ARR_DELAY: mean}) . - 방법1 (기본, agg와 딕셔너리 이용) . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:&#39;mean&#39;}) . ARR_DELAY . AIRLINE . AA 5.542661 | . AS -0.833333 | . B6 8.692593 | . DL 0.339691 | . EV 7.034580 | . F9 13.630651 | . HA 4.972973 | . MQ 6.860591 | . NK 18.436070 | . OO 7.593463 | . UA 7.765755 | . US 1.681105 | . VX 5.348884 | . WN 6.397353 | . - 방법2 ($ star star star$) . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:np.mean}) . ARR_DELAY . AIRLINE . AA 5.542661 | . AS -0.833333 | . B6 8.692593 | . DL 0.339691 | . EV 7.034580 | . F9 13.630651 | . HA 4.972973 | . MQ 6.860591 | . NK 18.436070 | . OO 7.593463 | . UA 7.765755 | . US 1.681105 | . VX 5.348884 | . WN 6.397353 | . - 방법3 , 나눠진 df에서 ARR_DELAY 뽑고, 평균함수적용 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(&#39;mean&#39;) . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . - 방법4 ($ star$) . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(np.mean) . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . - 방법5 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].mean() . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . - 방법2와 방법4는 사용자정의 함수를 쓸 수 있다는 장점이 있음 . - 방법6 . def f(x): return -np.mean(x) #사용자정의함수 지정 . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:f}) . ARR_DELAY . AIRLINE . AA -5.542661 | . AS 0.833333 | . B6 -8.692593 | . DL -0.339691 | . EV -7.034580 | . F9 -13.630651 | . HA -4.972973 | . MQ -6.860591 | . NK -18.436070 | . OO -7.593463 | . UA -7.765755 | . US -1.681105 | . VX -5.348884 | . WN -6.397353 | . - 방법7 . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:lambda x: -np.mean(x)}) . ARR_DELAY . AIRLINE . AA -5.542661 | . AS 0.833333 | . B6 -8.692593 | . DL -0.339691 | . EV -7.034580 | . F9 -13.630651 | . HA -4.972973 | . MQ -6.860591 | . NK -18.436070 | . OO -7.593463 | . UA -7.765755 | . US -1.681105 | . VX -5.348884 | . WN -6.397353 | . - 방법8 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(lambda x: -np.mean(x)) . AIRLINE AA -5.542661 AS 0.833333 B6 -8.692593 DL -0.339691 EV -7.034580 F9 -13.630651 HA -4.972973 MQ -6.860591 NK -18.436070 OO -7.593463 UA -7.765755 US -1.681105 VX -5.348884 WN -6.397353 Name: ARR_DELAY, dtype: float64 . &#51077;&#47141;&#51060; &#50668;&#47084;&#44060;&#51064; &#49324;&#50857;&#51088; &#51221;&#51032; &#54632;&#49688;&#51032; &#49324;&#50857; . def f(x,y): return np.mean(x)**y . - 방법1 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(f,2) . AIRLINE AA 30.721086 AS 0.694444 B6 75.561166 DL 0.115390 EV 49.485310 F9 185.794656 HA 24.730460 MQ 47.067715 NK 339.888677 OO 57.660681 UA 60.306954 US 2.826113 VX 28.610564 WN 40.926120 Name: ARR_DELAY, dtype: float64 . - 방법2 . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;: lambda x: f(x,2)}) . ARR_DELAY . AIRLINE . AA 30.721086 | . AS 0.694444 | . B6 75.561166 | . DL 0.115390 | . EV 49.485310 | . F9 185.794656 | . HA 24.730460 | . MQ 47.067715 | . NK 339.888677 | . OO 57.660681 | . UA 60.306954 | . US 2.826113 | . VX 28.610564 | . WN 40.926120 | . &#54876;&#50857; . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum} . - 방법1~5 . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:&#39;sum&#39;}) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:np.sum}) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].agg(&#39;sum&#39;) . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].agg(np.sum) . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].sum() . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum, mean} , {DIVERTED: sum, mean} . - 방법 1~4 (5번은 쓸 수 없다) . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[&#39;sum&#39;,&#39;mean&#39;],&#39;DIVERTED&#39;:[&#39;sum&#39;,&#39;mean&#39;]}) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[np.sum,np.mean],&#39;DIVERTED&#39;:[np.sum,np.mean]}) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[[&#39;CANCELLED&#39;,&#39;DIVERTED&#39;]].agg([&#39;sum&#39;,&#39;mean&#39;]) #컬럼을 리스트로 전달 . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[[&#39;CANCELLED&#39;,&#39;DIVERTED&#39;]].agg([np.sum,np.mean]) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum, mean, size} , {AIR_TIME: mean,var} . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[&#39;sum&#39;,&#39;mean&#39;,&#39;size&#39;],&#39;AIR_TIME&#39;:[&#39;mean&#39;,&#39;var&#39;]}) #딕셔너리 활용 . CANCELLED AIR_TIME . sum mean size mean var . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]) .agg({&#39;CANCELLED&#39;:[np.sum,np.mean,len],&#39;AIR_TIME&#39;:[np.mean,lambda x: np.std(x,ddof=1)**2]}) . CANCELLED AIR_TIME . sum mean len mean &lt;lambda_0&gt; . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . grouping by continuous variable &#50672;&#49549;&#54805;&#48320;&#49688; &#44536;&#47353;&#54868; . df . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 0 1 | 1 | 4 | WN | LAX | SLC | 1625 | 58.0 | 94.0 | 590 | 1905 | 65.0 | 0 | 0 | . 1 1 | 1 | 4 | UA | DEN | IAD | 823 | 7.0 | 154.0 | 1452 | 1333 | -13.0 | 0 | 0 | . 2 1 | 1 | 4 | MQ | DFW | VPS | 1305 | 36.0 | 85.0 | 641 | 1453 | 35.0 | 0 | 0 | . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 4 1 | 1 | 4 | WN | LAX | MCI | 1720 | 48.0 | 166.0 | 1363 | 2225 | 39.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 58488 12 | 31 | 4 | F9 | LAS | SFO | 1910 | 13.0 | 71.0 | 414 | 2050 | 4.0 | 0 | 0 | . 58489 12 | 31 | 4 | OO | SFO | SBA | 1846 | -6.0 | 46.0 | 262 | 1956 | -5.0 | 0 | 0 | . 58490 12 | 31 | 4 | WN | MSP | ATL | 525 | 39.0 | 124.0 | 907 | 855 | 34.0 | 0 | 0 | . 58491 12 | 31 | 4 | OO | SFO | BOI | 859 | 5.0 | 73.0 | 522 | 1146 | -1.0 | 0 | 0 | . 58492 rows × 14 columns . - 목표: DIST를 적당한 구간으로 나누어 카테고리화 하고 그것을 바탕으로 groupby를 수행하자. . df.DIST.hist() #앞쪽에 몰려있음 . &lt;AxesSubplot:&gt; . df.DIST.describe() #대략적 통계값 산출 . count 58492.000000 mean 872.900072 std 624.996805 min 67.000000 25% 391.000000 50% 690.000000 75% 1199.000000 max 4502.000000 Name: DIST, dtype: float64 . - 구간을 아래와 같이 설정한다. . bins=[-np.inf, 400, 700, 1200, np.inf] # -무한대 ~400 ~700 ~1200 ~무한대 . - pd.cut()을 이용하여 각 구간의 observation을 카테고리화(mapping) 하자. . cuts=pd.cut(df.DIST,bins=bins) #(적용할 칼럼, bins=구간) cuts . 0 (400.0, 700.0] 1 (1200.0, inf] 2 (400.0, 700.0] 3 (700.0, 1200.0] 4 (1200.0, inf] ... 58487 (1200.0, inf] 58488 (400.0, 700.0] 58489 (-inf, 400.0] 58490 (700.0, 1200.0] 58491 (400.0, 700.0] Name: DIST, Length: 58492, dtype: category Categories (4, interval[float64]): [(-inf, 400.0] &lt; (400.0, 700.0] &lt; (700.0, 1200.0] &lt; (1200.0, inf]] . - cuts, AIRLINE $ to$ {DIVERTED: sum} . df.groupby([cuts,&#39;AIRLINE&#39;]).agg({&#39;DIVERTED&#39;:sum}) #구분별 항공사 diverted합 산출 . DIVERTED . DIST AIRLINE . (-inf, 400.0] AA 0 | . AS 0 | . B6 0 | . DL 1 | . EV 3 | . F9 0 | . HA 0 | . MQ 0 | . NK 0 | . OO 5 | . UA 2 | . US 0 | . VX 0 | . WN 1 | . (400.0, 700.0] AA 3 | . AS 0 | . B6 0 | . DL 12 | . EV 8 | . F9 1 | . HA 0 | . MQ 4 | . NK 1 | . OO 7 | . UA 1 | . US 0 | . VX 0 | . WN 2 | . (700.0, 1200.0] AA 10 | . AS 0 | . B6 1 | . DL 6 | . EV 4 | . F9 0 | . HA 0 | . MQ 1 | . NK 1 | . OO 5 | . UA 4 | . US 0 | . VX 0 | . WN 4 | . (1200.0, inf] AA 13 | . AS 0 | . B6 1 | . DL 5 | . EV 0 | . F9 1 | . HA 1 | . MQ 0 | . NK 3 | . OO 4 | . UA 12 | . US 1 | . VX 1 | . WN 8 | . - 아래와 비교해보자. . df.groupby([&#39;AIRLINE&#39;]).agg({&#39;DIVERTED&#39;:sum}) . DIVERTED . AIRLINE . AA 26 | . AS 0 | . B6 2 | . DL 24 | . EV 15 | . F9 2 | . HA 1 | . MQ 5 | . NK 5 | . OO 21 | . UA 19 | . US 1 | . VX 1 | . WN 15 | . - cuts을 이용하여 추가그룹핑을 하면 조금 다른 특징들을 데이터에서 발견할 수 있다. . AA항공사와 DL항공사는 모두 비슷한 우회횟수를 가지고 있음. | AA항공사는 700회이상의 구간에서 우회를 많이하고 DL항공사는 400~700사이에서 우회를 많이 한다. (패턴이 다름) 상세한 패턴 확인 가능 | . - 구간이름에 label을 붙이는 방법 labels=[] 이용 . bins . [-inf, 400, 700, 1200, inf] . cuts2=pd.cut(df.DIST,bins=bins,labels=[&#39;Q1&#39;,&#39;Q2&#39;,&#39;Q3&#39;,&#39;Q4&#39;]) cuts2 . 0 Q2 1 Q4 2 Q2 3 Q3 4 Q4 .. 58487 Q4 58488 Q2 58489 Q1 58490 Q3 58491 Q2 Name: DIST, Length: 58492, dtype: category Categories (4, object): [&#39;Q1&#39; &lt; &#39;Q2&#39; &lt; &#39;Q3&#39; &lt; &#39;Q4&#39;] . df.groupby(by=[cuts2,&#39;AIRLINE&#39;]).agg({&#39;DIVERTED&#39;:sum}) . DIVERTED . DIST AIRLINE . Q1 AA 0 | . AS 0 | . B6 0 | . DL 1 | . EV 3 | . F9 0 | . HA 0 | . MQ 0 | . NK 0 | . OO 5 | . UA 2 | . US 0 | . VX 0 | . WN 1 | . Q2 AA 3 | . AS 0 | . B6 0 | . DL 12 | . EV 8 | . F9 1 | . HA 0 | . MQ 4 | . NK 1 | . OO 7 | . UA 1 | . US 0 | . VX 0 | . WN 2 | . Q3 AA 10 | . AS 0 | . B6 1 | . DL 6 | . EV 4 | . F9 0 | . HA 0 | . MQ 1 | . NK 1 | . OO 5 | . UA 4 | . US 0 | . VX 0 | . WN 4 | . Q4 AA 13 | . AS 0 | . B6 1 | . DL 5 | . EV 0 | . F9 1 | . HA 1 | . MQ 0 | . NK 3 | . OO 4 | . UA 12 | . US 1 | . VX 1 | . WN 8 | . df.groupby(cuts2).agg({&#39;DIVERTED&#39;:len}) . DIVERTED . DIST . Q1 15027 | . Q2 14697 | . Q3 14417 | . Q4 14351 | . &#49689;&#51228; . 구간을 . bins=[-np.inf, 400, 700, 1200, np.inf] . 이 아니라 . bins=[-np.inf, 400, 600, 800, 1000, 1200, np.inf] . 와 같이 나누고 적당한 각구간별로 해당하는 관측치의 수를 구하라. . . &#45936;&#51060;&#53552;&#49884;&#44033;&#54868; 10/27&#49688;&#50629; &#44284;&#51228; 201514142 &#44608;&#46041;&#51456; . bins=[-np.inf, 400, 600, 800, 1000, 1200, np.inf] . cuts3=pd.cut(df.DIST,bins=bins,labels=[&#39;Q1&#39;,&#39;Q2&#39;,&#39;Q3&#39;,&#39;Q4&#39;,&#39;Q5&#39;,&#39;Q6&#39;]) cuts3 . 0 Q2 1 Q6 2 Q3 3 Q5 4 Q6 .. 58487 Q6 58488 Q2 58489 Q1 58490 Q4 58491 Q2 Name: DIST, Length: 58492, dtype: category Categories (6, object): [&#39;Q1&#39; &lt; &#39;Q2&#39; &lt; &#39;Q3&#39; &lt; &#39;Q4&#39; &lt; &#39;Q5&#39; &lt; &#39;Q6&#39;] . df.groupby(cuts3).agg({&#39;DIVERTED&#39;:len}) . DIVERTED . DIST . Q1 15027 | . Q2 9130 | . Q3 8553 | . Q4 7542 | . Q5 3889 | . Q6 14351 | .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/28/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-1027-%EA%B0%95%EC%9D%98-%EC%A0%95%EB%A6%AC.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/28/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-1027-%EA%B0%95%EC%9D%98-%EC%A0%95%EB%A6%AC.html",
            "date": " • Oct 28, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "회귀분석 7장 연습문제R",
            "content": "3.7&#51088;&#47308; &#54644;&#49437; . x &lt;- c(4.2,3.8,4.8,3.4,4.5,4.6,4.3,3.7,3.9) y &lt;- c(2.8,2.5,3.1,2.1,2.9,2.6,2.4,2.4,2.5) lm37 &lt;- lm(y~x) . coef(lm37) . &lt;dl class=dl-inline&gt;(Intercept)0.345994832041343x0.542635658914729&lt;/dl&gt; $ to X = begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 vdots &amp; vdots 1 &amp; x_n end{bmatrix} , beta = begin{bmatrix} 0.346 0.543 end{bmatrix}$ . 7.1 . 연습문제 3.7의 자료로부터 다음을 구하여라. . 1) $X&#39;X$ . $X&#39;X$ = $ begin{bmatrix} n &amp; sum_{}^{}x_i sum_{}^{}x_i &amp; sum_{}^{}{x_i}^2 end{bmatrix}$ . n , $ sum_{}^{}x_i$ , $ sum_{}^{}{x_i}^2$ . n &lt;- length(x) sx &lt;- sum(x) sxs &lt;- sum(x^2) c(n,sx,sxs) . &lt;ol class=list-inline&gt;9 | 37.2 | 155.48 | &lt;/ol&gt; $ to X&#39;X = begin{bmatrix} 9 &amp; 37.2 37.2 &amp; 155.48 end{bmatrix}$ . 2) $(X&#39;X)^{-1}$ . $(X&#39;X)^{-1}$ = $ frac{1}{n sum_{}^{}{x_i}^2 - ( sum_{}^{}x_i)^2} $ $ begin{bmatrix} sum_{}^{}{x_i}^2 &amp; - sum_{}^{}x_i - sum_{}^{}x_i &amp; n end{bmatrix}$ . - $ frac{1}{n sum_{}^{}{x_i}^2 - ( sum_{}^{}x_i)^2} $ 계산 . M &lt;- 1/(n*sxs-(sx)^2) M . 0.0645994832041333 $ sum_{}^{}{x_i}^2 , - sum_{}^{}x_i , n$ . c(sxs*M,-1*sx*M,n*M) . &lt;ol class=list-inline&gt;10.0439276485787 | -2.40310077519376 | 0.5813953488372 | &lt;/ol&gt; $ to (X&#39;X)^{-1} = begin{bmatrix} 10.04 &amp; -2.403 -2.403 &amp; 0.581 end{bmatrix} $ . 3) $X&#39;Y$ . $X&#39;Y$ = $ begin{bmatrix} sum_{}^{}y_i sum_{}^{}x_iy_i end{bmatrix} $ . $ sum_{}^{}y_i , sum_{}^{}x_iy_i $ . sy &lt;- sum(y) sxy &lt;- sum(x*y) c(sy,sxy) . &lt;ol class=list-inline&gt;23.3 | 97.24 | &lt;/ol&gt; $ to X&#39;Y$ = $ begin{bmatrix} 23.3 97.24 end{bmatrix} $ . 4) $(X&#39;X)^{-1}X&#39;Y$ . $(X&#39;X)^{-1}X&#39;Y$ = $ begin{bmatrix} frac{(sxs*sy -sx*sxy)}{n*sxs-sx^2} frac{n*sxy - sx*sy}{n*sxs - sx^2} end{bmatrix} $ . 10.04*23.3-2.403*97.24 . 0.264279999999985 (-2.403*23.3)+(0.581*97.24) . 0.506539999999987 A = matrix(c(10.04,-2.403,-2.403,0.581),2,2) #(X&#39;X)^-1 B = matrix(c(23.3,97.24),2,1) #X&#39;Y print(A) print(B) . [,1] [,2] [1,] 10.040 -2.403 [2,] -2.403 0.581 [,1] [1,] 23.30 [2,] 97.24 . A %*% B . A matrix: 2 × 1 of type dbl 0.26428 | . 0.50654 | . $ to (X&#39;X)^{-1}X&#39;Y$ = $ begin{bmatrix} 0.26428 0.50654 end{bmatrix} $ . . 7.7 . 어린이들의 체중($y$ :파운드)이 신장($x_1$:인치)가 연령($x_2$:살)에 따라 어떻게 영향을 받는지 파악하기 위해 12명의 어린이로부터 다음의 자료를 얻었다. . 변수 값 . $y$ | 64 | 71 | 53 | 67 | 55 | 58 | 77 | 57 | 56 | 51 | 76 | 68 | . $x_1$ | 57 | 59 | 49 | 62 | 51 | 50 | 55 | 48 | 42 | 42 | 61 | 57 | . $x_2$ | 8 | 10 | 6 | 11 | 8 | 7 | 10 | 9 | 10 | 6 | 12 | 9 | . 1) $x_1$&#50640; &#45824;&#54620; $y$ / $x_2$&#50640; &#45824;&#54620; $y$ / $x_1$&#50640; &#45824;&#54620; $x_2$ &#51032; &#49328;&#51216;&#46020;&#47484; &#44536;&#47532;&#44256;, &#44033;&#44033;&#51032; &#49345;&#44288;&#44228;&#49688; $r_{x_1y},r_{x_2y},r_{x_1x_2}$&#47484; &#44396;&#54616;&#50668;&#46972;. . y &lt;- c(64,71,53,67,55,58,77,57,56,51,76,68) x1 &lt;- c(57,59,49,62,51,50,55,48,42,42,61,57) x2 &lt;- c(8,10,6,11,8,7,10,9,10,6,12,9) . $x_1$에 대한 $y$ / $x_2$에 대한 $y$ / $x_1$에 대한 $x_2$ . par(mfrow=c(1,3)) plot(x1,y,main=&quot;x1:y&quot;) plot(x2,y,main=&quot;x2:y&quot;) plot(x1,x2,main=&quot;x1:x2&quot;) . 상관계수 구하기 . cor(x1,y) cor(x2,y) cor(x1,x2) . 0.814256949718907 0.769816801847935 0.613838630337317 $x_1$에 대한 $y$ 의 상관계수,$r_{x_1y}: 0.8143$ . $x_2$에 대한 $y$ 의 상관계수,$r_{x_2y}: 0.7698$ . $x_1$에 대한 $x_2$ 의 상관계수,$r_{x_1x_2}: 0.6138$ . 2) $y= beta_0 + beta_1x_1+ epsilon$&#51012; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#44228;&#49688;&#50752; &#51092;&#52264;&#51228;&#44273;&#54633;&#51012; &#44396;&#54616;&#50668;&#46972;. . 회귀계수 . coef(lmx1y) . &lt;dl class=dl-inline&gt;(Intercept)6.18984870668621x11.07223035627135&lt;/dl&gt; $ to beta_0 = 6.19 , beta_1 = 1.072 $ . 잔차제곱합 . sum((y-(6.19 + 1.072*x1))^2) . 299.329232 3) $y= beta_0 + beta_2x_2+ epsilon$&#51012; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#44228;&#49688;&#50752; &#51092;&#52264;&#51228;&#44273;&#54633;&#51012; &#44396;&#54616;&#50668;&#46972;. . 회귀계수 . coef(lmx2y) . &lt;dl class=dl-inline&gt;(Intercept)30.5714285714286x23.64285714285714&lt;/dl&gt; $ to beta_0 = 30.57 , beta_2 = 3.643 $ . 잔차제곱합 . sum((y-(30.57 + 3.643*x2))^2) . 361.857144 4) $y= beta_0 + beta_1x_1+ beta_2x_2+ epsilon$&#51012; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#44228;&#49688;&#50752; &#51092;&#52264;&#51228;&#44273;&#54633;&#51012; &#44396;&#54616;&#50668;&#46972;. . lmyx1x2 &lt;- lm(y~x1+x2) . 회귀계수 . coef(lmyx1x2) . &lt;dl class=dl-inline&gt;(Intercept)6.55304825080945x10.722037958356366x22.05012635236516&lt;/dl&gt; $ to beta_0 = 6.553 , beta_1 = 0.722, beta_2 = 2.05 $ . 잔차제곱합 . sum((y-(6.553 + 0.722*x1 + 2.05*x2 ))^2) . 195.427516 5) 3&#44060; &#47784;&#54805;&#51032; &#51092;&#52264;&#51228;&#44273;&#54633;&#51012; &#48708;&#44368;&#54616;&#44256; &#44536; &#44208;&#44284;&#50640; &#45824;&#54644; &#45436;&#51032;&#54616;&#50668;&#46972; . 중회귀모형의 잔차제곱합이 $195.43$으로 가장 작다. 이것은 $x_1,x_2$이 서로 연관이 있고, 이때의 $y$가 제일 잘 적합됐다는 뜻으로 해석 할 수 있다. . . 7.10 . 다음 주어진 자료에 대하여 . 범주 값 . $y$ | 6 | 8 | 1 | 0 | 5 | 3 | 2 | -4 | 10 | -3 | 5 | . $x_1$ | 1 | 4 | 9 | 11 | 3 | 8 | 5 | 10 | 2 | 7 | 6 | . $x_2$ | 8 | 2 | -8 | -10 | 6 | -6 | 0 | -12 | 4 | -2 | -4 | . 1) &#51473;&#49440;&#54805;&#54924;&#44480;&#47784;&#54805; $y = beta_0 + beta_1x_1+ beta_2x_2+ epsilon$&#51012; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#49440;&#51012; &#52628;&#51221;&#54616;&#50668;&#46972;. . y &lt;- c(6,8,1,0,5,3,2,-4,10,-3,5) x1 &lt;- c(1,4,9,11,3,8,5,10,2,7,6) x2 &lt;- c(8,2,-8,-10,6,-6,0,-12,4,-2,-4) . lm710 &lt;- lm(y ~ x1+x2) . coef(lm710) . &lt;dl class=dl-inline&gt;(Intercept)14x1-2x2-0.500000000000001&lt;/dl&gt; $ beta_0 = 14 , beta_1 = -2 , beta_2 = -0.5 $ . 2) $ sigma^2$&#51032; &#48520;&#54200;&#52628;&#51221;&#47049; $MSE$&#47484; &#44396;&#54616;&#44256; &#52628;&#51221;&#46108; $MSE$&#44050;&#51012; &#51060;&#50857;&#54616;&#50668; . anova(lm710) . A anova: 3 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x11 | 116.081818 | 116.081818 | 13.6566845 | 0.006081901 | . x21 | 5.918182 | 5.918182 | 0.6962567 | 0.428255902 | . Residuals8 | 68.000000 | 8.500000 | NA | NA | . $MSE = 8.5$ . (1) $Var(b_1), Var(b_2)$&#47484; &#44033;&#44033; &#52628;&#51221;&#54616;&#50668;&#46972;. . X &lt;- matrix(c(1,1,1,1,1,1,1,1,1,1,1,array(x1),array(x2)),11,3) B &lt;- matrix(c(14,-2,-0.5),3,1) Y &lt;- matrix(y,11,1) . XtX &lt;- t(X) %*% X #[X&#39;X] XtX . A matrix: 3 × 3 of type dbl 11 | 66 | -22 | . 66 | 506 | -346 | . -22 | -346 | 484 | . XtXr &lt;- solve(XtX) # [X&#39;X]의 역함수 XtXr . A matrix: 3 × 3 of type dbl 4.3704790 | -0.84946237 | -0.40860215 | . -0.8494624 | 0.16897081 | 0.08218126 | . -0.4086022 | 0.08218126 | 0.04224270 | . (XtXr)* (8.5^2) # [(X&#39;X)^-1]*(MSE^2) = Var(b) . A matrix: 3 × 3 of type dbl 315.76711 | -61.373656 | -29.521505 | . -61.37366 | 12.208141 | 5.937596 | . -29.52151 | 5.937596 | 3.052035 | . $Var(b_1) : [(X&#39;X)^{-1}]*(MSE^2)$ 의 대각 2번째 원소 . 12.21 . $Var(b_2) :[(X&#39;X)^{-1}]*(MSE^2)$ 의 대각 3번째 원소&gt; 3.05 . (2) $x_1 =3, x_2=5$&#51068; &#46412; $y$&#51032; &#50696;&#52769;&#44050;&#51032; &#48516;&#49328;&#51012; &#44396;&#54616;&#50668;&#46972;. . 14-2*3-0.5*5 #y의 예측값 . 5.5 sum((5.5-mean(14-2*x1-0.5*x2))^2) . 6.25 $𝑦$ 의 예측값의 분산 : 6.25 .",
            "url": "https://cjfal.github.io/dj/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/10/25/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D7%EC%9E%A5%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/10/25/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D7%EC%9E%A5%EA%B3%BC%EC%A0%9C.html",
            "date": " • Oct 25, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "기계학습 3장 예제 파이썬",
            "content": "Advertising data &#48520;&#47084;&#50724;&#44256; df&#47196; &#47564;&#46308;&#44592; . import matplotlib.pyplot as plt import numpy as np import pandas as pd ad = pd.read_csv(&quot;Advertising.csv&quot;, header=0) # csv 파일 불러오기 . 1. Logistic regression model . statmodels에 의한 로지스틱 모형 적합 . ad[&#39;sales&#39;] = (ad[&#39;sales&#39;] &gt; 10)*1 #sales 변수가 10을 넘으면 1(판매량 높음), 그렇지 않으면 0으로 할당하여 분류문제로 세팅 X = ad[[&#39;TV&#39;,&#39;radio&#39;,&#39;newspaper&#39;]] Y = ad[&#39;sales&#39;] . linear model with statsmodels . import statsmodels.api as sm #statsmodels 패키지 불러오기 model = sm.GLM.from_formula(&quot;sales ~ TV + radio + newspaper&quot;, family = sm.families.Binomial(), data=ad) result = model.fit() result.summary() . Generalized Linear Model Regression Results Dep. Variable: sales | No. Observations: 200 | . Model: GLM | Df Residuals: 196 | . Model Family: Binomial | Df Model: 3 | . Link Function: logit | Scale: 1.0000 | . Method: IRLS | Log-Likelihood: -13.360 | . Date: Sat, 23 Oct 2021 | Deviance: 26.719 | . Time: 20:03:15 | Pearson chi2: 30.1 | . No. Iterations: 11 | | . Covariance Type: nonrobust | | . | coef std err z P&gt;|z| [0.025 0.975] . Intercept -21.5305 | 6.269 | -3.435 | 0.001 | -33.817 | -9.244 | . TV 0.2089 | 0.060 | 3.454 | 0.001 | 0.090 | 0.328 | . radio 0.4054 | 0.124 | 3.277 | 0.001 | 0.163 | 0.648 | . newspaper -0.0086 | 0.026 | -0.332 | 0.740 | -0.059 | 0.042 | . sklearn&#51012; &#51060;&#50857;&#54620; &#47196;&#51648;&#49828;&#54001; &#51201;&#54633; . (머신러닝에 특화된 패키지 , 서머리같은건 제공 잘 안해줌) . from sklearn.linear_model import LogisticRegression . model1 = LogisticRegression() # model instance setup model2 = model1.fit(X,Y) # model fitting to data print(model2.intercept_) print(model2.coef_) print(model2.score(X,Y)) . [-21.16756665] [[ 0.2054616 0.39803989 -0.00823107]] 0.97 . from sklearn import metrics Y_pred = model2.predict(X) . cm = metrics.confusion_matrix(Y, Y_pred) # confusion matrix cm . array([[ 42, 3], [ 3, 152]]) . model2.score(X,Y) # 정분류율 . 0.97 . &#50696;&#52769;&#49457;&#45733;&#51032; &#54217;&#44032;&#47484; &#50948;&#54644; &#54984;&#47144;&#51088;&#47308;&#50752; &#54217;&#44032;&#51088;&#47308;&#47484; &#51201;&#45817;&#54620; &#48708;&#50984;&#47196; &#45208;&#45572;&#50612; &#44228;&#49328;&#54644; &#48372;&#51088;. . from sklearn.model_selection import train_test_split X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=0) . model1 = LogisticRegression() # model instance setup model2 = model1.fit(X_train,Y_train) # model fitting to data . print(model2.intercept_) print(model2.coef_) print(model2.score(X,Y)) . [-21.87095867] [[0.20169776 0.38998892 0.02502465]] 0.96 . model2.predict_proba(X_test) # predicted probability for 0 vs 1 . array([[3.68362025e-01, 6.31637975e-01], [9.98889402e-01, 1.11059773e-03], [9.49784560e-01, 5.02154405e-02], [0.00000000e+00, 1.00000000e+00], [7.68983531e-08, 9.99999923e-01], [9.99484252e-01, 5.15748381e-04], [3.03408631e-01, 6.96591369e-01], [1.36557432e-13, 1.00000000e+00], [8.49772353e-01, 1.50227647e-01], [1.22679644e-12, 1.00000000e+00], [0.00000000e+00, 1.00000000e+00], [2.75460182e-01, 7.24539818e-01], [1.77948022e-05, 9.99982205e-01], [2.34914310e-11, 1.00000000e+00], [1.08841492e-02, 9.89115851e-01], [3.33913329e-05, 9.99966609e-01], [0.00000000e+00, 1.00000000e+00], [9.97690690e-01, 2.30930953e-03], [1.23437704e-06, 9.99998766e-01], [3.13082893e-14, 1.00000000e+00], [0.00000000e+00, 1.00000000e+00], [6.14898732e-04, 9.99385101e-01], [1.01664233e-10, 1.00000000e+00], [2.94828121e-06, 9.99997052e-01], [9.99942555e-01, 5.74451124e-05], [5.25259866e-08, 9.99999947e-01], [1.28092454e-07, 9.99999872e-01], [0.00000000e+00, 1.00000000e+00], [1.99917860e-11, 1.00000000e+00], [9.96672041e-01, 3.32795930e-03], [1.32267261e-04, 9.99867733e-01], [0.00000000e+00, 1.00000000e+00], [0.00000000e+00, 1.00000000e+00], [0.00000000e+00, 1.00000000e+00], [9.99992240e-01, 7.76014393e-06], [9.99997225e-01, 2.77524737e-06], [9.83558085e-01, 1.64419151e-02], [1.57451874e-09, 9.99999998e-01], [3.82797066e-05, 9.99961720e-01], [9.99992461e-01, 7.53906740e-06], [9.39035328e-02, 9.06096467e-01], [9.97181415e-01, 2.81858519e-03], [7.61125996e-09, 9.99999992e-01], [3.41060513e-13, 1.00000000e+00], [1.02140518e-14, 1.00000000e+00], [2.49832425e-05, 9.99975017e-01], [9.99999996e-01, 4.18250051e-09], [3.06304657e-01, 6.93695343e-01], [2.38279196e-09, 9.99999998e-01], [9.02643249e-02, 9.09735675e-01], [1.29806943e-03, 9.98701931e-01], [0.00000000e+00, 1.00000000e+00], [0.00000000e+00, 1.00000000e+00], [3.20645732e-11, 1.00000000e+00], [9.07025643e-01, 9.29743571e-02], [9.80798465e-01, 1.92015346e-02], [0.00000000e+00, 1.00000000e+00], [9.74632153e-10, 9.99999999e-01], [4.36317649e-13, 1.00000000e+00], [9.99776048e-01, 2.23951730e-04]]) .",
            "url": "https://cjfal.github.io/dj/python/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5/2021/10/25/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5-3%EC%9E%A5-%EC%98%88%EC%A0%9C%ED%8C%8C%EC%9D%B4%EC%8D%AC.html",
            "relUrl": "/python/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5/2021/10/25/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5-3%EC%9E%A5-%EC%98%88%EC%A0%9C%ED%8C%8C%EC%9D%B4%EC%8D%AC.html",
            "date": " • Oct 25, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "기계학습 3장 예제 R",
            "content": "&#50696;&#51228;1 : Advertising data . ad &lt;- read.csv(&quot;Advertising.csv&quot;) options(digits=4) # 자료수 표현 . fit &lt;- lm(sales ~TV + radio +newspaper , data = ad) fit1 &lt;- summary(fit) . (pvlaue=1-pf(fit1$fstatistic[1],fit1$fstatistic[2], fit1$fstatistic[3])) # pvalue for F test . value: 0 F검정결과 p값이 매우작아 연관성이 있다고 확신할 수 있다. (계수중 하나는 0이 아니다.) . RSE = sqrt(sum(fit$residuals^2)/(fit$df.residual)) #연관성의 정도 RSE . 1.68551037341474 R2 = fit1$r.squared R2 . 0.897210638178952 fit1$coefficients[,4] # 어떤 media가 판매량에 영향을 미치는가? . &lt;dl class=dl-inline&gt;(Intercept)1.26729450513134e-17TV1.50995995481439e-81radio1.50533892057562e-54newspaper0.859915050080572&lt;/dl&gt; 신문은 연관성이 관측되지 않음, 귀무가설을 기각한다. 0.8599 : 굉장히 큰값 . cbind(fit1$coefficients[,1]-2*fit1$coefficients[,2] ,fit1$coefficients[,1]+2*fit1$coefficients[,2]) #신뢰구간, 추정치 +- 표준편차*2 . A matrix: 4 × 2 of type dbl (Intercept) 2.31507 | 3.56271 | . TV 0.04297 | 0.04855 | . radio 0.17131 | 0.20575 | . newspaper-0.01278 | 0.01070 | . 신문에 대해서는 신뢰구간이 0을 포함하는 비교적 넓은 구간 . 선형성이 만족되는가? . 앞선 Figure 4 에서 선형성을 의심할 수 있는 정황이 발견 (3D plot) . fit2 = lm(sales ~ TV + radio, data=ad) # main fit3 = lm(sales ~ TV * radio, data=ad) # interaction c(summary(fit2)$r.squared,summary(fit3)$r.squared) #상호작용이 존재하는가? . &lt;ol class=list-inline&gt;0.897194261082896 | 0.967790549848252 | &lt;/ol&gt; summary(fit3)$coefficients[4,] # interaction term . &lt;dl class=dl-inline&gt;Estimate0.00108649469798996Std. Error5.24203957977123e-05t value20.7265641828171Pr(&gt;|t|)2.75768099928009e-51&lt;/dl&gt; . &#50696;&#51228;2 : &#8216;mtcars&#8217; dataset : &#49440;&#54805;&#47784;&#54805; - gradient descent algorithm &#51201;&#54633; . . . lm( mtcars$mpg~ mtcars$disp) . Call: lm(formula = mtcars$mpg ~ mtcars$disp) Coefficients: (Intercept) mtcars$disp 29.5999 -0.0412 . gradientDesc 랑 lm이랑 거의 비슷 .",
            "url": "https://cjfal.github.io/dj/r/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5/2021/10/25/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5-3%EC%9E%A5-%EC%98%88%EC%A0%9CR.html",
            "relUrl": "/r/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5/2021/10/25/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5-3%EC%9E%A5-%EC%98%88%EC%A0%9CR.html",
            "date": " • Oct 25, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "데이터시각화 10/18 강의 과제",
            "content": "import numpy as np import matplotlib.pyplot as plt import pandas as pd from plotnine import * . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/extremum.csv&#39;) . temp=np.array(df.iloc[:,3]) . np.random.seed(1) ϵ1=np.random.normal(size=656, scale=10) icecream=temp*2 + 30 + ϵ1 . np.random.seed(2) ϵ2=np.random.normal(size=656,scale=1) disease=temp*0.5 + 40 +ϵ2 . df1=pd.DataFrame({&#39;temp&#39;:temp, &#39;icecream&#39;:icecream, &#39;disease&#39;:disease}) . def f(x): if x&lt;0: y=&#39;group0&#39; elif x&lt;10: y=&#39;group10&#39; elif x&lt;20: y=&#39;group20&#39; else: y=&#39;group30&#39; return y . df1[&#39;temp2&#39;]=list(map(f,df1.temp)) . ggplot(data=df1)+geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),alpha=0.5) . &lt;ggplot: (8774727276960)&gt; . ggplot(data=df1)+geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),alpha=0.2)+geom_smooth(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),size=2,linetype=&#39;dashed&#39;) . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8774723030923)&gt; . np.random.seed(1) ϵ1=np.random.normal(size=656, scale=10) icecream=temp*2 + 30 + ϵ1 . np.random.seed(2) ϵ2=np.random.normal(size=656,scale=1) disease= 30+ temp*0.0 + icecream*0.15 +ϵ2*2 . df2=pd.DataFrame({&#39;temp&#39;:temp,&#39;icecream&#39;:icecream,&#39;disease&#39;:disease}) df2[&#39;temp2&#39;]=list(map(f,df2.temp)) . ggplot(data=df2)+geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),alpha=0.2)+geom_smooth(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),size=2,linetype=&#39;dashed&#39;) . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8774722931447)&gt; .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/18/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%941018%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/18/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%941018%EA%B3%BC%EC%A0%9C.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post18": {
            "title": "회귀분석 6장",
            "content": "6.2 . 다음 자료는 A 제품을 생산하는 공장의 총자산(x)과 총수입(y)과의 관계를 조사한 표이다. . x 25 6 8 5 1 24 17 2 13 14 . y | 10.1 | 2.9 | 3.0 | 1.8 | 0.1 | 9.4 | 6.9 | 0.3 | 5.1 | 6.0 | . 1) &#49328;&#51216;&#46020;&#47484; &#44536;&#47532;&#44256;, &#51201;&#54633;&#54620; &#47784;&#54805;&#51012; &#49444;&#51221;&#54616;&#50668;&#46972;. . x &lt;- c(25,6,8,5,1,24,17,2,13,14) y &lt;- c(10.1,2.9,3.0,1.8,0.1,9.4,6.9,0.3,5.1,6.0) plot(x,y) lm62&lt;-lm(y~x) abline(lm62,col=&#39;red&#39;) . 적합한 모형은 1차선형회귀모형이다. . 2) &#50896;&#51216;&#51012; &#51648;&#45208;&#45716; &#54924;&#44480;&#47784;&#54805; $y= beta_1x + epsilon$ &#51012; &#51201;&#54633;&#49884;&#53412;&#44256; &#48516;&#49328;&#48516;&#49437;&#54364;&#47484; &#51089;&#49457;&#54616;&#50668; &#44480;&#47924;&#44032;&#49444; $H_0 : beta_1 = 0 $ &#51012; &#44160;&#51221;&#54616;&#50668;&#46972;. $ alpha = 0.05 $ . b1 구하기 . sum(x*y)/sum(x^2) #기울기 구하기 . 0.401410579345088 b1(기울기) 값은 0.401410579345088 이다. . 불편 추정량: yhat = 0.401410579345088*x . yhat = 0.401410579345088*x . y-0.401410579345088*x #잔차구하기 . &lt;ol class=list-inline&gt;0.0647355163727994 | 0.491536523929472 | -0.211284634760704 | -0.20705289672544 | -0.301410579345088 | -0.233853904282112 | 0.0760201511335046 | -0.502821158690176 | -0.118337531486144 | 0.380251889168768 | &lt;/ol&gt; sum(y-0.401410579345088*x) #잔차의 합이 0이 아니다. . -0.56221662468512 영가설 $H_0 : beta_1 = 0$ 검정 . 회귀모형의 변동 (F 통계량 구하기) . SST = sum(y^2) SSR = sum(yhat^2) SSE = SST - SSR MSE = SSE/(length(x)-1) F0 = (SSR)/(SSE/(length(x)-1)) F0 . 3212.53761820648 F 통계량은 3212.53761820648 이고 유의수준 0.05일때 자유도 1,9인 F값은 3.26 이므로 영가설 $H_0$를 기각한다. . 즉, x는 y에 영향을 끼친다. . 3) &#45800;&#49692;&#54924;&#44480;&#47784;&#54805; $y= beta_0 + beta_1x+ epsilon$&#51012; &#51201;&#54633;&#49884;&#53412;&#44256; &#44208;&#51221;&#44228;&#49688; $R^2$ &#51012; &#44228;&#49328;&#54616;&#50668;&#46972;. . 단순회귀모형 적합 . coef(lm62) . &lt;dl class=dl-inline&gt;(Intercept)-0.168452830188679x0.411169811320755&lt;/dl&gt; $ beta_0 = -0.168452830188679 , beta_1 = 0.411169811320755 $ . 단순회귀모형 :$y = -0.168452830188679 + 0.411169811320755x$ . summary(lm62)$r.squared #결정계수 . 0.99289614378722 결정계수가 1에 굉장히 가까운 것으로 보아 관계를 설명하기 굉장히 좋은 모형이다. . . 6.5 . 다음 표는 남녀 어린이 각각 16명에게 비타민B를 복용시켰을 때 4주간의 성장률에 관한 자료이다. . 남 여 . 성장률(y) | 복용량(x) | 성장률(y) | 복용량(x) | . 17.1 | 0.301 | 18.5 | 0.301 | . 14.3 | 0.301 | 22.1 | 0.301 | . 21.6 | 0.301 | 15.3 | 0.301 | . 24.5 | 0.602 | 23.6 | 0.602 | . 20.6 | 0.602 | 26.9 | 0.602 | . 23.8 | 0.602 | 20.2 | 0.602 | . 27.7 | 0.903 | 24.3 | 0.903 | . 31.0 | 0.903 | 27.1 | 0.903 | . 29.4 | 0.903 | 30.1 | 0.903 | . 30.1 | 1.204 | 28.1 | 0.903 | . 28.6 | 1.204 | 30.3 | 1.204 | . 34.2 | 1.204 | 33.0 | 1.204 | . 37.3 | 1.204 | 35.8 | 1.204 | . 33.3 | 1.505 | 32.6 | 1.505 | . 31.8 | 1.505 | 36.1 | 1.505 | . 40.2 | 1.505 | 30.5 | 1.505 | . 1) &#51452;&#50612;&#51652; &#51088;&#47308;&#50640; $y= beta_0 + beta_1x + epsilon$ &#51060; &#49457;&#47549;&#54620;&#45796;&#44256; &#44032;&#51221;&#54616;&#44256; &#45224;&#45376; &#50612;&#47536;&#51060; &#44033;&#44033;&#51032; &#44221;&#50864;&#50640; &#54924;&#44480;&#49440;&#51012; &#52628;&#51221;&#54616;&#50668;&#46972;. . 남자 어린이의 경우 . eatboy &lt;- c(0.301,0.301,0.301,0.602,0.602,0.602,0.903,0.903,0.903,1.204,1.204,1.204,1.204,1.505,1.505,1.505) growboy &lt;- c(17.1,14.3,21.6,24.5,20.6,23.8,27.7,31.0,29.4,30.1,28.6,34.2,37.3,33.3,31.8,40.2) lmboy &lt;- lm(growboy~eatboy) coef(lmboy) . &lt;dl class=dl-inline&gt;(Intercept)14.1775757575758eatboy14.8253297090506&lt;/dl&gt; 남자어린이의 추정된 회귀선은 $y = 14.1775757575758 + 14.8253297090506x $ 이다. . 여자 어린이의 경우 . eatgirl &lt;- c(0.301,0.301,0.301,0.602,0.602,0.602,0.903,0.903,0.903,0.903,1.204,1.204,1.204,1.505,1.505,1.505) growgirl &lt;- c(18.5, 22.1,15.3 ,23.6 ,26.9 ,20.2 ,24.3 ,27.1 ,30.1 ,28.1 ,30.3 , 33.0,35.8 ,32.6 ,36.1 ,30.5) lmgirl &lt;- lm(growgirl~eatgirl) coef(lmgirl) . &lt;dl class=dl-inline&gt;(Intercept)15.65625eatgirl12.7353266888151&lt;/dl&gt; 여자어린이의 추정된 회귀선은 $y = 15.65625 +12.7353266888151x $ 이다. . 2) &#46160; &#44060;&#51032; &#52628;&#51221;&#46108; &#54924;&#44480;&#49440;&#51012; &#44057;&#51008; &#54217;&#47732;&#49345;&#50640; &#45208;&#53440;&#45236;&#50612; &#48708;&#44368;&#54644; &#48372;&#46972;. . plot(growboy~eatboy,col=&quot;red&quot;) abline(lmboy,col=&#39;red&#39;) par(new = T) plot(growgirl~eatgirl,col=&#39;blue&#39;) abline(lmgirl,col=&#39;blue&#39;) . 3) &#46160; &#54924;&#44480;&#51649;&#49440;&#51032; &#44592;&#50872;&#44592;&#44032; &#44057;&#51008;&#51648; &#44160;&#51221;&#54616;&#50668;&#46972;. $ alpha = 0.05 $ . boycoef &lt;- summary(lmboy)$coefficients girlcoef &lt;- summary(lmgirl)$coefficients db &lt;- (girlcoef[2,1]-boycoef[2,1]) #두 기울기의 차이 sd &lt;- sqrt(girlcoef[2,2]^2+boycoef[2,2]^2) #두 기울기의 분산 합 df &lt;- (lmboy$df.residual+lmgirl$df.residual) #자유도 td &lt;- (abs(db/sd)) #t 통계량 2*pt(-td,df) #유의확률 . 0.432356448008467 기울기의 검정 $H_0 : beta_{1boy} = beta_{1girl}$ 에 대한 유의확률이 0.43 이므로 영가설을 기각할 수 없다. 동일한 기울기로 볼 수있다. . 4) &#46160; &#54924;&#44480;&#51649;&#49440;&#51032; &#46041;&#51068;&#49457; &#50668;&#48512;&#47484; &#44160;&#51221;&#54616;&#50668;&#46972;. $ alpha = 0.05 $ . anova(lmboy) anova(lmgirl) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . eatboy 1 | 616.0656 | 616.06556 | 58.36567 | 2.331699e-06 | . Residuals14 | 147.7738 | 10.55527 | NA | NA | . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . eatgirl 1 | 440.8333 | 440.83333 | 52.03501 | 4.469824e-06 | . Residuals14 | 118.6060 | 8.47186 | NA | NA | . 분산분석표에서 완전모형의 잔차제곱합 . $SSE(F) = SSE_1 + SSE_2 = 147.7738 + 118.6060 = 266.3798$ . 자유도 : $df_F = 14 + 14 =28 $ . eatbar &lt;- (1/(length(eatboy)*2))*(sum(eatboy)+sum(eatgirl)) growbar &lt;- (1/(length(eatboy)*2))*(sum(growboy)+sum(growgirl)) sum((eatboy-eatbar)*(growboy-growbar))+sum((eatgirl-eatbar)*(growgirl-growbar))/(sum((eatboy-eatbar)^2)+(sum((eatgirl-eatbar)^2))) #b1(기울기) . 47.8825170071177 growbar-47.8825170071177*eatbar #b0 (절편) . -16.1883077830255 . . 6.7 . 단순 회귀 모형에서 회귀제곱합 . $SSR = y&#39;[X(X&#39;X)^{-1} - frac{J}{n}]y = sum_{}^{} ( hat{y_i}- bar{y})^2$ . 의 기댓값을 [정리 6.4]를 이용하여 구하고 잔차제곱합 . $ SSE = sum_{i=1}^{n} (y_i - hat{y_1})^2 $ = $ y&#39;[I-X(X&#39;X)^{-1} X&#39;] y $ . 의 기댓값도 구하여 보아라 . - [정리 6.4] : 만약 벡터 $y sim N( mu,V)$ 이면 ($V$는 분산공분산행렬) . 1) $E(y&#39;Ay) = tr(AV) + mu&#39;A mu $ (이것은 y가 정규분포가 아닐 때도 성립) . 2) $Cov(y,y&#39;Ay) = 2VA mu$ . 1) . $E(SSR) = E(y&#39;Ay) to$ A = $ [X(X&#39;X)^{-1} - frac{J}{n}] $ . $ V = I sigma^2 $ 이므로 . $E(SSR) = sigma^2 tr(A) + mu&#39;A mu $ . = $ sigma^2 + { beta_1}^2 sum{}^{} (x_i - bar{x})^2 $ 이다. . 2) . $E(SSE) = E(y&#39;By) to$ B = $ [I - X(X&#39;X)^{-1}$ . $E(SSE) = sigma^2 tr(B) + mu&#39;B mu $ . = $(n-2) sigma^2$ 이다. . . 6.10 . 단순회귀모형 . $ y = beta_0 + beta_1 x + epsilon $ , $ epsilon sim N(0, sigma^2)$ . 에서 $H_0 : beta_1 = 0$ 이 성립하면 검정통계량 . $F_0 = frac{MSR}{MSE}$ . 은 비중심모수 $ lambda = 0$ 인 중심 $F(1,n-2)$ 분포가 됨을 보여라([정리 6.8]이용) . - [정리 6.8] . $y sim N( mu,I)$ 이면 $ y&#39;Ay sim $ $ chi^2 {&#39;} $ $ (k, frac{1}{2} mu&#39;A mu)$ 이 되기 위한 필요충분조건은 $A$가 계수 $k$인 멱등행렬이다. . 풀이 . $SSR = y&#39;[X(X&#39;X)^{-1} - frac{J}{n}]y $ . $ SSE = y&#39;[I-X(X&#39;X)^{-1} X&#39;] y $ 에서 . $[X(X&#39;X)^{-1} - frac{J}{n}]$ = A . $[I-X(X&#39;X)^{-1} X&#39;]$ = B 로 두고 $SSR,SSE$ 를 $ sigma^2$ 으로 나누면 . $ frac{SSR}{ sigma^2} = y&#39; frac{A}{ sigma^2}y $ 이고, . $ frac{SSE}{ sigma^2} = y&#39; frac{B}{ sigma^2}y $ 이다. . AVB = 0 이므로 바로 위 두식은 독립이다. . F 통계량을 구해보면 . $ F = frac{MSR}{MSE} = frac{ frac{SSR}{ sigma^2}/1}{ frac{SSE}{ sigma^2}/(n-2)} = F&#39; $ 이다. (이때 $F&#39; : (1,n-2; lambda)$) . 여기서 $ lambda = { beta_1}^2 sum{}^{} (x_i- bar{x})^2 / 2 sigma^2 $ 이다. . 이때 $ beta_1 = 0$ 이면, $ lambda = 0 $이므로 . $F_0 = frac{MSR}{MSE}$ 는 비중심모수 $ lambda = 0$ 인 중심 $F(1,n-2)$ 분포가 된다. .",
            "url": "https://cjfal.github.io/dj/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/10/15/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D6%EC%9E%A5%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/10/15/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D6%EC%9E%A5%EA%B3%BC%EC%A0%9C.html",
            "date": " • Oct 15, 2021"
        }
        
    
  
    
        ,"post19": {
            "title": "회귀분석 5장",
            "content": "5.2 . - 어떤 화학반응에서 촉매의 양(x)이 합성물의 소득량(y)에 어떻게 영향을 끼치는지 알아보기 위해 12번 실험하여 다음의 자료를 얻었다. . x(g) 1 1 1 2 2 2 4 4 4 8 8 8 . y(g) | 13.5 | 15.4 | 16.1 | 18.2 | 19.6 | 20.2 | 21.8 | 22.2 | 23.1 | 23.6 | 24.7 | 24.9 | . x &lt;- c(1,1,1,2,2,2,4,4,4,8,8,8) y &lt;- c(13.5,15.4,16.1,18.2,19.6,20.2,21.8,22.2,23.1,23.6,24.7,24.9) . 1) x&#50640;&#45824;&#54620; y&#51032; &#49328;&#51216;&#46020;&#47484; &#44536;&#47140;&#46972;. . plot(x,y,col=&quot;red&quot;) . 2) $ log_{10} x$&#47484; &#44228;&#49328;&#54616;&#44256; $ log_{10} x$&#50640; &#45824;&#54620; y&#44050;&#51032; &#49328;&#51216;&#46020;&#47484; &#44536;&#47140;&#46972;. . logx &lt;- log(x,base=10) logx . &lt;ol class=list-inline&gt;0 | 0 | 0 | 0.301029995663981 | 0.301029995663981 | 0.301029995663981 | 0.602059991327962 | 0.602059991327962 | 0.602059991327962 | 0.903089986991944 | 0.903089986991944 | 0.903089986991944 | &lt;/ol&gt; plot(logx,y,col=&quot;blue&quot;) . par(mfrow=c(1,2)) plot(x,y,col=&quot;red&quot;) plot(logx,y,col=&quot;blue&quot;,xlim=c(0,8)) # xlim 으로 x범위 조정 . 3) &#50948; 1)&#44284; 2) &#51473; &#50612;&#45712; &#44163;&#51060; &#45908; &#49440;&#54805;&#50640; &#44032;&#44620;&#50868;&#44032;? . 2)의 로그 그래프가 같은 범위에서 더 선형에 가깝다. . . 5.3 . - 연습문제 5.2의 자료에 대해 다음 질문에 답하여라. . 1) $ y = beta_0 + beta_1 x + epsilon $ &#47484; &#51201;&#54633;&#49884;&#53412;&#44256; $MSE$ &#47484; &#44396;&#54616;&#50668;&#46972;. . lm53 &lt;- lm(y~x) coefficients(lm53) . &lt;dl class=dl-inline&gt;(Intercept)15.8130434782609x1.18985507246377&lt;/dl&gt; $y= 15.51 + 1.19x$ . anova(lm53) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x 1 | 122.10888 | 122.108877 | 34.1147 | 0.0001636405 | . Residuals10 | 35.79362 | 3.579362 | NA | NA | . $MSE$ :Mean Square Residuals = 3.579362 . 2) $ y = beta_0 + beta_1 log_{10} x + epsilon $ &#47484; &#44032;&#51221;&#54616;&#44256; $MSE$ &#47484; &#44228;&#49328;&#54616;&#50668;&#46972;. . lm53log &lt;- lm(y~logx) anova(lm53log) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . logx 1 | 146.32817 | 146.328167 | 126.4247 | 5.374543e-07 | . Residuals10 | 11.57433 | 1.157433 | NA | NA | . $MSE$ :Mean Square Residuals = 1.157433 . 3) &#50948; 1)&#44284; 2)&#51032; &#47784;&#54805; &#51473; &#50612;&#45712; &#44163;&#51060; &#45908; &#51201;&#54633;&#54620;&#51648; $MSE$ &#47484; &#51060;&#50857;&#54616;&#50668; &#48708;&#44368;&#54616;&#50668;&#46972;. . $ log_{10} x$ 에서의 $MSE$ 가 더 작다. 즉, 2)의 모형이 더 적합하다. . . 5.12 . - 다음 과 같은 자료에 대하여 . x 2 6 10 . y | 4 | 7 | 4 | . 1) &#45800;&#49692;&#54924;&#44480;&#47784;&#54805; $ y = beta_0 + beta_1 x + epsilon $ , $ epsilon sim N(0, sigma^2)$&#51012; &#44032;&#51221;&#54616;&#44256; &#54924;&#44480;&#51649;&#49440;&#51012; &#52628;&#51221;&#54616;&#50668;&#46972;. &#46608; $ beta_1$ &#51032; 90% &#49888;&#47280;&#44396;&#44036;&#51012; &#44396;&#54616;&#50668;&#46972;. . x &lt;- c(2, 6, 10) y &lt;- c(4, 7, 4) lm512 &lt;- lm(y~x) coefficients(lm512) confint(lm512,level = 0.90) # 기울기와 절편의 90% 신뢰구간 . &lt;dl class=dl-inline&gt;(Intercept)5x-4.81432375190295e-16&lt;/dl&gt; A matrix: 2 × 2 of type dbl 5 %95 % . (Intercept)-13.676329 | 23.676329 | . x -2.733935 | 2.733935 | . 기울기 $ beta_1$의 90% 신뢰구간:$(-2.733935, 2.733935)$ . 2) $ y = beta_0 + beta_1 x + epsilon $ , $ epsilon sim N(0,k^2 {x_i}^2)$ &#51012; &#44032;&#51221;&#54616;&#50668; &#44032;&#51473;&#54924;&#44480;&#51649;&#49440;&#51012; &#52628;&#51221;&#54616;&#44256; $ beta_1$ &#51032; 90% &#49888;&#47280;&#44396;&#44036;&#51012; &#44396;&#54616;&#50668;&#46972;. . 오차항의 분산 : 2 . w &lt;- sqrt(1/2) xw &lt;- x/w yw &lt;- y/w b0w &lt;- 5/w b1w &lt;- 0 xbar &lt;- mean(x) ybar &lt;- mean(y) . 가중 정규방정식의 해 . sum(w*(x-xbar)*(y-ybar))/sum(w*(x-xbar)^2) #b1 . 0 ybar #b0 . 5 3) &#50948; 1), 2)&#51032; &#44208;&#44284;&#47484; &#48708;&#44368;&#54616;&#50668;&#46972; . 1)과 2) 는 y=5 로 같다. . . 5.14 . - 다음은 어떤 컴퓨터 부품의 과거 14개월(x) 동안의 판매액(y)에 관한 자료이다. . x 1 2 3 4 5 6 7 8 9 10 11 12 13 14 . y | 6.0 | 6.3 | 6.1 | 6.8 | 7.5 | 8.0 | 8.1 | 8.5 | 9.0 | 8.7 | 7.9 | 8.2 | 8.4 | 9.0 | . 1) &#45936;&#51060;&#53552;&#51032; &#49328;&#51216;&#46020;&#47484; &#44536;&#47140;&#46972;. . x &lt;- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14) y &lt;- c(6.0,6.3,6.1,6.8,7.5,8.0,8.1,8.5,9.0,8.7,7.9,8.2,8.4,9.0) plot(x,y) . 2) &#45800;&#49692;&#54924;&#44480;&#47784;&#54805;&#51012; &#44032;&#51221;&#54616;&#44256; &#51092;&#52264;&#51032; &#49328;&#51216;&#46020;&#47484; &#45208;&#53440;&#45236;&#44256; &#51088;&#44592;&#49345;&#44288;&#51060; &#51316;&#51116;&#54616;&#45716;&#51648;&#47484; &#44160;&#53664;&#54616;&#50668;&#46972;. . lm514 &lt;- lm(y~x) coefficients(lm514) . &lt;dl class=dl-inline&gt;(Intercept)6.13296703296704x0.215604395604395&lt;/dl&gt; err &lt;- function(A){ print(0.215604395604395 * A + 6.13296703296704) } . yerr = err(x)-y . [1] 6.348571 6.564176 6.779780 6.995385 7.210989 7.426593 7.642198 7.857802 [9] 8.073407 8.289011 8.504615 8.720220 8.935824 9.151429 . plot(x,yerr) . 2차곡선식의 회귀선이 적절해보이는 산점도이다. . 3) Durbin-Watson d &#53685;&#44228;&#47049;&#51032; &#44050;&#51012; &#44396;&#54616;&#50668; $H_0 : rho = 0 , H_1 : rho neq 0 $ &#51012; $ alpha = 0.05 $ &#47196; &#44160;&#51221;&#54616;&#50668;&#46972;. . d통계량 구하기 . derr &lt;- err(x)-y . [1] 6.348571 6.564176 6.779780 6.995385 7.210989 7.426593 7.642198 7.857802 [9] 8.073407 8.289011 8.504615 8.720220 8.935824 9.151429 . derr . &lt;ol class=list-inline&gt;0.348571428571435 | 0.26417582417583 | 0.679780219780225 | 0.19538461538462 | -0.289010989010985 | -0.57340659340659 | -0.457802197802195 | -0.6421978021978 | -0.926593406593405 | -0.41098901098901 | 0.604615384615384 | 0.520219780219779 | 0.535824175824175 | 0.151428571428569 | &lt;/ol&gt; length(derr) . 14 temp &lt;- 0 for (i in 2:14) temp &lt;- temp + sum((derr[i]-derr[i-1])^2) return(temp) . 2.3106819466248 temp/(sum(derr^2)) #d 통계량 . 0.624575413892953 d 통계량은 0.6246 으로 0이상 2이하이다. 양의 자기상관을 가진다고 볼 수 있다. . 4) &#50948; 3)&#51032; &#44160;&#51221;&#44208;&#44284;&#45716; 2)&#51032; &#49328;&#51216;&#46020;&#50640;&#49436; &#50619;&#51008; &#45712;&#45196;&#44284; &#51068;&#52824;&#54616;&#45716;&#51648; &#45436;&#51032;&#54616;&#50668;&#46972;. . $2)$ 의 산점도는 2차곡선식의 회귀선이 타당해보이며, $3)$의 검정결과는 양의 자기상관을 이야기하고있다. 느낌이 일치하지 않는다. .",
            "url": "https://cjfal.github.io/dj/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/10/15/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D5%EC%9E%A5%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/10/15/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D5%EC%9E%A5%EA%B3%BC%EC%A0%9C.html",
            "date": " • Oct 15, 2021"
        }
        
    
  
    
        ,"post20": {
            "title": "데이터시각화 10/13 강의 과제",
            "content": "import pandas as pd . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . df.iloc[:,list(map(lambda x : &#39;face&#39; in x, df.columns) )] . director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes cast_total_facebook_likes facenumber_in_poster actor_2_facebook_likes movie_facebook_likes . 0 0.0 | 855.0 | 1000.0 | 4834 | 0.0 | 936.0 | 33000 | . 1 563.0 | 1000.0 | 40000.0 | 48350 | 0.0 | 5000.0 | 0 | . 2 0.0 | 161.0 | 11000.0 | 11700 | 1.0 | 393.0 | 85000 | . 3 22000.0 | 23000.0 | 27000.0 | 106759 | 0.0 | 23000.0 | 164000 | . 4 131.0 | NaN | 131.0 | 143 | 0.0 | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | . 4911 2.0 | 318.0 | 637.0 | 2283 | 2.0 | 470.0 | 84 | . 4912 NaN | 319.0 | 841.0 | 1753 | 1.0 | 593.0 | 32000 | . 4913 0.0 | 0.0 | 0.0 | 0 | 0.0 | 0.0 | 16 | . 4914 0.0 | 489.0 | 946.0 | 2386 | 5.0 | 719.0 | 660 | . 4915 16.0 | 16.0 | 86.0 | 163 | 0.0 | 23.0 | 456 | . 4916 rows × 7 columns .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/13/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%941013%EA%B0%95%EC%9D%98%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/13/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%941013%EA%B0%95%EC%9D%98%EA%B3%BC%EC%A0%9C.html",
            "date": " • Oct 13, 2021"
        }
        
    
  
    
        ,"post21": {
            "title": "데이터시각화 10/6 강의 정리",
            "content": "import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns from scipy import stats . qqplot . - 히스토그램이나 박스플랏보다 분포를 특정하기에 좋은 시각화는 없을까? . 정규분포 크기 1000 평균 2 표준편차 1.5 . t분포 자유도 10 크기 1000 표준편차 루트(자유도/(자유도-2)) . t분포는 평균이 0 | . np.random.seed(43052) x=np.random.normal(size=1000,loc=2,scale=1.5) y=stats.t.rvs(df=10,size=1000)/np.sqrt(10/8)*1.5 + 2 . plt.hist(y) . (array([ 1., 2., 5., 47., 164., 342., 311., 95., 26., 7.]), array([-5.32281821, -4.04507802, -2.76733783, -1.48959763, -0.21185744, 1.06588276, 2.34362295, 3.62136314, 4.89910334, 6.17684353, 7.45458373]), &lt;BarContainer object of 10 artists&gt;) . 가끔식 튀는 큰값이 나온다 . - 우리가 관측한 $x_1, dots,x_{1000}$이 $N(2,1.5^2)$에서 나온 샘플인지 궁금하다. . (1) 관측한 값을 순서대로 나열하여 $x_{(1)},x_{(2)}, dots, x_{(1000)}$을 만든다. . x[:2] #2번째 까지만 보이기 . array([2.57513073, 3.62626175]) . $x_1=2.57513073, quad x_2=3.62626175$ | . x.sort() # 작은 순 정렬 . x[:2] . array([-2.44398446, -2.14071467]) . $x_{(1)}= -2.44398446, quad x_{(2)}=-2.14071467$ | . (2) 파이썬이나 R로 $N(2,1.5^2)$에서 1000개의 정규분포를 생성. 그리고 순서대로 나열하여 $ tilde{x}_{(1)}, tilde{x}_{(2)}, dots, tilde{x}_{(1000)}$를 만든다. . (3) $x_{(1)} approx tilde{x}_{(1)}, dots , x_{(1000)} approx tilde{x}_{(1000)}$ 이면 x는 정규분포일것 . 그런데 $ tilde{x}_{(1)}, tilde{x}_{(2)}, dots, tilde{x}_{(1000)}$은 시뮬레이션을 할때마다 다른값이 나올테니까 불안정한 느낌이 든다. $ to$ 이론적인 값을 계산하자. . xx = (x-np.mean(x)) / np.std(x,ddof=1) # x를 표준화 xx[:2] . array([-3.05569305, -2.84275629]) . print(stats.norm.ppf(0.001)) #실제우리가 관측한 값 print(stats.norm.ppf(0.002)) . -3.090232306167813 -2.878161739095483 . m=[i/1000 for i in np.arange(1000)+1] # 이론적인 값 - 분위수 . np.arange(1000)[:10] . array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) . q=[] for i in range(len(m)): q=q+[stats.norm.ppf(m[i])] . q[:2] . [-3.090232306167813, -2.878161739095483] . $xx approx q$ 을 확인하기 위해서 $(q,q)$그래프와 $(q,xx)$의 그래프를 그려서 겹쳐보자. . plt.plot(q,xx,&#39;o&#39;) #표준화 : 동그라미점 선 plt.plot(q,q,&#39;-&#39;) #이론적인값 : 직선 . [&lt;matplotlib.lines.Line2D at 0x7f00b75caca0&gt;] . 해석: 점들이 주황색선 근처에 모여있을수록 정규분포에 가깝다. 굉장히 좋게 나온 예시 . | . - 아래와 같이 쉽게 그릴수도 있다. (_ = stats.probplot(x,plot=plt)우리가 그린그림과 조금 다르게 보인다) y축이 다름 . 자세히보면 조금 다르게 그려지긴 하는데 이는 $m=( frac{1}{1000}, dots, frac{999}{1000}, frac{1000}{1000})$와 같이 계산하지 않고 약간 보정한값을 계산하기 때문임 . | stats.probplot? 을 통하여 확인한 결과 아래와 같은 코드로 구현됨 . ### 보정하는방법1 n=len(xx) m=[((i+1)-0.3175)/(n+0.365) for i in range(n)] m[-n]=0.5**(1/n) m[0]=1-m[-n] . | 프로그램에 따라서 아래와 같이 보정하는 경우도 있음### 보정하는방법2 m=[(i-3/8)/(n+1/4) for i in np.arange(1000)+1] . | 또 자세히보면 stats.probplot은 y축에 표준화전의 x값이 있음을 알 수 있음. | . _ = stats.probplot(x,plot=plt) . _ = stats.probplot(x,plot=plt) # 정규분포 . _ = stats.probplot(y,plot=plt) # t분포 . t분포: 푸른점들이 대체로 붉은선위에 놓여있는듯 하지만 양끝단에서는 그렇지 않다. (중앙부근은 정규분포와 비슷하지만, 꼬리부분은 정규분포와 확실히 다르다) | 왼쪽꼬리: 이론적으로 나와야 할 값보다 더 작은값이 실제로 관측됨 | 오른쪽꼬리: 이론적으로 나와야 할 값보다 더 큰값이 실제로 관측됨 | 해석: 이 분포는 정규분포보다 두꺼운 꼬리를 가진다. | . &#49436;&#47196; &#45796;&#47480; &#54056;&#53412;&#51648;&#47484; &#49324;&#50857;&#54664;&#45716;&#45936; &#48537;&#50668;&#49436; &#44536;&#47532;&#44256; &#49910;&#51020; . matplot 기반이라 같이 쓸 수 있는 패키지가 있음 . fig , (ax1,ax2) = plt.subplots(1,2) fig.set_figwidth(8) # 그래프 크기 늘리기 . _ = stats.probplot(x,plot=ax1) _ = stats.probplot(y,plot=ax2) ax1.set_title(&#39;normal dist&#39;) ax2.set_title(&#39;t dist&#39;) . Text(0.5, 1.0, &#39;t dist&#39;) . fig . &#50696;&#51228;4 (boxplot, histrogram, qqplot) . - 박스플랏, 히스토그램, qqplot을 같이 그려보자. . fig, ax =plt.subplots(2,3) . (ax1,ax2,ax3), (ax4,ax5,ax6) = ax #각각의 축에 접근 . sns.boxplot(x,ax=ax1) #ax1에 박스플랏을 넣겠다 sns.histplot(x,kde=True,ax=ax2) #ax2에 히스토그램 _ = stats.probplot(x,plot=ax3) #ax3에 qq플랏 sns.boxplot(y,ax=ax4) sns.histplot(y,kde=True,ax=ax5) _ = stats.probplot(y,plot=ax6) #넒게 조정 fig.set_figwidth(10) fig.set_figheight(8) fig.tight_layout() . /home/kdj/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( /home/kdj/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( . fig . 지금까지는 가운데를 타겟으로 봤는데, 아래쪽그래프들은 양극단 데이터도 무시할 수가 없다. -&gt; ex)아마존 : 정규분포의 가운데가 마냥 맞는 것은 아니다. 전략 수립에서 정규성을 벗어나는지 봐야한다. . &#48516;&#50948;&#49688;&#47484; &#44396;&#54616;&#45716; &#45796;&#50577;&#54620; &#48169;&#48277; . m=[i/1000 for i in np.arange(1000)+1] #리스트 컴프리헨션 # np.arange(1000) : 0~999 . $m= big { frac{i}{1000}: i in {1,2,3, dots,1000 } big }= big { frac{1}{1000}, frac{2}{1000}, dots, frac{1000}{1000} big }$ | . m[:5] . [0.001, 0.002, 0.003, 0.004, 0.005] . range? . Init signature: range(self, /, *args, **kwargs) Docstring: range(stop) -&gt; range object range(start, stop[, step]) -&gt; range object Return an object that produces a sequence of integers from start (inclusive) to stop (exclusive) by step. range(i, j) produces i, i+1, i+2, ..., j-1. start defaults to 0, and stop is omitted! range(4) produces 0, 1, 2, 3. These are exactly the valid indices for a list of 4 elements. When step is given, it specifies the increment (or decrement). Type: type Subclasses: . range . 처음부터 정수 시퀀스를 생성하는 개체 반환(포함) 단계별로 정지(정지)합니다. . 범위(i, j)는 i, i+1, i+2, ..., j-1을 생성합니다. . start 기본값은 0이고 stop은 생략됩니다! range(4)는 0, 1, 2, 3을 생성합니다. . 이들은 정확히 4개의 원소 목록에 대한 유효한 지수이다. . 단계가 지정되면 증분(또는 감소)을 지정합니다. . stats.norm.ppf? . Signature: stats.norm.ppf(q, *args, **kwds) Docstring: Percent point function (inverse of `cdf`) at q of the given RV. Parameters - q : array_like lower tail probability arg1, arg2, arg3,... : array_like The shape parameter(s) for the distribution (see docstring of the instance object for more information) loc : array_like, optional location parameter (default=0) scale : array_like, optional scale parameter (default=1) Returns - x : array_like quantile corresponding to the lower tail probability q. File: ~/anaconda3/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py Type: method . stats.norm.ppf() . 주어진 RV의 q에서 백분율 포인트 함수(&#39;cdf&#39;의 역) . Parameters . q : array_like 낮은 꼬리 확률 arg1, arg2, arg3,... : array_like 분포에 대한 형상 모수(의 문서 문자열 참조) 자세한 내용을 보려면 인스턴스 개체) loc : array_like, 옵션 위치 매개 변수(기본값=0) scale : array_like, 옵션 척도 모수(기본값=1) . return . x : array_like = 아래쪽 꼬리 확률 q에 해당하는 분위수입니다. . q=[] for i in range(len(m)): q=q+[stats.norm.ppf(m[i])] q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . q=[stats.norm.ppf(m[i]) for i in range(len(m))] q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . q=list(map(stats.norm.ppf, m)) q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . stats.norm.ppf(m)[:5] . array([-3.09023231, -2.87816174, -2.74778139, -2.65206981, -2.5758293 ]) . lambda . lambda &#49324;&#50857;&#48277; . f = lambda x,y,z : x+y+z ## lambda 입력:출력 #이자체가 오브젝트로 취급된다. . f(2,3,4) . 9 . lambda &#46356;&#54260;&#53944;&#51077;&#47141;&#44050; . x= (lambda a=&#39;fee&#39;,b=&#39;fie&#39;,c=&#39;foe&#39;: a+b+c) . x(&#39;wee&#39;) . &#39;weefiefoe&#39; . lambda&#51032; &#47532;&#49828;&#53944;&#54868; . l = [lambda x: x**2, lambda x: x**3, lambda x: x**4] #리스트안에 람다 3개 . for f in l: print(f(2)) . 4 8 16 . lambda&#51032; &#46357;&#49492;&#45320;&#47532;&#54868; . dct={&#39;f1&#39;: (lambda x: x+1), &#39;f2&#39;: (lambda x: x+22), &#39;f3&#39;: (lambda x: x+333)} . dct[&#39;f1&#39;](1), dct[&#39;f2&#39;](1), dct[&#39;f3&#39;](1) . (2, 23, 334) . lambda&#51032; &#51312;&#44148;&#48512; &#52636;&#47141; . lower = lambda x,y : x if x&lt;y else y . lower(&#39;a&#39;,&#39;b&#39;) . &#39;a&#39; . lower(&#39;c&#39;,&#39;b&#39;) . &#39;b&#39; . lambda expression &#51012; return &#51077;&#47141;&#44032;&#45733; . def action(x): return (lambda y: x+y) #리턴을 람다로 . act = action(99) ## act를 99+y를 수행하는 함수로 저장 act2 = action(98) ## act2를 98+y를 수행하는 함수로 저장 . action은 마치 함수를 만드는 함수같다.. | . print(act(2)) # act안에 y에 2를 넣겠다. 99+2 print(act2(2)) # act2안에 y에 2를 넣겠다. 98+2 . 101 100 . &#50696;&#51228;6&#51032; &#48156;&#51204; . action = lambda x: (lambda y: x+y) # 람다 출력에 또 람다 . act= action(99) #x에 99를 넣은 함수 act 선언 act2=action(98) #x에 98를 넣은 함수 act2 선언 . print(act(2)) print(act2(2)) . 101 100 . 괄호를 생략하여 선언하면 . action = lambda x: lambda y: x+y act= action(99) act2=action(98) print(act(2)) print(act2(2)) # 똑같다. . 101 100 . map . map? #map(func, *iterables) --&gt; map 개체 #다음 인수를 사용하여 함수를 계산하는 반복자를 만듭니다. #각 반복 사항 최단 시간이 소진되면 중지됩니다. . Init signature: map(self, /, *args, **kwargs) Docstring: map(func, *iterables) --&gt; map object Make an iterator that computes the function using arguments from each of the iterables. Stops when the shortest iterable is exhausted. Type: type Subclasses: . map &#49324;&#50857;&#48169;&#48277; . def inc(x): return x+1 #임시로 쓸건데 공간도 차지하고 좀 그럼 $ to$ 람다로 처리 . list(map(inc,[1,2,3,4])) . [2, 3, 4, 5] . &#50696;&#51228;1&#51032; &#48320;&#54805;(&#46988;&#45796;&#49324;&#50857;) . list(map(lambda x: x+1,[1,2,3,4])) . [2, 3, 4, 5] . list(map(def inc(x): return x+1,[1,2,3,4])) #안됨 . File &#34;&lt;ipython-input-69-e70d258d54b1&gt;&#34;, line 1 list(map(def inc(x): return x+1,[1,2,3,4])) #안됨 ^ SyntaxError: invalid syntax . 함수명을 쓰는 자리에 lambda로 표현한 오브젝트 자체를 전달할 수 있다. $ to$ 코드가 간단하다. | . map&#44284; &#47532;&#49828;&#53944;&#52980;&#54532;&#47532;&#54760;&#49496; &#48708;&#44368; . (함수선언) . f = lambda x: &#39;X&#39; in x . f(&#39;X1&#39;),f(&#39;X2&#39;),f(&#39;Y1&#39;),f(&#39;Y2&#39;) . (True, True, False, False) . (map) . list(map(f,[&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;])) . [True, True, False, False] . (리스트컴프리헨션과 비교) . [f(x) for x in [&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;]] . [True, True, False, False] . &#46160;&#44060;&#51032; &#51077;&#47141;&#51012; &#48155;&#45716; &#54632;&#49688;(pow) map, &#47532;&#49828;&#53944;&#52980;&#54532;&#47532;&#54760;&#49496; &#48708;&#44368; . (함수소개) . pow(2,4) #2를 4제곱 . 16 . (map) . list(map(pow,[2,2,2,3,3,3],[0,1,2,0,1,2])) . [1, 2, 4, 1, 3, 9] . (리스트컴프리헨션과 비교) . [pow(x,y) for x,y in zip([2,2,2,3,3,3],[0,1,2,0,1,2])] #zip이라는 새로운 오브젝트 생성 . [1, 2, 4, 1, 3, 9] . map은 (하나의 함수,다양한 입력)인 경우 사용가능 . l=[lambda x: x+1, lambda x: x+2, lambda x: x+3 ] . list(map(l,[100,200,300])) . TypeError Traceback (most recent call last) &lt;ipython-input-78-dcc049c06067&gt; in &lt;module&gt; -&gt; 1 list(map(l,[100,200,300])) TypeError: &#39;list&#39; object is not callable . 리스트컴프리헨션은 (다양한함수,다양한입력)이 가능함 . [l[i](x) for i,x in zip([0,1,2],[100,200,300])] . [101, 202, 303] . 리스트컴프리헨션은 (다양한함수,다양한입력)이 가능함 . [l[i](x) for i,x in zip([0,1,2],[100,200,300])] . [101, 202, 303] . 종합:map을 리스트컴프리헨션과 비교 . (1) 반복인덱스를 쓰지 않는 장점 . (2) 좀 더 제약적으로 사용할 수 밖에 없다는 단점 . &#51339;&#51008; &#49884;&#44033;&#54868; &#54616;&#44592; . - 왜 우수한 그래프일까? . 자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존 | 이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임 | 미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함. | . &#49884;&#44033;&#54868; &#50696;&#51228; . x=[44,48,49,58,62,68,69,70,76,79] ## 몸무게 y=[159,160,162,165,167,162,165,175,165,172] ## 키 g= &#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;m&#39;,&#39;f&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39; df=pd.DataFrame({&#39;w&#39;:x,&#39;h&#39;:y,&#39;g&#39;:g}) . df . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 4 62 | 167 | m | . 5 68 | 162 | f | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . - 미나드의 접근방법 . sns.scatterplot(data=df,x=&#39;w&#39;,y=&#39;h&#39;,hue=&#39;g&#39;) . &lt;AxesSubplot:xlabel=&#39;w&#39;, ylabel=&#39;h&#39;&gt; . - 일반적인 사람들 (보통 색깔을 사용할 생각을 못한다.) . figs = sns.FacetGrid(df,col=&#39;g&#39;) figs.map (sns.scatterplot,&#39;w&#39;,&#39;h&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f00b6fa36d0&gt; . - 생각보다 데이터가 정리된 형태에 따라서 시각화에 대한 사고방식이 달라진다. 아래와 같은 자료를 받았다고 하자. . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv . df1 . w h . 0 44 | 159 | . 1 48 | 160 | . 2 49 | 162 | . 3 58 | 165 | . 5 68 | 162 | . df2 . w h . 4 62 | 167 | . 6 69 | 165 | . 7 70 | 175 | . 8 76 | 165 | . 9 79 | 172 | . - 데이터프레임을 바꿀 생각을 하는게 쉽지 않다. . (방법1) . df1[&#39;g&#39;]= &#39;f&#39; . df1 . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . df2[&#39;g&#39;]= &#39;m&#39; . df2 . w h g . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . pd.concat([df1,df2]) . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . (방법2) . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv . pd.concat([df1,df2],keys=[&#39;f&#39;,&#39;m&#39;]).reset_index().iloc[:,[0,2,3]].rename(columns={&#39;level_0&#39;:&#39;g&#39;}) . g w h . 0 f | 44 | 159 | . 1 f | 48 | 160 | . 2 f | 49 | 162 | . 3 f | 58 | 165 | . 4 f | 68 | 162 | . 5 m | 62 | 167 | . 6 m | 69 | 165 | . 7 m | 70 | 175 | . 8 m | 76 | 165 | . 9 m | 79 | 172 | . - 어려운점: . (1) 센스가 없어서 색깔을 넣어서 그룹을 구분할 생각을 못함 | (2) 변형해야할 데이터를 생각못함 | (3) 데이터를 변형할 생각을 한다고 해도 변형하는 실제적인 코드를 구현할 수 없음 (그래서 엑셀을 킨다..) (1) 기획력부족 -&gt; 훌륭한 시각화를 많이 볼것 | (2) 데이터프레임에 대한 이해도가 부족 -&gt; tidydata에 대한 개념 | (3) 프로그래밍 능력 부족 -&gt; 코딩공부열심히.. | . | . - 목표: . (2) 어떠한 데이터 형태로 변형해야하는가? | (3) 그러한 데이터 형태로 바꾸기 위한 pandas 숙련도 | .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/10/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC-%EA%B3%B5%EB%B6%80-%EC%95%84%EB%A7%885.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/10/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC-%EA%B3%B5%EB%B6%80-%EC%95%84%EB%A7%885.html",
            "date": " • Oct 10, 2021"
        }
        
    
  
    
        ,"post22": {
            "title": "데이터시각화 10/6 강의 과제",
            "content": "import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns from scipy import stats . &#45936;&#51060;&#53552;&#49884;&#44033;&#54868; 10/6&#51068;&#51088; &#44284;&#51228; 201514142 &#44608;&#46041;&#51456; . np.random.seed(201514142) x=np.random.chisquare(df=5, size=100) . fig, ax =plt.subplots(1,3) (ax1,ax2,ax3) =ax . sns.boxplot(x,ax=ax1) #ax1에 박스플랏을 넣겠다 sns.histplot(x,kde=True,ax=ax2) #ax2에 히스토그램 _ = stats.probplot(x,plot=ax3) #ax3에 qq플랏 . fig.set_figwidth(10) fig.set_figheight(5) fig.tight_layout() fig .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/08/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/08/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-%EA%B3%BC%EC%A0%9C.html",
            "date": " • Oct 8, 2021"
        }
        
    
  
    
        ,"post23": {
            "title": "데이터시각화 중간고사 공부2",
            "content": "import matplotlib.pyplot as plt import numpy as np import cv2 as cv import pandas as pd . Histogram Equalization, HE, &#55176;&#49828;&#53664;&#44536;&#47016; &#54217;&#54876;&#54868; . 이미지의 명암대비 개선 . . 이미지 불러오기 . img = cv.imread(&#39;사진이름.확장자&#39;,흑백-&gt;0) . img = cv.imread(&#39;450px-Unequalized_Hawkes_Bay_NZ.jpg&#39;,0) . img 입력시 array 숫자들이 출력됨 . $ to$ 그림이 픽셀의 조합이기때문 . $ to$ 이미지자료는 사실 0~255 사이의 어떠한 숫자들이 포함된 매트릭스일 뿐 . $ to$ 매트릭스에 있는 숫자들을 색깔로 표현하여 값이 클수록 하얗게, 값이 작을수록 검게 그린다. 극단적으로 0은 검은색, 255는 흰색이다. . plt.imshow(img,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7fd5b2e211f0&gt; . - 이미지가 넘파이 매트릭스일 뿐이라는 것을 판다스를 활용하면 더 잘 시각화하여 이해할 수 있다. . plt.imshow(img[200:300,400:500],cmap=&#39;gray&#39;,vmin=0,vmax=255) . &lt;matplotlib.image.AxesImage at 0x7fd5b266f100&gt; . df=pd.DataFrame(img) df.iloc[200:300,400:500].style.set_properties(**{&#39;font-size&#39;:&#39;10pt&#39;}).background_gradient(&#39;gray&#39;,vmin=0,vmax=255) . 데이터 프레임인데 각 셀의 색이 다르다 -&gt; like 그림을 크게 확대한것 . img.flatten().shape . (135000,) . fig1=plt.hist(img.flatten(),256,[0,256]) . - 히스토그램을 그려보니 120~200 사이에 너무 값들이 모여있음 . - 원래 0~255까지의 색을 표현할 수 있는데 컴퓨터가 표현가능한 색상보다 적은 조합만을 사용하고 있음. . $ to$ 더 많은 색상 표현 가능 = 히스토그램을 더 평평하게 = 선명 . img2=cv.equalizeHist(img) . fig2_1=plt.hist(img2.flatten(),256,[0,256]) . fig2_2=plt.hist(img2.flatten(),10,[0,256]) . plt.imshow(img2,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7fd5b05eb0d0&gt; . _img=np.hstack((img,img2)) . plt.imshow(_img,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7fd5b051af40&gt; . $ to$ 수정된 사진 비교 (더 진해 졌다) . . &#51060;&#48120;&#51648; &#51088;&#47308;&#50640; &#45824;&#54620; &#51060;&#54644; . - 흑백이미지 . 차원: 세로픽셀수 $ times$ 가로픽셀수 | 값: 0~255 (값이 클수록 흰색) | . - 칼라이미지 . 차원: 세로픽셀수 $ times$ 가로픽셀수 $ times$ 3 | 값: 0~255 (값이 클수록 진한빨강, 진한파랑, 진한녹색) | . hani=cv.imread(&#39;450px-Unequalized_Hawkes_Bay_NZ.jpg&#39;) . import matplotlib.pyplot as plt plt.imshow(hani) . &lt;matplotlib.image.AxesImage at 0x7fd5b0938b50&gt; . hani.shape . (300, 450, 3) . import numpy as np hani_red=np.zeros_like(hani) hani_green=np.zeros_like(hani) hani_blue=np.zeros_like(hani) hani_red[:,:,0]=hani[:,:,0] hani_green[:,:,1]=hani[:,:,1] hani_blue[:,:,2]=hani[:,:,2] . _img2=np.hstack((hani_red,hani_green,hani_blue)) plt.imshow(_img2) . &lt;matplotlib.image.AxesImage at 0x7fd5b03e8580&gt; . plt.imshow(hani_red+hani_green+hani_blue) . &lt;matplotlib.image.AxesImage at 0x7fd5b033aac0&gt; . &#49328;&#51216;&#46020; (scatter plot) . 산점도:직교 좌표계(도표)를 이용해 좌표상의 점들을 표시함으로써 두 개 변수 간의 관계를 나타내는 그래프 방법이다. 산점도는 보통 $X$와 $Y$의 관계를 알고 싶을 경우 그린다. . 박스플랏, 히스토그램은 그림을 그리기 위해서 하나의 변수만 필요함; 산점도를 위해서는 두개의 변수가 필요함. | 두변수 $ to$ 두변수의 관계 | . &#47800;&#47924;&#44172;&#50752; &#53412; &#50696;&#49884; . x=[44,48,49,58,62,68,69,70,76,79] y=[159,160,162,165,167,162,165,175,165,172] . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd5b027e4f0&gt;] . 키가 큰 사람일수록 몸무게도 많이 나간다. (반대도 성립) | 키와 몸무게는 관계가 있어보인다. (정비례) | . - 얼만큼 정비례인지? . 이 질문에 대답하기 위해서는 상관계수의 개념을 알아야 한다. | 상관계수에 대한 개념은 산점도를 이해함에 있어서 핵심개념이다. | . - (표본)상관계수 . $$r= frac{ sum_{i=1}^{n}(x_i- bar{x})(y_i- bar{y}) }{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2 sum_{i=1}^{n}(y_i- bar{y})^2 }} $$ . 분모를 계산했다고 치자. 계산한 값을 어떤 상수 $c$라고 생각하자. 이 값을 분자안에 넣을수도 있다. | . $$r= sum_{i=1}^{n} frac{1}{c}(x_i- bar{x})(y_i- bar{y}) $$ . 위의 식은 아래와 같이 다시 쓸 수 있다. | . $$r= sum_{i=1}^{n} left( frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}} frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}} right)$$ . 편의상 아래와 같이 정의하자. | . $$ tilde{x}_i= frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^n(x_i- bar{x})^2}}$$ . $$ tilde{y}_i= frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^n(y_i- bar{y})^2}}$$ . 결국 $r$은 아래와 같은 모양이다. | . $$r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i $$ . x=np.array(x) y=np.array(y) . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd5b02662e0&gt;] . plt.plot(x-np.mean(x), y-np.mean(y),&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd5b01c7190&gt;] . $$r= sum_{i=1}^{n} left( frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}} frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}} right)$$ . a=np.sqrt(np.sum((x-np.mean(x))**2)) #괄호 왼쪽 분모 b=np.sqrt(np.sum((y-np.mean(y))**2)) #괄호 오른쪽 분모 a,b . (36.58004920718396, 15.218409903797438) . $a&gt;b$ 이므로 $ {x_i }$들이 $ {y_i }$들 보다 좀 더 퍼져있다. (=평균근처에 몰려있지 않다) | . - 사실 $a,b$는 아래와 같이 계산할 수 있다. . $a= sqrt{n} times{ tt np.std(x)}$ . $b= sqrt{n} times{ tt np.std(y)}$ . n=len(x) np.sqrt(n)*np.std(x), np.sqrt(n)*np.std(y) . (36.58004920718397, 15.21840990379744) . ${ tt np.std(x)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(x_i- bar{x})^2}$ | ${ tt np.std(y)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(y_i- bar{y})^2}$ | . . Note: ${ tt np.std(x,ddof=1)}= sqrt{ frac{1}{n-1} sum_{i=1}^{n}(x_i- bar{x})^2}$ . - 이제 $( tilde{x}_i, tilde{y}_i)$를 그려보자. . xx= (x-np.mean(x))/a yy= (y-np.mean(y))/b plt.plot(xx,yy,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd5b01a9580&gt;] . 평균도 비슷하고 퍼진정도도 비슷하다. | . - 질문1: $r$의 값이 양수인가? 음수인가? . plotly 사용하여 그려보자. . import plotly.express as px from IPython.display import HTML fig=px.scatter(x=xx, y=yy) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . $ tilde{x}_i$, $ tilde{y}_i$ 를 곱한값이 양수인것과 음수인것을 체크해보자. | 양수인쪽이 많은지 음수인쪽이 많은지 생각해보자. | $r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i$ 의 부호는? $ to$ 양수인 쪽이 훨씬 많다축=0 기준으로 사분면을 그어 양수쪽 기울기일지 그 수를 확인 . 1,3분면 :양수 . | . - 질문2: 아래와 같은 두개의 데이터set이 있다고 하자. . x1=np.arange(0,10,0.1) y1=x1+np.random.normal(loc=0,scale=1.0,size=len(x1)) . plt.plot(x1,y1,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd5ab5801c0&gt;] . x2=np.arange(0,10,0.1) y2=x2+np.random.normal(loc=0,scale=7.0,size=len(x2)) plt.plot(x2,y2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd5ab54cdf0&gt;] . 같이 그리기 . plt.plot(x1,y1,&#39;o&#39;) plt.plot(x2,y2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd5ab523f40&gt;] . 각 데이터셋의 표준상관계수를 각각 $r_1$(파란색), $r_2$(주황색)라고 하자. . (1) $r_1$, $r_2$의 부호는 양수인가? 음수인가? . $r_1$ :양수&gt; $r_2$ :양수 . n=len(x1) xx1= (x1-np.mean(x1)) / (np.std(x1) * np.sqrt(n)) yy1= (y1-np.mean(y1)) / (np.std(y1) * np.sqrt(n)) xx2= (x2-np.mean(x2)) / (np.std(x2) * np.sqrt(n)) yy2= (y2-np.mean(y2)) / (np.std(y2) * np.sqrt(n)) . plt.plot(xx1,yy1,&#39;o&#39;) plt.plot(xx2,yy2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fd5ab4885b0&gt;] . (2) $r_1,r_2$의 값중 어떠한 값이 더 절대값이 큰가? . &#49345;&#44288;&#44228;&#49688; &#44228;&#49328; . sum(xx1*yy1), sum(xx2*yy2) . (0.9361646680973845, 0.4067814338019102) . 상관계수 r1이 더 크다 (절댓값이 더 크다) .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/03/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC-%EA%B3%B5%EB%B6%802.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/03/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC-%EA%B3%B5%EB%B6%802.html",
            "date": " • Oct 3, 2021"
        }
        
    
  
    
        ,"post24": {
            "title": "데이터시각화 중간고사 공부1",
            "content": "import matplotlib.pyplot as plt import numpy as np . boxplot . 단순한 평균비교보다 분포를 비교해보는 것이 중요하다. 분포를 살펴보는 방법 중 유용한 방법이 박스플랏이다. . 함수 :&gt;&gt;import matplotlib.pyplot as plt&gt;&gt;plt.boxplot() . y1=[75,75,76,76,77,77,79,79,79,98] # A선생님에게 통계학을 배운 학생의 점수들 y2=[76,76,77,77,78,78,80,80,80,81] # B선생님에게 통계학을 배운 학생의 점수들 . np.mean(y1), np.mean(y2) . (79.1, 78.3) . plt.boxplot(y1) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae2999040&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae29993a0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae2999700&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae2999a60&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae298ec70&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae2999dc0&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae29a5190&gt;], &#39;means&#39;: []} . plt.boxplot(y2) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae51dec10&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae51def70&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae51ea310&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae51ea670&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae51de8b0&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae51ea9d0&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae51ead30&gt;], &#39;means&#39;: []} . plt.boxplot([y1,y2]) # 나란히 그리기 . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae5149670&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae51499d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae5153e80&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae515f220&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae5149d30&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae51530d0&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae515f580&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae515f8e0&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae5149310&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae5153b20&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae5153430&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae515fc40&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae5153790&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae515ffa0&gt;], &#39;means&#39;: []} . 박스플랏 설명 그림 . np.random.seed(916170) # connection path is here: https://stackoverflow.com/questions/6146290/plotting-a-line-over-several-graphs mu, sigma = 0, 1 # mean and standard deviation s = np.random.normal(mu, sigma, 1000) fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(10, 5)) # rectangular box plot bplot = axes.boxplot(s, vert=False, patch_artist=True, showfliers=True, # This would show outliers (the remaining .7% of the data) positions = [0], boxprops = dict(linestyle=&#39;--&#39;, linewidth=2, color=&#39;Black&#39;, facecolor = &#39;red&#39;, alpha = .4), medianprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Yellow&#39;), whiskerprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Blue&#39;, alpha = .4), capprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Black&#39;), flierprops = dict(marker=&#39;o&#39;, markerfacecolor=&#39;green&#39;, markersize=10, linestyle=&#39;none&#39;, alpha = .4), widths = .3, zorder = 1) axes.set_xlim(-4, 4) plt.xticks(fontsize = 14) axes.set_yticks([]) axes.annotate(r&#39;&#39;, xy=(-.73, .205), xycoords=&#39;data&#39;, xytext=(.66, .205), textcoords=&#39;data&#39;, arrowprops=dict(arrowstyle=&quot;|-|&quot;, connectionstyle=&quot;arc3&quot;) ); axes.text(0, .25, &quot;Interquartile Range n(IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=18) axes.text(0, -.21, r&quot;Median&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(2.65, -.15, &quot; &quot;Maximum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.15, &quot; &quot;Minimum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-.68, -.24, r&quot;Q1&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.21, r&quot;(Q1 - 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(.6745, -.24, r&quot;Q3&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(.6745, -.30, r&quot;(75th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(-.68, -.30, r&quot;(25th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(2.65, -.21, r&quot;(Q3 + 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.annotate(&#39;Outliers&#39;, xy=(2.93,0.015), xytext=(2.52,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); axes.annotate(&#39;Outliers&#39;, xy=(-3.01,0.015), xytext=(-3.41,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); fig.tight_layout() . . plotly . 그림(그래프)에 마우스를 올리면 상호작용하는 그림 . plotly.express 와 pandas 필요 . import plotly.express as px import pandas as pd from IPython.display import HTML . 박스플랏에서 구한 성적을 df로 구현. . 열에 A라는것을 y1 수(길이)만큼 배열 . pd.concat([df1,df2]) :데이터프레임 합치기 ignore_index=True -&gt; 기존에 있던 인덱스를 무시해라 . 0~9 / 0~9 (기존) -&gt; 0~19 (무시) . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) . df=pd.concat([A,B],ignore_index=True) . html 같은 경우 블로그에 올릴 때 유용하다. (포맷을 변환) . 반응형 플랏을 볼 수 있다. (마우스 올리면 값나옴,HTML형태로 그려진 그림) . fig=px.box(data_frame=df, x=&#39;class&#39;,y=&#39;score&#39;) . HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . Histogram . X축이 변수의 구간, Y축은 그 구간에 포함된 빈도를 의미하는 그림 . plt.hist() 함수 이용 . np.random.normal() :정규분포&gt; &gt; loc:평균 , scale:표준편차 , size:표본수 . plt.hist(np.random.normal(loc=0, scale=1, size=1000000)) . (array([2.40000e+01, 1.21000e+03, 2.13380e+04, 1.39948e+05, 3.51614e+05, 3.39662e+05, 1.27147e+05, 1.80510e+04, 9.87000e+02, 1.90000e+01]), array([-5.05590169, -4.03792348, -3.01994528, -2.00196708, -0.98398887, 0.03398933, 1.05196753, 2.06994573, 3.08792394, 4.10590214, 5.12388034]), &lt;BarContainer object of 10 artists&gt;) . bins를 이용해 더 촘촘하게 그릴 수 있다. (정규분포에 더 가까워짐) . plt.hist(np.random.normal(loc=0, scale=1, size=1000000),bins=50) . (array([2.0000e+00, 6.0000e+00, 1.6000e+01, 3.9000e+01, 6.1000e+01, 1.3800e+02, 2.9000e+02, 5.0700e+02, 9.0400e+02, 1.6030e+03, 2.6310e+03, 4.1220e+03, 6.4460e+03, 9.5500e+03, 1.3819e+04, 1.9254e+04, 2.5638e+04, 3.3537e+04, 4.1336e+04, 4.9881e+04, 5.8100e+04, 6.5370e+04, 7.0605e+04, 7.3583e+04, 7.4674e+04, 7.2582e+04, 6.8887e+04, 6.2318e+04, 5.4823e+04, 4.6453e+04, 3.8169e+04, 3.0141e+04, 2.3006e+04, 1.7010e+04, 1.2102e+04, 8.3090e+03, 5.5450e+03, 3.4440e+03, 2.2440e+03, 1.2700e+03, 7.4300e+02, 4.3200e+02, 2.1800e+02, 9.4000e+01, 5.4000e+01, 1.9000e+01, 1.3000e+01, 5.0000e+00, 4.0000e+00, 3.0000e+00]), array([-4.56309489, -4.37544858, -4.18780228, -4.00015598, -3.81250967, -3.62486337, -3.43721707, -3.24957076, -3.06192446, -2.87427816, -2.68663185, -2.49898555, -2.31133925, -2.12369294, -1.93604664, -1.74840034, -1.56075403, -1.37310773, -1.18546143, -0.99781512, -0.81016882, -0.62252252, -0.43487621, -0.24722991, -0.05958361, 0.1280627 , 0.315709 , 0.5033553 , 0.69100161, 0.87864791, 1.06629421, 1.25394051, 1.44158682, 1.62923312, 1.81687942, 2.00452573, 2.19217203, 2.37981833, 2.56746464, 2.75511094, 2.94275724, 3.13040355, 3.31804985, 3.50569615, 3.69334246, 3.88098876, 4.06863506, 4.25628137, 4.44392767, 4.63157397, 4.81922028]), &lt;BarContainer object of 50 artists&gt;) . . 평균이 항상 좋은 중심경향값은 아니지만, 특수한 상황을 가정하면 평균이 좋은 중심경향값임 . np.random.seed(43052) #값이 안변하도록 시드설정 y1=np.random.normal(loc=0,scale=1,size=10000) #전북고 A반의 통계학 성적이라 생각하자. y2=np.random.normal(loc=0.5,scale=1,size=10000) #전북고 B반의 통계학 성적이라 생각하자. . np.mean(y1), np.mean(y2) #np.mean:평균, 튜플로 나옴 . (-0.011790879905079434, 0.4979147460611458) . (np.mean(y2)-np.mean(y1)).round(3) #소수 n째자리에서 반올림 . 0.51 . plt.boxplot([y1,y2]) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae27ac7c0&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae27acb20&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae2737fa0&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae2743340&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae27ace80&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae2737220&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae27436a0&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae2743a00&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae27ac460&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae2737c40&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae2737580&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae2743d60&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7f3ae27378e0&gt;, &lt;matplotlib.lines.Line2D at 0x7f3ae2751100&gt;], &#39;means&#39;: []} . 분포의 모양이 거의 일치하다고 할만큼 비슷하다. . $B반의 성적 approx A반의 성적 + 0.51$ 라고 주장해도 큰 무리가 없음 . 정규분포인지는 어떻게 알까? $ to$ 히스토그램 그려보기 . plt.hist(y1,bins=50) . plt.hist(y2,bins=50) . plt.hist([y1,y2],bins=200) #같이 그리기 . $ to$ 아웃풋이 너무 지저분하다. . &#49352;&#47196;&#50868; &#54056;&#53412;&#51648; &#51060;&#50857; . R:ggplot2 가 대세&gt; Python:&gt;&gt;matplotlib (매트랩 모방) . seaborn . plotnine (ggplot모방) . plotly 등등 많음 . seaborn . 깔끔하게 히스토그램을 그리는 패키지 . df를 입력으로 받는다 . import seaborn as sns . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) df=pd.concat([A,B],ignore_index=True) . sns.histplot(df,x=&#39;score&#39;,hue=&#39;class&#39;) . &lt;AxesSubplot:xlabel=&#39;score&#39;, ylabel=&#39;Count&#39;&gt; . plotnine . 인터랙티브 그래프를 위해서 plotly 홈페이지를 방문하여 적당한 코드를 가져온다. . from plotnine import * . ggplot(df)+geom_histogram(aes(x=&#39;score&#39;,color=&#39;class&#39;)) . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: &#39;stat_bin()&#39; using &#39;bins = 84&#39;. Pick better value with &#39;binwidth&#39;. . &lt;ggplot: (8743170859795)&gt; . $ to$ 별로 알아보기가 힘들다 . color를fill로 바꿔줌 , position을 동등하게 , alpha: 투명도 . ggplot(df)+geom_histogram(aes(x=&#39;score&#39;,fill=&#39;class&#39;),position=&#39;identity&#39;,alpha=0.5) . /home/kdj/anaconda3/lib/python3.8/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: &#39;stat_bin()&#39; using &#39;bins = 84&#39;. Pick better value with &#39;binwidth&#39;. . &lt;ggplot: (8743171077340)&gt; . plotly &#54876;&#50857; . 구글에 검색하면 예시가 잘 나와있다. . import plotly.figure_factory as ff import numpy as np hist_data=[y1,y2] group_labels=[&#39;A&#39;,&#39;B&#39;] fig = ff.create_distplot(hist_data, group_labels, bin_size=.2, show_rug=False) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . .",
            "url": "https://cjfal.github.io/dj/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/02/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%941.html",
            "relUrl": "/python/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94/2021/10/02/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%941.html",
            "date": " • Oct 2, 2021"
        }
        
    
  
    
        ,"post25": {
            "title": "4주차 회귀분석 연습문제 4.8 R 풀이",
            "content": "base . A &lt;- c(5,6,7,8,9,10,11,12,13,14) B &lt;- c(89,87,98,110,103,114,116,110,126,130) . 1)2) &#51208;&#54200;&#44284; &#44592;&#50872;&#44592;&#51032; &#49888;&#47280;&#44396;&#44036; &#48143; &#44160;&#51221; . lm48 &lt;- lm(B~A) summary(lm48) . Call: lm(formula = B ~ A) Residuals: Min 1Q Median 3Q Max -9.3758 -2.1545 0.9152 2.0864 8.3455 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 66.212 5.767 11.482 3.00e-06 *** A 4.430 0.581 7.625 6.16e-05 *** Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 5.278 on 8 degrees of freedom Multiple R-squared: 0.879, Adjusted R-squared: 0.8639 F-statistic: 58.14 on 1 and 8 DF, p-value: 6.161e-05 . coeffs &lt;- coefficients(lm48) confint(lm48,level = 0.95) # 기울기와 절편의 95% 신뢰구간 . A matrix: 2 × 2 of type dbl 2.5 %97.5 % . (Intercept)52.914087 | 79.510156 | . A 3.090412 | 5.770194 | . R을 통해 y=β_0+β_1 x+ϵ 를 가정해 본 결과 절편β_0은 66.212, 기울기β_1은 4.430이 나왔다. 절편의 신뢰구간을 추정해본 결과 절편 β_0의 신뢰구간은 (52.914087, 79.510156) 으로 나왔다. 이어서 자유도가 8인 t분포에서 가운데 면적이 95% 인 경우의 t*값은 2.306이다. 그런데 summary 에서 확인할 수 있는 절편의 t-value은 11.482로 2.306보다 크다. 즉 영가설을 기각한다. . 기울기의 신뢰구간은 (3.090412, 5.770194)이다. summary에서 절편에 대한 t-value 값은 7.625인데 이 값은 자유도 8인 t분포에서 가운데 면적이 95%일때의 t*값인 2.306 보다 크므로 영가설을 기각한다. . 3) &#48516;&#49328;&#48516;&#49437;&#54364;&#47196; &#44592;&#50872;&#44592; &#44160;&#51221; . anova(lm48) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . A1 | 1619.2758 | 1619.27576 | 58.13643 | 6.160731e-05 | . Residuals8 | 222.8242 | 27.85303 | NA | NA | . F-value는 58.136 이다. 분자의 자유도 1 과 분모의 자유도가 8인 F-분포에서 p-value 는 6.161^(-10)이다. 이 p값은 굉장히 작기 때문에 선형모형(기울기와 편차)의 가정이 좋은 가정이라고 말할 수 있다. . 4) &#44208;&#51221;&#44228;&#49688;&#50752; &#51032;&#48120; . (cor(A,B))^2 . 0.879037922792333 결정계수 R^2는 0.8790379이다. 1에 가까운 값으로 추정된 방정식이 판매액과 광고비를 잘 나타내 준다고 말할 수 있다 . 5) x=10 &#51068;&#46412; yhat &#49888;&#47280;&#44396;&#44036; . q10 &lt;- data.frame(A=10) predict(lm48,q10,level=0.95,interval=&quot;confidence&quot;) . A matrix: 1 × 3 of type dbl fitlwrupr . 1110.5152 | 106.6087 | 114.4216 | . 적합된 광고비 값은 110.5152이고, 그 신뢰구간은 (106.6087,114.4216) 이다. . 6) x=10 &#51068;&#46412; y &#50696;&#52769;&#44396;&#44036; . predict(lm48,q10,level=0.95,interval=&quot;predict&quot;) . A matrix: 1 × 3 of type dbl fitlwrupr . 1110.5152 | 97.73341 | 123.2969 | . 적합된 광고비 값은 110.5152이고, 그 예측구간은 (97.73341,123.2969) 이다. . q8 &lt;- data.frame(A=8) q9 &lt;- data.frame(A=9) q10 &lt;- data.frame(A=10) q11 &lt;- data.frame(A=11) q12 &lt;- data.frame(A=12) predict(lm48,q8,level=0.95,interval=&quot;confidence&quot;) predict(lm48,q9,level=0.95,interval=&quot;confidence&quot;) predict(lm48,q10,level=0.95,interval=&quot;confidence&quot;) predict(lm48,q11,level=0.95,interval=&quot;confidence&quot;) predict(lm48,q12,level=0.95,interval=&quot;confidence&quot;) predict(lm48,q8,level=0.95,interval=&quot;predict&quot;) predict(lm48,q9,level=0.95,interval=&quot;predict&quot;) predict(lm48,q10,level=0.95,interval=&quot;predict&quot;) predict(lm48,q11,level=0.95,interval=&quot;predict&quot;) predict(lm48,q12,level=0.95,interval=&quot;predict&quot;) . A matrix: 1 × 3 of type dbl fitlwrupr . 1101.6545 | 97.3128 | 105.9963 | . A matrix: 1 × 3 of type dbl fitlwrupr . 1106.0848 | 102.1784 | 109.9913 | . A matrix: 1 × 3 of type dbl fitlwrupr . 1110.5152 | 106.6087 | 114.4216 | . A matrix: 1 × 3 of type dbl fitlwrupr . 1114.9455 | 110.6037 | 119.2872 | . A matrix: 1 × 3 of type dbl fitlwrupr . 1119.3758 | 114.2736 | 124.4779 | . A matrix: 1 × 3 of type dbl fitlwrupr . 1101.6545 | 88.73311 | 114.576 | . A matrix: 1 × 3 of type dbl fitlwrupr . 1106.0848 | 93.30311 | 118.8666 | . A matrix: 1 × 3 of type dbl fitlwrupr . 1110.5152 | 97.73341 | 123.2969 | . A matrix: 1 × 3 of type dbl fitlwrupr . 1114.9455 | 102.024 | 127.8669 | . A matrix: 1 × 3 of type dbl fitlwrupr . 1119.3758 | 106.1794 | 132.5721 | . &#49888;&#47280;&#45824; &#50696;&#52769;&#45824; &#46020;&#49884; . m_conf &lt;- predict(lm48,level=0.95,interval=&quot;confidence&quot;) plot(B~A) lwr &lt;- m_conf[,2] upr &lt;- m_conf[,3] sx &lt;- sort(A, index.return=TRUE) abline(coef(lm48),lwd=2) lines(sx$x, lwr[sx$ix], col=&quot;blue&quot;, lty=2) lines(sx$x, upr[sx$ix], col=&quot;blue&quot;, lty=2) m_pred &lt;- predict(lm48,level=0.95,interval=&quot;predict&quot;) p_lwr &lt;- m_pred[,2] p_upr &lt;- m_pred[,3] lines(A, p_lwr, col=&quot;red&quot;, lty=2) lines(A, p_upr, col=&quot;red&quot;, lty=2) . Warning message in predict.lm(lm48, level = 0.95, interval = &#34;predict&#34;): “predictions on current data refer to _future_ responses ” . (오류는 무슨뜻일까.. 문제는 없어보인다) . 붉은선은 예측대, 파란선은 신뢰대이다. 예측대가 신뢰대보다 더 넓은 범위를 차지하며 . 신뢰대와 예측대 모두 거의 중앙에 회귀선을 품고있는 모습을 하고 있다. . 값에따른 신뢰구간과 예측구간 . x_0 신뢰구간(confidence) 예측구간(predict) . | lwr | upr | lwr | Upr | . 8 | 97.31280 | 105.9963 | 88.73311 | 114.5760 | . 9 | 102.1784 | 109.9913 | 93.30311 | 118.8666 | . 10 | 106.6087 | 114.4216 | 97.73341 | 123.2969 | . 11 | 110.6037 | 119.2872 | 102.0240 | 127.8669 | . 12 | 114.2736 | 124.4779 | 106.1794 | 132.5721 | .",
            "url": "https://cjfal.github.io/dj/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/09/30/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C_4_8.html",
            "relUrl": "/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/09/30/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C_4_8.html",
            "date": " • Sep 30, 2021"
        }
        
    
  
    
        ,"post26": {
            "title": "4주차 회귀분석 연습문제 4.1 R 풀이",
            "content": "Base 코드 . x &lt;- c(28.0,28.0,32.5,39.0,45.9,57.8,58.1,62.5) #시간당평균온도 y &lt;- c(12.4,11.7,12.4,10.8,9.4,9.5,8.0,7.5) #석탄소비량 lm31 &lt;- lm(y~x) . 1) &#44592;&#50872;&#44592;&#50752; &#51208;&#54200;&#51032; &#49888;&#47280;&#44396;&#44036; &#44396;&#54616;&#44592; . summary(lm31) . Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -0.5663 -0.4432 -0.1958 0.2879 1.0560 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 15.83786 0.80177 19.754 1.09e-06 *** x -0.12792 0.01746 -7.328 0.00033 *** Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 0.6542 on 6 degrees of freedom Multiple R-squared: 0.8995, Adjusted R-squared: 0.8827 F-statistic: 53.69 on 1 and 6 DF, p-value: 0.0003301 . coeffs &lt;- coefficients(lm31) confint(lm31,coeffs[2],level=0.95) #기울기 b1 의 95% 신뢰구간 . A matrix: 1 × 2 of type dbl 2.5 %97.5 % . x-0.1706383 | -0.08520517 | . confint(lm31,level = 0.95) #절편 b0 의 95% 신뢰구간 . A matrix: 2 × 2 of type dbl 2.5 %97.5 % . (Intercept)13.8759886 | 17.79972621 | . x-0.1706383 | -0.08520517 | . 2) &#49888;&#47280;&#44396;&#44036;&#51032; &#51032;&#48120; . 시간당 평균온도를 한 단위(℉) 늘리면 석탄소비량(ton)은 -0.171과 -0.0852 사이의 어느 한 값의 배수만큼 평균적으로 증가함을 신뢰계수 0.95로 예측할 수 있다. . 3) &#44032;&#49444; &#44160;&#51221; &#50689;&#44032;&#49444;=0 &#50976;&#51032;&#49688;&#51456; 0.05 . summary(lm31) . Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -0.5663 -0.4432 -0.1958 0.2879 1.0560 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 15.83786 0.80177 19.754 1.09e-06 *** x -0.12792 0.01746 -7.328 0.00033 *** Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 0.6542 on 6 degrees of freedom Multiple R-squared: 0.8995, Adjusted R-squared: 0.8827 F-statistic: 53.69 on 1 and 6 DF, p-value: 0.0003301 . 15.838 + 2.447* 0.01746 15.838 - 2.447* 0.01746 . 15.88072462 15.79527538 기울기의 추정값 b1 = 15.838 이고 표준오차 SE는 0.01746 이다. 자유도(degrees of freedom)=6 인 t분포에서 가운데 면적이 95%인 t*=2.447 이며 95% 신뢰구간은 다음과 같이 계산한다. b_1±t^*×SE=15.838 ±2.447 ×0.01746 . 95% 신뢰구간 : (15.79528 , 15.88072) . 이 결과로부터 기울기(평균온도가 1℉ 오를 때 석탄소비량 상승은 15.79528 ton 에서 15.88072 ton 사이에 있을 것이라고 95% 확신한다. . 4) &#44032;&#49444;&#44160;&#51221;2 . Pr(&gt;|t|) 값(p-value)의 값이 극히 작으므로 상당히 믿을 만한 정보이고, 영가설 H0를 기각한다. 즉, 기울기 β_1 은 의미있는 가정값이다. . 5) &#48516;&#49328;&#48516;&#49437;&#51012; &#53685;&#54620; &#44032;&#49444;&#44160;&#51221; . anova(lm31) . A anova: 2 × 5 DfSum SqMean SqF valuePr(&gt;F) . &lt;int&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . x1 | 22.980816 | 22.980816 | 53.69488 | 0.0003300523 | . Residuals6 | 2.567934 | 0.427989 | NA | NA | . F-value는 53.695 이다. 분자의 자유도 1 과 6인 F-분포에서 p-value 는 0.00033301이다. 이 p값은 굉장히 작기 때문에 선형모형(기울기와 편차)의 가정이 좋은 가정이라고 말할 수 있다. . 6)&#49884;&#44036;&#45817; &#54217;&#44512; &#50728;&#46020;&#50640; &#46384;&#47480; &#49548;&#48708;&#47049; &#52628;&#51221;, &#49888;&#47280;&#44396;&#44036; &#44396;&#54616;&#44592; . q6 &lt;- data.frame(x=40) predict(lm31,q6, level=0.95,interval=&quot;confidence&quot;) #신뢰구간 . A matrix: 1 × 3 of type dbl fitlwrupr . 110.72099 | 10.1301 | 11.31188 | . 추정된 석탄소비량은 10.72099 ton 이다. 그 신뢰구간은 (10.1301, 11.31188) 이고 y값이 이 범위에 있을 확률이 95%라는 의미이다. . 7) &#50696;&#52769;&#44396;&#44036; &#52628;&#51221; . predict(lm31,q6, level=0.95,interval=&quot;predict&quot;)예측구간 . A matrix: 1 × 3 of type dbl fitlwrupr . 110.72099 | 9.014624 | 12.42735 | . 추정된 석탄소비량은 10.72099 ton 이다. 그 예측구간은 (9.014624, 12.42735) 이고 y값이 이 범위에 있을 확률이 95%라는 의미이다. . 8) 6&#48264; 7&#48264;&#47928;&#51228; &#48708;&#44368; . 신뢰구간:y의 평균이 존재하는 구간을 추정  모집단을 예측 변수의 특정 값의 반응변수의 값으로 제한한다. 예측구간:하나의 y가 존재하는 구간을 추정  모집단을 대부분 포함해야 하므로 구간이 더 넓다. . 9) &#44208;&#51221;&#44228;&#49688; &#48143; &#51032;&#48120; . cor(x,y) # 상관계수 . -0.948413871025354 상관 계수 r :-0.9484139  -1에 가까우므로 강한 음의 상관관계를 가진다고 볼 수 있다. . (cor(x,y))^2 #결정계수 . 0.899488870753297 결정 계수 R^2: 0.8994889 . 결정 계수는 온도변화로 석탄소비량의 89.95%를 설명한다는 뜻이다. . 결정 계수가 1에 거의 근접하므로 가정된 방정식이 온도변화와 석탄소비량의 관계를 잘 설명한다고 볼 수 있다. .",
            "url": "https://cjfal.github.io/dj/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/09/30/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C_4_1.html",
            "relUrl": "/r/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/2021/09/30/%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C_4_1.html",
            "date": " • Sep 30, 2021"
        }
        
    
  
    
        ,"post27": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://cjfal.github.io/dj/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post28": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://cjfal.github.io/dj/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "김동준 소개 .",
          "url": "https://cjfal.github.io/dj/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://cjfal.github.io/dj/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}